---
date: 2025-05-19 13:58
tags:
---
# 并发编程演进史

> **目标**：不讲技术细节，讲每个时代面临的**真实问题**和**解决思路的演变**
> 
> 框架：△Why（为什么这样设计）→ △Trade-offs（取舍）→ △How（非技术复述）

---

## 时间线概览

```
1970s-1980s: 多进程时代        Why: CPU 单核，如何并发？
                                     → 操作系统负责调度
     ↓ 问题：进程太重，内存爆炸
1990s-2000s: 多线程时代        Why: 共享内存，减轻进程负担
                                     → 程序员手工管理线程
     ↓ 问题：线程同步难，死锁、竞态条件频发
2000s-2010s: 回调/异步时代     Why: 事件驱动，避免线程阻塞
                                     → Node.js、JavaScript 流行
     ↓ 问题：回调地狱，代码难读
2010s-2020s: 协程/Async时代     Why: 用户态轻量级任务切换
                                     → Python asyncio、Rust async
     ↓ 问题：单核性能受限，多核怎么办
2020s-今天:  分布式并发时代     Why: 单机性能上限，向外扩展
                                     → 微服务、消息队列、流计算
```

---

# 第 1 阶段：多进程时代（1970s-1980s）

## △ Why：为什么需要并发？

### 问题背景

```
时代背景：计算机还没有多核

【场景】：一个 Web 服务器
- 服务器有 1 个 CPU
- 同时有 100 个用户请求
- 如果处理完一个请求再处理下一个，用户要等待 100 秒

【现象】：服务器看起来"阻塞"了
```

### 设计动机

```
关键洞察：CPU 和 I/O 速度相差 100 倍

用户请求来了
  ↓
【处理业务逻辑】← CPU 工作（1 微秒）
  ↓
【等待数据库返回】← I/O 等待（100 微秒）← CPU 闲置！浪费！
  ↓
【继续业务逻辑】← CPU 工作（1 微秒）

在等待 I/O 的 100 微秒里，CPU 其实可以处理其他请求！
但怎样让操作系统来管理这个切换呢？
→ 答案：多进程
```

### 解决方案：多进程

```
为每个用户请求创建一个进程：

进程 1（用户 A）
  ↓ I/O 等待时
进程 2（用户 B）← OS 调度器在这里工作
  ↓ I/O 等待时
进程 3（用户 C）

每当一个进程阻塞在 I/O 上，OS 就切换到其他进程
结果：整个服务器看起来在"同时"处理多个请求
```

---

## △ Trade-offs：多进程的代价

### 收益

```
✓ 编程简单：每个进程就是顺序代码，不用考虑"并发"
✓ 隔离：进程间内存独立，一个进程崩溃不影响其他进程
✓ 稳定：操作系统帮你管理调度，你只管写业务逻辑
```

### 代价

```
✗ 内存开销巨大：每个进程 10-100MB
  → 100 个并发请求 = 1-10GB 内存（1980 年代是奢侈品）
  
✗ 上下文切换开销：OS 每次切换进程都要保存 CPU 状态
  → 频繁切换导致 CPU 缓存失效，性能急剧下降
  
✗ 数据共享困难：进程间内存隔离
  → 想共享数据？必须用 IPC（进程间通信），很复杂
```

### 量化数据

```
场景：Web 服务器，同时处理 1000 个连接

多进程方案：
- 内存：1000 进程 × 50MB = 50GB（当时的服务器只有 1GB）
- 上下文切换：1000 进程，每 10ms 轮转一次 → 性能下降 90%
- 结论：不可行

实际做法：
- 1980 年代的 Apache 用"进程池"
- 最多维护 100-200 个进程
- 用户排队等待可用进程
```

---

## △ How：用比喻讲多进程

```
【比喻】：银行柜台模式

传统方式（无并发）：
- 1 个柜员，顾客排成一列
- 柜员处理完 A，再处理 B，再处理 C
- 从 A 的视角：自己办业务（2 分钟）+ 等前面的人（30 分钟）= 32 分钟

多进程方式：
- 银行老板说："我给你招 20 个柜员"
- 每个顾客进来就分配一个柜员
- 柜员 A 在等"办理转账的银行系统"时（2 分钟）
- 柜员 B 可以同时服务其他顾客
- 从顾客的视角：平均等待时间大幅下降

代价：
- 要招 20 个柜员（工资成本 = 内存成本）
- 柜员之间经常要协调（谁处理这个账户？避免重复）
- 柜员太多的话，互相干扰，反而效率下降
```

---

## 历史回顾

```
1983 年：Apache Web Server 推出，用多进程模型
        一台机器最多 50-100 并发（进程太多了）

1990 年代：互联网爆炸，用户连接数激增
         C10K 问题诞生（如何处理 10,000 并发连接？）
         多进程已经撑不住了

→ 需要新的并发模型
```

---

# 第 2 阶段：多线程时代（1990s-2010s）

## △ Why：为什么要抛弃多进程用线程？

### 问题背景

```
【困境】：C10K 问题（Concurrent 10,000 connections）

多进程方案：
- 10,000 个请求 = 10,000 个进程
- 每个进程 10MB 内存 = 100GB 总内存
- 上下文切换 10,000 次 = 性能災难

【需求】：
- 希望有一种"轻量级进程"
- 内存占用少得多
- 但仍然能共享内存（便于数据交互）
```

### 设计动机

```
核心洞察：进程的大部分开销是"独立的内存空间"
         如果多个任务能共享内存，就能大幅减轻开销

→ 答案：线程（Thread）= 轻量级进程 + 共享内存
```

### 多线程模型

```
进程（重量级）
  ├─ 线程 1（轻量级，共享内存，但独立栈）
  ├─ 线程 2
  └─ 线程 3

线程 1 在等 I/O 时
线程 2 可以立即获得 CPU（不用等待 OS 重新调度）

好处：
✓ 内存开销：1 个进程 + 1000 个线程 = 100MB（而不是 100GB）
✓ 切换快：线程切换比进程切换快 100 倍
```

---

## △ Trade-offs：多线程的代价

### 收益

```
✓ 内存效率：1000 个线程 = 100MB（vs 进程的 100GB）
✓ 切换速度：线程切换快，CPU 缓存命中率高
✓ 数据共享：直接访问共享内存，不用 IPC
```

### 代价

```
✗ 同步困难：多个线程访问同一个数据，可能产生竞态条件
  → 需要 Lock、Mutex、Semaphore 等同步原语
  → 编程难度陡增

✗ 死锁风险：线程 A 等 Lock1、线程 B 等 Lock2
          线程 A 想要 Lock2、线程 B 想要 Lock1
          → 双方互相等待，永远阻塞（死锁）

✗ 调试困难：多线程 bug 很难复现
  → "在我电脑上跑好好的"（竞态条件只在特定时序出现）
  
✗ CPU 数量限制：多线程还是要靠 OS 调度
  → 仍然受 CPU 核数限制（双核 CPU 最多 2 个线程真正并行）
```

### 量化数据

```
数据库连接池问题：

场景：Web 应用，需要处理 1000 并发连接

错误做法：
- 创建 1000 个线程
- 每个线程持有一个数据库连接
- 数据库最多支持 1000 个连接
- 当线程阻塞在"查询数据库"时，连接被占用但 CPU 闲置
- 结果：经常出现"数据库连接耗尽"的错误

正确做法：
- 创建 1000 个线程
- 但只维护 20 个数据库连接（连接池）
- 线程之间共享这 20 个连接
- 这需要精心设计同步逻辑（各种 Lock）
- 容易出现死锁
```

---

## △ How：用比喻讲多线程

```
【比喻】：餐厅厨房

多进程方式（1980 年代 Apache）：
- 为每个订单建一个独立的小厨房（进程）
- 每个小厨房配一套完整的锅碗瓢盆（内存）
- 50 个订单 = 50 个小厨房 = 内存爆炸

多线程方式（2000 年代升级）：
- 1 个大厨房（共享内存）
- 多个厨师（线程）共享锅碗瓢盆
- 50 个厨师 = 1 套锅碗瓢盆 = 内存只需 1/50

代价：
- 厨师A 在用"高温锅"时，厨师B 不能用
- 需要用"锁"（钥匙）来管理谁能用哪个锅
- 厨师A 拿了"锅的钥匙"又想要"盘子的钥匙"
- 但厨师B 已经拿了"盘子的钥匙"也想要"锅的钥匙"
- 结果：两个厨师互相等待，什么都做不了（死锁）
```

---

## 历史回顾

```
1990s：Java 推出 Thread，多线程变得流行
      号称"一劳永逸"解决并发问题

2000s：互联网爆炸，C10K 问题依然存在
      多线程方案虽然内存好多了，但仍然无法处理 10,000 连接
      原因：线程调度开销仍然巨大

2003 年：Dan Kegel 的"C10K Problem"论文成名
       指出：在多线程模型下，很难处理 10,000+ 并发连接

→ 需要新的并发模型
```

---

# 第 3 阶段：事件驱动/回调时代（2000s-2010s）

## △ Why：为什么要抛弃线程？

### 问题背景

```
【困境】：多线程仍然无法解决 C10K

案例：Web 服务器处理 10,000 请求

线程方案：
- 创建 10,000 个线程
- OS 需要管理 10,000 个线程的调度
- 每次上下文切换都要保存/恢复线程状态
- 总开销 = 10,000 线程 × 调度成本 → 性能災難

为什么多线程不行？
→ 因为"线程"的核心假设是"一个线程对应一个请求"
  当请求数量达到 10,000 时，线程数也是 10,000
  而 OS 调度器根本无法高效管理这么多线程
```

### 设计动机

```
关键洞察：真正的瓶颈不是"处理能力"，而是"管理开销"

线程模型的假设：
- 线程 1 处理请求 A，到 I/O 点阻塞
- OS 切换到线程 2（保存线程 1 的状态）
- 线程 2 处理请求 B，到 I/O 点阻塞
- OS 切换到线程 3...
- 这样的"强制切换"需要内核参与，开销大

新想法：
- 由应用程序（不是 OS）来管理任务调度
- 不用创建 10,000 个线程，用 1 个线程 + 事件循环
- 当一个请求的 I/O 完成了，事件循环就捡起来继续处理
- 所有的"上下文切换"都在用户态进行，没有 OS 开销

→ 答案：事件驱动 + 回调（Event-driven + Callback）
```

### 事件驱动模型

```
传统多线程模型：
进程 1 ─┬─ 线程 1（请求 A）─→ 阻塞等 I/O
       ├─ 线程 2（请求 B）─→ 阻塞等 I/O
       └─ 线程 3（请求 C）─→ 在 CPU 上运行
                    ↑ OS 不断做上下文切换，开销大

事件驱动模型：
进程 1 ─── 主线程 + 事件循环
           ├─ 请求 A（I/O 挂起）
           │   ↓ I/O 完成，产生事件
           │   ↑ 事件循环拿起，继续处理
           ├─ 请求 B（I/O 挂起）
           │   ↓ I/O 完成，产生事件
           │   ↑ 事件循环拿起，继续处理
           └─ 请求 C（在 CPU 上运行）

特点：
- 只有 1 个线程（或核心线程 = CPU 核数）
- 应用程序控制任务调度（用户态，零开销）
- 不需要 Lock（因为是单线程）
```

---

## △ Trade-offs：事件驱动的代价

### 收益

```
✓ 高并发：1 个线程可以处理 100,000+ 连接
✓ 低开销：不需要 Lock，没有上下文切换
✓ 简单：不用考虑竞态条件和死锁
```

### 代价

```
✗ 回调地狱（Callback Hell）：
  ```javascript
  // 伪代码
  queryUser(id, function(err, user) {
    queryOrder(user.id, function(err, orders) {
      queryProduct(orders[0].productId, function(err, product) {
        updateInventory(product.id, function(err, result) {
          // 业务逻辑被撕裂成嵌套回调
        });
      });
    });
  });
```

问题：代码难读、难维护、难调试

✗ 不支持并行计算： 事件驱动是"单线程"模型 → 不能利用多核 CPU → 8 核机器上，事件驱动仍然只用 1 核

✗ 阻塞性操作会导致整体卡顿：

```javascript
// CPU 密集型操作（计算斐波那契数列）
for (let i = 0; i < 1000000000; i++) {
  // 某个用户在做计算
}
// 在这 5 秒内，所有其他用户都卡住了（事件循环被阻塞）
```

✗ 错误处理复杂： 在回调链中，如果某个环节出错，要逐级传递 很容易出现"遗漏 error handler"的 bug

```

### 量化数据

```

性能对比：处理 10,000 并发连接

多线程方案（Java）：

- 内存：10,000 线程 × 1MB = 10GB
- CPU 上下文切换：100ms 内 10,000 次 = 性能 80% 损耗
- 实际吞吐：1000 req/s

事件驱动方案（Node.js）：

- 内存：1 线程 + 数据结构 = 100MB
- 上下文切换：0（应用程序控制）
- 实际吞吐：50,000 req/s（50 倍提升！）

代价：

- 代码复杂度：从"顺序代码"变成"回调链"
- 调试难度：×10（因为执行流程非常规）

```

---

## △ How：用比喻讲事件驱动

```

【比喻】：饭店点餐模式

多线程方式：

- 每个顾客分配一个专属服务员
- 100 个顾客 = 100 个服务员
- 服务员 A 在等"厨房出菜"时，就站在那里无事可做
- 服务员太多，互相撞来撞去，效率反而下降

事件驱动方式：

- 只有 1 个服务员（核心线程数 = CPU 核数）
- 顾客 A 点餐 → 服务员记录 → 交给厨房 → 继续服务顾客 B
- 当厨房说"顾客 A 的菜好了"时 → 事件循环通知服务员 → 上菜
- 结果：1 个服务员可以高效服务 10,000 个顾客

代价：

- 服务员必须想清楚"每个顾客的下一步"（而不是"站着等"）
- 如果顾客 A 要求"先配 10 道前菜再上主菜" 服务员需要记住这个"顺序约束"（否则出错）
- 服务员如果去做"费时的工作"（比如手工制作特殊饮料） 所有其他 10,000 个顾客都会被卡住

```

---

## 历史回顾

```

2009 年：Node.js 推出（基于事件驱动 + 回调） 声称可以处理 C10K + 从此成为 Web 后端的新宠儿

2010s：Node.js 崛起，事件驱动变成主流 但"回调地狱"问题困扰着数百万 JavaScript 开发者

→ 需要解决"回调地狱"，但保留"事件驱动的高效"

```

---

# 第 4 阶段：协程/Async 时代（2010s-2020s）

## △ Why：怎样结合"线程的易用性"和"事件驱动的高效性"？

### 问题背景

```

【困境】：两个世界都不完美

线程模型： ✓ 代码易读（顺序代码，符合直觉） ✗ 无法高并发（C10K 问题）

事件驱动模型： ✓ 高并发（可处理 100,000+ 连接） ✗ 代码难读（回调地狱）

【期望】： 能不能有一个模型，既能处理高并发，又能写顺序代码？

```

### 设计动机

```

关键洞察：我们真正需要的是什么？

线程要点：

- 每个任务有独立的"执行上下文"（栈、局部变量、返回地址）
- 可以随时暂停和恢复
- 操作系统帮我们管理暂停/恢复

问题：

- OS 管理的代价太大（上下文切换开销）
- 所以我们无法创建 10,000 个线程

新想法：

- 由应用程序（不是 OS）来管理"执行上下文"的暂停/恢复
- 这样的轻量级任务叫"协程"（Coroutine）
- 应用程序管理意味着："零开销"

结果：

- 协程看起来像"线程"（顺序代码）
- 但效率像"事件驱动"（高并发）

```

### 协程模型

```

async/await 是协程的现代化写法：

async function handleRequest(userId) { // 看起来是顺序代码 const user = await queryUser(userId); // 暂停点 1 const orders = await queryOrder(user.id); // 暂停点 2 const product = await queryProduct(orders[0]); // 暂停点 3 return { user, orders, product }; // 恢复并返回 }

执行过程：

- 暂停点 1：I/O 发起 → 函数暂停，返还 CPU → 其他协程继续运行 ↓ I/O 完成，产生事件
- 暂停点 2：自动恢复，继续执行 → I/O 发起 → 函数暂停 ↓ I/O 完成
- 暂停点 3：自动恢复，继续执行 → 函数返回结果

特点： ✓ 代码是顺序的（易读） ✓ 但底层用事件驱动实现（高效） ✓ 没有"回调地狱" ✓ 错误处理可以用 try/catch（自然）

```

---

## △ Trade-offs：协程的权衡

### 收益

```

✓ 代码易读：顺序代码，不用回调嵌套 ✓ 错误处理简单：try/catch 就行 ✓ 高并发：1 个 CPU 可以处理 100,000+ 协程 ✓ 低开销：协程切换全在用户态，几纳秒（vs 线程上下文切换的微秒）

```

### 代价

```

✗ 单 CPU 仍然是单线程： 8 核机器，标准的 async/await 仍然只用 1 核 → 需要配合"进程池"或"工作线程"来充分利用多核

✗ 学习曲线： async/await 看起来简单，但有很多"坑" 比如："忘记 await"导致 Promise 不会等待

✗ 与同步代码的混合使用容易出错：

```python
async def handle():
  result = some_sync_function()  # 这个阻塞调用会卡死整个事件循环！
  data = await async_function()
```

✗ 库生态分裂： 有的库是 async，有的库是同步 混合使用会很复杂

```

### 量化数据

```

性能对比：处理 100,000 并发连接

多线程方案（Java + Tomcat）：

- 内存：100,000 线程 × 1MB = 100GB（不现实）
- 实际做法：线程池 200，排队等待
- 吞吐：10,000 req/s

协程方案（Python asyncio）：

- 内存：100,000 协程 × 1KB = 100MB
- 上下文切换：0（应用程序控制）
- 吞吐：100,000 req/s（10 倍提升！）

代价：

- 代码需要改写（同步 → 异步）
- 必须所有库都支持 async（否则回到同步的"阻塞"）

```

---

## △ How：用比喻讲协程

```

【比喻】：线程池餐厅模式（2020 年代升级版）

多线程方式（2000s）：

- 100,000 个顾客 = 100,000 个服务员
- 每个服务员站着等，效率低

事件驱动方式（2010s）：

- 1 个服务员
- 顾客 A 点完菜，立即服务顾客 B
- 但这样的话，"为顾客 A 查账"和"为顾客 B 点菜"的逻辑混在一起
- 代码一团糟

协程方式（2020s）：

- 8 个服务员（= CPU 核数）
- 每个服务员维护一个"待服务顾客列表"（协程队列）
- 顾客 A 在等菜时，服务员立即转向顾客 B
- 菜好了，服务员自动切换回顾客 A
- 代码仍然是"顺序"的（易读），但效率是事件驱动级别的

代价：

- 需要"正确使用 await"（不能偷懒跳过）
- 如果某个顾客要求"手工制作特殊饮料"（CPU 密集型） 整个服务员队都会被卡住

```

---

## 历史回顾

```

2010s：

- Python 推出 asyncio（协程）
- JavaScript 推出 Promise（解决回调地狱的过渡方案）

2015 年：JavaScript async/await 标准化 "顺序代码 + 事件驱动效率"的梦想实现了

2017 年：Rust async/await 推出 在系统编程领域也能用协程了

2020s：协程变成业界标准 Go（goroutine）、Python（asyncio）、Rust（async/await）都支持

```

---

# 第 5 阶段：分布式并发（2010s-今天）

## △ Why：单机能力的上限

### 问题背景

```

【困境】：再怎么优化单机，也有物理上限

协程方案的现状：

- 1 台机器，8 核 CPU
- 用协程，每核都可以处理 100,000 并发
- 理论上 8 核 = 800,000 并发
- 现实中，受限于内存、网络 I/O
- 实际能处理：10,000-50,000 并发

当用户达到 1 亿时怎么办？ → 无法用单台机器解决

```

### 设计动机

```

关键洞察：解决 1 亿并发的唯一办法是"向外扩展"

单机并发的瓶颈：

1. CPU 核数有限（最多 128 核）
2. 内存有限（最多 2TB）
3. 网络 I/O 有限（最多 100Gbps）

解决方案：多台机器 × 协程

```
微服务架
```