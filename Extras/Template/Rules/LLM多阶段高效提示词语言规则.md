

## LLM多阶段高效提示词语言规则

### 核心原则：消除模糊性，提供精确指令

与 LLM 交互时，将其视为一个能力极强但“死板”的助手。它没有常识或隐含理解，需要清晰、无歧义地说明任务[[../../../Atlas/Index/目标]]、执行步骤、规则限制和预期结果。

**在多阶段架构中应用此核心原则：**

*   **所有阶段的Prompt都需要遵循此原则：** 无论您是在发出初始指令、要求LLM思考、评估自身输出，还是进行改进，都必须使用精确、无歧义的语言。
*   **阶段间的连接依赖精确指令：** 一个阶段的输出往往是下一个阶段的输入。明确要求LLM以特定格式输出中间结果（如评估报告、分析原因）对于后续阶段至关重要。

### 结构化多阶段提示词架构概览

以下是本规则文档所基于的多阶段架构：

[任务指令 Prompt]
        ↓
[初步思考 Prompt] → [输出结果]
        ↓
[自我评估 Prompt（Self-Eval）]
        ↓
[元认知分析 Prompt（Meta-Reflect）]
        ↓
[改进建议 Prompt（Refinement）]
        ↓
[更新提示 / 策略 / 工具选择]

本规则文档将结合此架构，阐述如何在每个阶段构建高效的提示词，并通过一个示例贯穿所有阶段。

### 各阶段提示词的构建要点与示例

虽然所有提示词都需要清晰、精确，但不同阶段的Prompt有其侧重点和特定要求。

#### 1. [任务指令 Prompt] (Initial Prompt)

**构建要点：**
*   **[[目标]]定义清晰：** 开头即明确最终要完成的任务是什么。
*   **角色设定（可选但推荐）：** 如果需要，设定LLM的角色（例如，“你是一位专业的[领域]编辑”，“你是一位代码审计专家”）。
*   **概述任务范围：** 简要说明需要处理的输入、预期的大致输出类型。
*   **引入必要背景信息：** 提供LLM理解任务所需的任何上下文或背景知识。
*   **指明后续流程（可选）：** 如果LLM知道它之后会被要求进行评估或反思，有时有助于其在初次生成时就考虑这些方面。

**核心原则应用：** 确保指令的“意图”明确，让LLM知道最终要实现什么。

**示例Prompt (P1):**

```markdown
“你是一名专业的学术摘要撰写助理。你的任务是阅读提供的学术论文片段，并为其撰写一个简洁、准确的摘要。摘要应清晰概括文章的核心主题、方法和主要结论。摘要长度应控制在150字以内。请在输出摘要之前，先思考并列出你认为这段文字的三个核心论点。”

---
[待处理的学术论文片段]
近期研究表明，大规模语言模型（LLMs）在多种自然语言处理任务中展现出惊人的能力。然而，这些模型的可解释性仍然是一个重大挑战。本研究提出了一种新的基于注意力权重的可视化方法，用于分析LLM内部决策过程。我们评估了该方法在情感分析和命名实体识别任务上的有效性，结果显示，通过可视化注意力分布，可以部分揭示模型关注的输入部分，从而为模型行为提供一定的洞察。虽然该方法不能提供完全透明的解释，但它为理解LLM的“黑箱”迈出了有意义的一步，并为未来的可解释AI研究提供了方向。
```

#### 2. [初步思考 Prompt] (Thinking/Planning Prompt)

**构建要点：**
*   **要求显式思考：** 使用指令如“请先思考”、“请列出完成此任务的步骤”、“请分析输入数据的关键要素”。
*   **任务分解：** 要求LLM将复杂任务拆解成更小、更易处理的子任务。
*   **规划步骤：** 要求LLM规划执行任务的具体步骤和顺序。
*   **识别关键信息/约束：** 要求LLM在输入中识别并列出重要的信息、规则或限制。
*   **输出思考过程：** 要求LLM将其思考过程以结构化格式（如列表、思维链 Chain-of-Thought）输出，这有助于后续阶段的调试和理解。

**核心原则应用：** 消除LLM思考过程中的“黑箱”，使其规划过程可视化，从而提高其后续执行的可靠性。

**示例LLM输出 (O1 - 思考过程 & 初步结果):**

*(请注意，Prompt P1 已经包含了要求LLM先思考的要求，所以这个输出结合了思考过程和初步结果。如果您希望思考和结果是两个独立的步骤，可以在P1中只要求思考，然后在另一个Prompt P2中要求基于思考结果生成摘要。)*

```markdown
好的，在撰写摘要之前，我将先思考这段论文片段的核心论点。

**初步思考：**
1.  LLMs 能力强大但可解释性差。
2.  提出了一种新的注意力权重可视化方法。
3.  该方法可以部分揭示模型关注的信息，帮助理解模型行为。
4.  虽然不完美，但对理解LLM黑箱和未来研究有价值。

基于以上思考，我将撰写摘要。

**初步输出结果：**

大规模语言模型（LLMs）在多种任务中表现出色，但可解释性是其主要挑战。本研究提出并评估了一种用于分析LLM内部机制的注意力权重可视化新方法。结果显示，该方法通过展示模型关注的输入部分，能够为理解LLM决策过程提供有限但有意义的洞察，是迈向可解释AI的一步。
```

#### 3. [自我评估 Prompt（Self-Eval）]

**构建要点：**
*   **明确评估标准：** 提供清晰、具体的评估指标清单。这些标准应来源于[任务指令 Prompt]中设定的要求（例如：是否满足格式要求？是否包含了所有必要信息？是否存在逻辑错误？）。
*   **指定评估方式：** 要求LLM逐条对照标准进行评估，并给出评估结果（例如：使用“是/否”、“符合/不符合”、“评分”）。
*   **要求指出具体问题：** 如果发现不符合项，必须要求LLM明确指出具体是输出中的哪一部分存在问题。
*   **输出评估报告：** 要求LLM以结构化格式（如表格、列表）输出评估过程和结果。

**核心原则应用：** 将抽象的“好坏”判断转化为可执行的、基于标准的检查。精确指定评估对象和评估维度。

**示例Prompt (P2):**

```markdown
“请根据以下标准评估你刚刚生成的摘要：
1.  摘要是否简洁准确地概括了原文核心主题、方法和主要结论？
2.  摘要长度是否控制在150字以内？
3.  摘要语言是否清晰、流畅且符合学术规范？

请对每一项评估标准给出“符合”或“不符合”的判断，并简要说明理由。如果存在“不符合”项，请具体指出摘要中的问题所在。”
```

**示例LLM输出 (O2 - 自我评估报告):**

```markdown
好的，我将评估我生成的摘要。

**自我评估报告：**

1.  **概括核心内容（主题、方法、结论）：** 符合。摘要提到了LLM能力与挑战、提出的方法（注意力可视化）、评估方法（在任务上评估）以及方法的效果（提供洞察）。
2.  **长度控制（150字以内）：** 不符合。我的摘要长度是95字，远低于150字的上限，可能过于简洁，未能充分展开。
3.  **语言清晰、流畅、学术规范：** 符合。语言表达清晰，符合学术摘要的风格。

**评估总结：** 摘要在内容概括和语言风格上符合要求，但长度远未达到上限，可能可以包含更多关键细节以提升信息量。
```

#### 4. [元认知分析 Prompt（Meta-Reflect）]

**构建要点：**
*   **分析问题原因：** 要求LLM结合评估结果和之前的思考过程，分析为什么会出现这些问题（是指令理解偏差？信息遗漏？逻辑错误？）。
*   **反思执行过程：** 要求LLM反思它在[初步思考 Prompt]阶段的规划是否存在不足。
*   **总结经验教训：** 要求LLM提炼出可以避免类似错误的一般性经验或改进方向。
*   **建议总体策略调整（可选）：** 如果问题严重，可能需要LLM建议是否需要调整整体策略或方法。
*   **输出分析结论：** 要求LLM以结构化格式输出其分析和反思结论。

**核心原则应用：** 引导LLM对自身“思考”和“执行”过程进行深入剖析，识别根本原因，而非仅仅停留在表面错误。

**示例Prompt (P3):**

```markdown
“根据你刚刚的自我评估报告，你发现摘要长度远低于要求。请分析为什么会出现这种情况？是我的原始指令不够清晰，还是你在思考或生成时存在偏差？请反思你的思考过程，并提出未来避免类似问题的通用建议。”
```

**示例LLM输出 (O3 - 元认知分析):**

```markdown
好的，我将分析摘要长度不足的原因并进行反思。

**元认知分析：**

*   **问题分析：** 我在初步思考阶段正确识别了核心论点，但在撰写摘要时，可能过于追求“简洁”而忽略了“控制在150字以内”的上限要求，将其错误地理解成了“尽量简短”。我的思考过程侧重于提取最精炼的信息点，而没有明确规划如何将这些信息点扩展到接近要求的长度范围内。
*   **执行反思：** 在生成阶段，我应该在初稿完成后，回对照长度要求进行检查和调整，而不是仅凭感觉判断是否“简洁”。
*   **经验教训与改进方向：**
    *   未来在处理有明确长度（上限/下限）要求的任务时，应将长度要求作为硬性约束，并在生成后进行二次检查和必要的内容补充/删减。
    *   在初步思考阶段，除了提取核心点，还可以思考如何将这些核心点进行适当展开或关联，以满足可能的长度要求。
    *   可以考虑在生成Prompt中增加要求，例如“请先生成一个包含所有关键信息点的草稿，然后在此基础上扩展到接近150字”。

**结论：** 问题主要出在我的生成策略和对长度约束的执行不够严格，而非原始指令本身不清晰。
```

#### 5. [改进建议 Prompt（Refinement）]

**构建要点：**
*   **基于评估和分析：** 明确指出建议的依据是前两个阶段的评估结果和元认知分析结论。
*   **提出具体修改方案：** 要求LLM针对 identified problems 提出具体的、可执行的修改方案或建议。这可能包括：修改输出中的具体段落或数据、调整生成内容的风格或结构、填补遗漏的信息等。
*   **提供修改理由：** 要求LLM说明提出这些修改建议的理由。
*   **准备进行修改：** 可以选择在此阶段就让LLM直接进行修改，或者仅仅是输出修改建议清单。

**核心原则应用：** 将问题解决过程具体化，提供精确的修改指令或修改方案，确保改进有的放矢。

**示例Prompt (P4):**

```markdown
“根据你刚刚的评估和分析，你的摘要需要增加更多内容以接近150字的长度上限，同时保持简洁准确。请根据你的分析结论，修改你之前的摘要，补充适当的细节（例如，可以稍微展开讨论该方法的局限性、或其对未来研究的具体启示），使其长度在120-150字之间，并输出最终的摘要。”
```

**示例LLM输出 (O4 - 改进后的输出):**

```markdown
好的，我将根据我的评估和分析，修改之前的摘要，增加细节以达到建议的长度范围，同时保持准确性和简洁性。

**改进后的最终摘要：**

大规模语言模型（LLMs）虽在多种自然语言处理任务中展现卓越性能，其内在工作机制的不可解释性仍构成挑战。本研究提出并评估了一种基于注意力权重的创新可视化技术，旨在为理解LLM的内部决策流程提供工具。该方法在情感分析和命名实体识别任务上的应用验证了其有效性，通过可视化注意力分布，研究者可以初步揭示模型在处理特定输入时所关注的部分，从而对模型行为获得一定洞察。尽管此方法尚不能实现完全透明的解释，且存在一定的局限性，但它为探索LLM“黑箱”迈出了重要一步，并为未来推动可解释人工智能领域的研究提供了宝贵的思路和方向。
```

#### 6. [更新提示 / 策略 / 工具选择] (Post-Refinement)

**构建要点：**
*   **反思整个流程效率：** 回顾多阶段交互是否高效解决了问题。
*   **优化未来Prompt策略：** 根据本次成功的Prompt组合或失败的环节，调整后续任务的Prompt编写策略。
*   **考虑工具或模型选择：** 如果特定任务反复出现问题，可能需要考虑更换更适合的模型或引入外部工具协助（例如：需要精确计算时调用计算器工具）。
*   **积累Prompt模式：** 将本次成功的Prompt序列或关键指令提炼成可复用的模式。

**核心原则应用：** 从单次任务的视角提升到更宏观的Prompt工程和工作流优化。

**用户/系统反思示例：**

*   “这次通过自我评估和反思，模型成功意识到了长度不足的问题并进行了改进。未来对于有严格长度要求的任务，可以在Prompt中更强调长度是硬性约束，甚至要求模型在输出后**立刻**报告字数并进行检查。”
*   “这个多阶段流程对于需要精确控制输出质量的任务非常有效，值得针对特定任务（如摘要、代码生成、文本校对）创建相应的Prompt模板序列。”
*   “模型的元认知能力还需要进一步探索，它能识别原因并提出改进方法，这在一定程度上降低了用户手动调试的成本。”

### 高效LLM提示词的通用精确规范 (适用于所有阶段的Prompt)

不论在哪一阶段，构建Prompt时都应遵循以下通用规范：

1.  **语言明确直接：** 使用祈使句（“你要”、“必须”、“生成”）直接下达操作命令，清晰界定任务范围和行为边界。
2.  **结构化指令：** 使用编号列表、标题、Markdown格式（如代码块）等方式组织内容，将复杂的任务分解为多个清晰的步骤或要点。
3.  **精确指定输入/输出：** 明确说明处理哪些输入数据（是原始输入？还是上一阶段的输出？），严格规定当前阶段的输出格式、标签、属性、文件类型等具体要求。
4.  **量化约束：** 给出具体的数字限制、次数限制或比例要求（如：列出3个主要原因，改进建议不超过5条，生成长度在100-150字之间，列表不少于5项）。
5.  **明确禁止项：** 使用“禁止”、“不得”、“绝对不要”、“避免使用”等词语清晰列出不允许的操作、内容或风格。
6.  **提供操作细则：** 详细说明关键操作步骤、处理逻辑、判定标准或判断依据。
7.  **包含示例（可选但推荐）：** 提供具体的输入、处理逻辑示例或输出格式样例，帮助LLM理解复杂指令或抽象概念。示例是重要的教学工具。
8.  **定义边界条件和错误处理：** 说明在特定条件下应如何操作（如：如果输入为空，则返回特定提示；如果遇到歧义，则按默认规则处理或请求澄清）。
9.  **保持顺序和一致性：** 强调内容元素或操作步骤的顺序要求，以及风格、术语使用的一致性。

### 这篇规则文档的语言风格

本规则文档采用了一种结构化、指令性强且信息密集的语言风格，旨在清晰、系统地阐述构建LLM提示词的原则和方法，并将其应用于多阶段架构的语境中。语言正式、书面化，注重概念的精确定义和操作步骤的详细说明，通过示例具体化抽象规则。体现出一种设定标准、指导执行的权威口吻，适合作为内部规范或操作手册使用。
```

---
这份文档将您原有的笔记内容进行了细化，增加了“构建要点”下的详细说明，并在最后的“示例”部分提供了一个假设性的完整流程，从初始Prompt (P1) 到改进后的输出 (O4)，展示了每个阶段的Prompt和模拟的LLM输出，以及用户或系统的反思。请记住，示例中的LLM输出是为了说明规则和流程而构建的理想化输出，实际情况会根据模型能力和具体任务有所不同。