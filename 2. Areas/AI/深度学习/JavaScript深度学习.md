---
aliases: 
theme: moon
original: 
url: 
author: 
date_created: 2024-08-03 12:59
date_updated: 
type: 
priority: false
tags:
---

# 第一部分 动机和基本概念

## 第 1 章 深度学习和JavaScript

### 1.5 小结

机器学习要解决的核心问题是如何转换数据的表示，从而更好地解决当下的问题。
在机器学习中，神经网络可以通过连续的数学运算步骤（层）来转换数据的表示。深度学习领域涉及拥有一定“深度”的神经网络，也就是拥有很多层的神经网络。
2023/11/20 9:40

---

TensorFlow.js是一个全面、灵活且强大的JavaScript开源深度学习库，也是本书的重点。
2023/11/20 9:40

---

# 第二部分 深入浅出TensorFlow.js

## 第 2 章 TensorFlow.js入门：从简单的线性回归开始

预估等待时间本质上就是预测问题，而这正是TensorFlow.js的强项。TensorFlow.js可以根据使用场景和用户信息准确地预测下载任务所需时间，从而打造清晰可靠的体验，充分尊重用户的时间和注意力。
2023/11/20 9:42

---

但对深度学习从业者而言，深挖线性代数、微积分和高维数据空间统计虽然确有帮助，但实无必要，即使是构建复杂的高性能系统，情况也是如此。
2023/11/20 9:43

---

### 2.1 示例1：用TensorFlow.js预测下载任务所需时间

测试、运行和学习代码清单内容的最佳方法是下载本书随书代码，然后在本地进行试验。本书在编写过程中经常使用CodePen2，它可以用作简单、可分享的交互式代码仓库。
2023/11/20 9:44

---

当只有一个JavaScript文件时，CodePen非常好用，GitHub代码仓库中则提供了一些更大、结构更复杂的示例程序，
2023/11/20 9:45

---

@tensorflow/tfjs@latest
2023/11/20 9:45

---

指明了如何使用@latest后缀加载最新版的TensorFlow.js库4。
2023/11/20 9:46

---

例如，可以用tf.add()在TensorFlow.js中进行两个张量间的加法运算。
2023/11/20 9:46

---

本示例的目标是根据sizeMB来预测timeSec。
2023/11/20 9:47

---

输出通常又叫作目标（target），输入中的各种元素叫作特征（feature）。在本示例的40个样例中，每个样例都正好有一个特征（sizeMB）和一个数值目标（timeSec）。
2023/11/20 9:47

---

在开始实践之前，需要将这些数据转换成TensorFlow.js能支持的格式，那就是张量。
2023/11/20 9:48

---

但是如果想加强对TensorFlow.js API的理解，则可以阅读附录B。其中不仅包含像tf.tensor2d()这样创建张量的函数，还包含可以转换和组合张量的函数，以及如何将现实中常用的数据类型（如图像和视频等）打包成张量的常见设计模式。
2023/11/20 9:49

---

这里的形状意味着我们想将原数组理解为20个样本，每个样本都是1个数字。如果可以从数组的结构或其他位置明显推断出形状，则可以省略此参数
2023/11/20 9:50

---

维度数和每个维度的尺寸叫作张量的形状（shape）。
2023/11/20 9:50

---

在张量的语境下，维度通常又叫作轴（axis）
2023/11/20 9:51

---

在深度学习的语境下，将输入特征映射到输出目标上的函数叫作模型（model）。
2023/11/20 9:52

---

在深度学习中，模型还可以叫作网络（network），它们所指是一样的。我们的第一个模型将用线性回归（linear regression）来实现。
2023/11/20 9:52

---

在机器学习中，回归（regression）指模型会输出实数值，并且会尝试匹配训练集中的目标。这一点和分类（classification）是不一样的，后者输出的是从一系列选项中做出的选择。在回归任务中，模型输出的数字越接近目标数字，其性能就越优异。
2023/11/20 9:52

---

型有一个重要特性，那就是可调性（tunable）。这意味着可以调整输入到输出的计算。我们利用这一特性来调整模型，让它更“拟合”数据。
2023/11/20 9:53

---

神经网络的核心组成部分是层（layer），它是一个数据处理模块，可以看作张量之间的一个可调函数。
2023/11/20 9:53

---

从本质上讲，密集层就是执行每组输入与输出之间的可调的乘积累加（multiply-add）运算。
2023/11/20 9:53

---

：y = m * x + b。如图2-3所示，在密集层中，m叫作核（kernel），b叫作偏差（bias）
2023/11/20 9:53

---

由这些随机数值生成的文件下载所需时间的预测值不太理想，为了得到较好的预测值，必须让模型从数据中学习，自动为核与偏差寻找恰当的数值。这个寻找的过程就是训练过程（training process）。

核与偏差可以统称为权重，要为它们设定恰当的数值，需要下面两项内容。
2023/11/20 9:54

---

损失函数（loss function），即度量误差（error）的方法。
2023/11/20 9:54

---

优化器（optimizer），即模型基于数据和损失函数更新权重（核和偏差）所使用的算法。
2023/11/20 9:54

---

代码清单2-4中的sgd是随机梯度下降算法（stochastic gradient descent）的简称，2.2节会对它展开介绍。简单来说，此处会用微积分来计算如何调整权重从而减小损失。
2023/11/20 9:54

---

在深度学习领域，针对训练集的每一次完整迭代叫作一个轮次（epoch）。
2023/11/20 9:55

---

{epochs: 10}
2023/11/20 9:56

---

这里利用立即调用异步函数表达式（immediately invoked async function expression）。模式来等待fit()调用完成，然后继续后续操作。后续示例会在后台进行训练，而不是等其完成，前台线程可以同时执行其他命令。
2023/11/20 9:55

---

具体而言，就是将测试集和训练集分离，避免用测试集进行训练。
2023/11/20 9:56

---

也可以说，该模型的平均绝对误差（mean absolute error, MAE）刚好超过0.3。这个结果是好是坏呢？
2023/11/20 10:00

---

testData.timeSec.sub(0.295).abs().mean().print();

2023/11/20 10:00

---

看起来之前的模型是欠拟合（underfitting）的，也就是还不够适应训练集。
2023/11/20 10:02

---

过拟合问题更难以发现，它是指模型针对训练集调整过多，导致不能很好地将训练规则泛化到未曾见过的数据上的情况。
2023/11/20 10:01

---

model.predict(tf.tensor2d([[smallFileMB], [bigFileMB],
[hugeFileMB]])).print();
2023/11/20 10:04

---

可以看到，当下载大小为10 000MB的文件时，模型预测大约需要718秒。注意，训练集中没有任何接近这个大小的数据样例。一般而言，外推（extrapolate）远超出训练集范围的值是非常冒险的。但对这个简单示例而言，只要不涉及类似内存缓冲、I/O连接等复杂的问题，模型计算的结果还是相当准确的。当然，如果能收集更多这个文件大小范围内的数据就更好了。
2023/11/20 10:04

---

### 2.2 model.fit()内部原理剖析：示例1中的梯度下降算法

这里kernel（核）和bias（偏差）是密集层中的可调参数（统称权重），包含模型从训练集中习得的规则。
2023/11/20 10:06

---

最初，这些权重会初始化成很小的随机值，这步叫作随机初始化（random initialization）。
2023/11/20 10:06

---

损失平面是个碗形，其中最小也是最好的损失在{bias: 0.08, kernel: 0.07}附近，这和我们数据隐含的直线斜率和截距是吻合的：即使文件大小无限接近0，下载该文件也需要0.1秒，和损失平面中的最小偏差相近。模型的随机初始化会赋予可调参数随机值，这相当于在等高线图中随意选取了一个位置，该位置对应的损失即初始损失。接下来要根据反馈信号逐渐调整参数，这一逐渐调整的过程就是训练（training），也就是“机器学习”中的“学习”。
2023/11/20 10:07

---

但有一种更好的方法，那就是利用模型中所有运算是“可微”的这一特性，计算损失关于模型参数的梯度（gradient）。
2023/11/20 10:08

---

梯度就是一个修改权重的方向，在这个方向上，由于细微修改权重而导致损失增加的速率，会比其他任何方向上的修改所导致的损失增加的速率都大。
2023/11/20 10:08

---

首先，梯度是一个向量，它和权重包含同样数量的元素，代表由所有权重形成的空间中的一个方向。如果模型的权重和之前的示例一样，由两个数字组成，那么梯度就是一个二维向量。深度学习模型通常有上千甚至上百万个维度，同样，这些模型的梯度也拥有上千个甚至上百万个元素的向量（方向）。
其次，模型的梯度取决于当前权重。换言之，不同权重会导致不同的梯度。这一点在图2-5中非常明显，其中能够最快降低损失的方向取决于当前在损失平面上的位置。当处于损失平面的左边缘时，向右移动降低损失最快；当处于损失平面的底部时，向上移动降低损失最快，以此类推。
最后，从数学意义上来看，梯度是损失函数增加的方向。当然，训练神经网络旨在降低损失，这就是朝与梯度相反的方向改变权重的原因。
2023/11/20 10:09

---

这里最开始使用的是由默认学习率（default learning rate）决定的默认步长（step size）。但对于这些有限的数据，仅仅训练10个轮次并不能实现到达最优点，训练200个轮次则恰好合适。那么，如何选择学习率？如何判断模型是否已训练完成？本书后面会陆续介绍关于这些方面的一些有用的经验法则，但它们并不是“万灵药”。如果使用的学习率过小，就会导致每次的步长过小，从而无法在可接受时间内得到最优的参数。与此相反，如果使用的学习率过大，其对应的步长就会过大，可能导致完全跳过最小点，由此得到的损失可能会高于起始点。这可能会进一步导致模型的参数疯狂地在最佳点附近振荡，而不是直接快速获取它。图2-8展示了梯度步长过大的情况。在更极端的情况下，过大的学习率会导致参数值发散到无穷大，最终使权重变为NaN，即“非数字值”（not a number），这会完全毁掉你的模型。
2023/11/20 10:09

---

神经网络优化背后的微积分理论无疑非常有趣，可以让人了解这些算法背后的工作原理。但是，除了一些基本知识，其他更深入的理论对机器学习实践者而言并不是必要条件。这就好比TCP/IP，了解其复杂性固然是有益的，但对构建现代Web应用程序来说，这并不是必需的。
2023/11/20 10:11

---

用可滑动的单页应用演示反向传播算法原理。
2023/11/20 10:12

---

### 2.3 示例2：涉及多个输入特征的线性回归

第一个示例只使用了一个输入特征sizeMB来预测目标timeSec。但更为常见的场景是，问题涉及多个输入特征，并且事先不知道其中哪些预测能力最强，哪些只是和目标有松散的关联，这时要同时使用所有的特征，让算法自动分析出输入特征与目标的关联性。
2023/11/20 10:16


---

熟悉使用model.fit()回调函数，实现在训练中更新Web中的UI。
2023/11/20 10:17

---

数十年来，它一直被用作统计学入门与机器学习的标准数据集。
2023/11/20 10:17

---

可以把它想象为利用周边地区的可量化数据，计算某地区房地产价格的系统。
2023/11/20 10:19

---

GitHub平台提供了一个非常好的教程，在GitHub Docs界面搜索“Set up Git”即可浏览Git相关工具的使用方法。如果发现其中代码有任何错误，或者希望参与社区互动，欢迎使用GitHub中的pull request功能。
2023/11/20 10:20

---

对波士顿房价预测项目而言，负责更新UI元素的代码都在ui.js中，负责下载数据的代码都在data.js中，这两个文件都可以通过index.js中的import语句来引用。
2023/11/20 10:20

---

index.js：位于根目录的JavaScript文件，负责加载数据、定义模型并训练循环，以及更新UI元素。
2023/11/20 10:21

---

ui.js：将UI元素与行为绑定的UI事件监听器，并配置图表。
2023/11/20 10:21

---

normalization.js：数值计算的相关函数，比如从数据中减去数据均值的函数。
2023/11/20 10:21

---

可以从谷歌云平台地址免费获取以CSV格式存储的波士顿房价数据11。这些房价数据预先将样本随机分配为训练集和测试集，其中训练集约占三分之二，测试集部分单独放置，专门用于评估训练好的模型。此外，无论是训练集还是测试集，目标特征都已从其他特征中分离出来，划入了CSV文件。
2023/11/20 10:22

---

因此，波士顿房价项目在data.js文件中定义了名为BostonHousingDataset的类。该类封装了数据集的流操作，并提供了能够以数值矩阵形式获取原始数据的API。
2023/11/20 10:23

---

另一个选择是根据误差大小对它们进行加权，较大的误差对应较高的权重。也就是不再取绝对误差的均值，而是取误差平方的均值。
2023/11/20 10:32

---

正是因为这种对较大预测误差的敏感度，所以相比平均绝对误差，均方误差更容易受到样本中离群值（outlier）的影响。
2023/11/20 10:32

---

但是，如果你的应用程序本身对预测值中的离群值非常敏感，那么均方误差绝对是比平均绝对误差更好的选择。
2023/11/20 10:33

---

线性回归前的准备工作：数据标准化
2023/11/20 10:34

---

为了应对这一问题，需要先把数据标准化（normalize）。也就是说，对特征进行缩放（scale），使其平均值为0，标准差为单位标准差。这类标准化方法通常叫作标准变换（standard transformation）或z-score标准化（z-score normalization）。
2023/11/20 10:36

---

首先计算每个特征的平均值，然后从原始值中减去平均值，这样特征的平均值就变为0。随后，计算特征的标准差，将减去平均值后的特征值与标准差相除，就得到了标准化后的特征。
2023/11/20 10:37

---

(feature - mean(feature)) / std(feature)
2023/11/20 10:37

---

在波士顿房价预测示例中，标准化的代码划入了名为normalization.js的独立文件，
2023/11/20 10:46

---

按照惯例，第1个维度是样本维度，其中每个索引都对应独立且唯一的样本。第2个维度是特征维度，它的12个元素分别对应12个输入特征（如CRIM、ZN、INDUS等）。
2023/11/20 10:47

---

你就会发现data是形状为[333, 12]的二阶张量，而dataMean是形状为[12]的一阶张量。通常而言，两个不同形状的张量是不可能相减的。但是，这里TensorFlow使用了其广播机制（broadcast），通过重复第2个张量333遍，拓展了第2个张量的形状。结果就和我们使用时预期的一样，只不过不必明确写出来。这个易用的机制会为使用者带来很大的便利，
2023/11/20 10:48

---

(2) 较小张量会沿着新添加的轴进行自我复制，来匹配较大的张量的完整形状。
2023/11/20 10:49

---

无论怎样，这种将广播机制当作较小张量沿着新轴进行复制的想法，对于直观理解广播机制非常有帮助。
2023/11/20 10:49

---

截至TensorFlow 0.12.0版本，可用的回调触发事件如下：onTrainBegin、onTrainEnd、onEpochBegin、onEpochEnd、onBatchBegin和onBatchEnd。
2023/11/20 10:50

---

原始数据还会划分出另一个单独的数据集，即验证集（validation data）。验证集、训练集和测试集彼此独立，那验证集的用途是什么呢？机器学习工程师会评估模型在验证集上的性能，并根据评估结果调整模型的配置14，从而提高验证集的准确率。
2023/11/20 10:51

---

利用梯度下降算法拟合模型权重。
2023/11/20 10:51

---

选择模型架构和超参数。
2023/11/20 10:51

---

最终无偏见地评估模型性能。
2023/11/20 10:51

---

### 2.4 如何理解模型

与2.1.4节中学习的标量（scalar）线性函数不同，此处的特征与核都是向量（vector）。而上面公式中的“·”指内积运算（inner product），即将标量乘法泛化到向量上的运算。内积又名点积（dot product），是向量间对应元素乘积之和。
2023/11/20 10:52

---

运行波士顿房价预测模型后得到的5个绝对值靠前的特征权重，这里按绝对值大小进行排序。
2023/11/20 10:58

---

### 2.6 小结

梯度下降算法是深度学习背后的根本算法。它在概念上非常简单，就是指在可以改进模型拟合的方向上，不断小幅度更新模型的参数。
模型的损失平面描述了模型在不同参数组合下的拟合程度。由于参数空间是高维度的，因此计算损失平面通常并不现实。但是它非常直观，有助于理解机器学习的工作原理。
2023/11/20 11:00

---

## 第 3 章 添加非线性：升级加权和

### 3.1 非线性的定义及其优势

该模型是一个双层的网络。第一层是拥有50个单元（神经元）的密集层，使用自定义的激活函数和核初始化器（initializer），参见3.1.2节。该层是一个隐藏层（hidden layer），其输出在模型外是不可见的。第二层是使用默认激活函数（线性激活函数）的密集层，其结构与第2章使用的纯线性模型完全相同。该层是一个输出层，其输出就是模型的最终输出，也是模型predict()方法的返回值。注意，这里模型在代码中对应的函数名称为多层感知机（multilayer perceptron, MLP）。用这个术语描述的神经网络通常具有两个特征：第一，它有一个简单的无环拓扑结构，也就是说它属于前馈神经网络（feedforward neural network）；第二，它至少有一个隐藏层。本章将介绍的所有模型都满足这两点。
2023/11/20 11:01

---

sigmoid函数是一种“挤压式”的非线性，可以将所有实数（负无穷至正无穷）“挤压”到一个小得多的范围（这里是0.0～1.0）
2023/11/20 11:02

---

index.js中的multiLayerPerceptronRegressionModel2Hidden()函数可以实现这一点，这个函数对应的是界面中名为“Train Neural Network Regressor (2 Hidden Layers)”的按钮。
2023/11/20 11:03

---

也就是说，通过添加非线性的隐藏层，我们再一次成功地提升了模型的预测准确率，并且扩展了它的容量。
2023/11/20 11:04

---

像单元数量、核初始化器以及激活函数这样的参数都属于模型的超参数（hyperparameter）。“超参数”标志着这些参数和模型的权重参数是截然不同的，权重参数是在训练时通过反向传播实现自动更新，即通过model.fit()调用。
2023/11/20 11:05

---

### 3.2 输出端的非线性：分类任务的模型

二元交叉熵（binary crossentropy）
2023/11/20 11:06

---

下面这一对度量指标尝试捕捉准确率未能反映的数据细节，即精确率（precision）和召回率（recall）。在下面的讨论中，正例指那些仍须执行额外行为的事情，比如链接是否高亮，或帖子是否标记为需要人工审核。负例指无须执行任何行为。这些度量指标主要侧重于从不同视角评估模型在预测中可能出现的不同类型的“错”。
2023/11/20 11:07

---

精确率度量的是模型中真正例占预测正例的比例：
2023/11/20 11:07

---

召回率是模型中真正例占所有正例的比例：
2023/11/20 11:07

---

### 3.3 多分类问题

这里用于诠释多分类问题的是源自统计领域的著名数据集——鸢尾花数据集（iris-flower dataset），该数据集主要介绍鸢尾属下的3种亚属，分别是山鸢尾（iris setosa）、变色鸢尾（iris versicolor）和弗吉尼亚鸢尾（iris virginica）。这3种亚属可以通过形状和大小来区分。在20世纪初，英国统计学家Ronald Fisher收集了150朵鸢尾花的样本，并测量了它们的花瓣和萼片的长度与宽度。这3种亚属的样本数量相同，每个目标标签都正好有50个样本。
2023/11/20 11:09

---

最后一层使用的激活函数是归一化指数函数，即softmax函数，它是专门为多分类问题而设计的。
2023/11/20 11:11

---

图3-9的底部展示了另一种描绘多分类器性能特征的方式，那就是多分类器的混淆矩阵（confusion matrix）。
2023/11/20 11:12

---

## 第 4 章 用convnet识别图像和音频

convnet（卷积神经网络）的概念、工作原理及其适用于涉及图像数据的机器学习任务的原因。
2023/11/20 11:14

---

### 4.3 告别浏览器：用Node.js更快地训练模型

Node.js版TensorFlow.js（下文简称为tfjs-node）在CPU模式下会直接使用C++编写的多线程数学运算方法，这些运算方法和主打的Python版TensorFlow所使用的是相同的。如果你的计算机安装了一个启用CUDA的GPU，tfjs-node还可以使用CUDA编写的、GPU加速的核函数进行数学运算，从而进一步提升运算速度。
2023/11/20 11:16

---

训练模型是费时费力的事情，它既会耗费CPU和GPU的算力，也会耗费一定的时间。因此，训练成功后应该保存训练的成果。如果不保存模型，下次运行main.js时，就得从头开始训练模型。本节会展示如何在训练完成后保存模型，并将保存好的模型作为文件导出到硬盘上。导出的模型文件叫作检查点（checkpoint）或制品（artifact）。之后我们还会展示如何在浏览器中导入检查点，重组模型，然后将其用于推断。main.js中main()函数的最后部分包含下面的模型保存代码（见代码清单4-7）。
2023/11/20 11:17

---

### 4.4 口语单词识别：对音频数据使用convnet

现代Web浏览器可以使用WebAudio API。它们能够和声卡通信，为Web应用程序提供实时的、数字化的音频信号（经过用户授权）。因此，从JavaScript程序员的角度来看，音频数据可以看作由实数组成的一些数组。在深度学习中，这样的数组通常会表示为一维张量。
2023/11/20 11:18

---

## 第 5 章 迁移学习：复用预训练的神经网络

什么是迁移学习；为何对于很多问题而言，它比从头训练模型要好。
2023/11/20 11:19

---

幸运的是，有一种叫作迁移学习（transfer learning）的技巧，能帮助解决这类问题。
2023/11/20 11:19

---

### 5.1 迁移学习简介：复用预训练模型

这意味着训练可以在搭载TensorFlow.js的边缘设备（edge device）上进行，比如笔记本计算机或手机
2023/11/20 11:20

---

### 5.2 通过对convnet进行迁移学习实现目标检测

一个高级目标识别模型的示例是TensorFlow.js版的单发多框检测模型。注意，图中标出的多个边框，以及它们对应的目标类别和预测置信度
2023/11/20 11:25

---

最著名的目标检测模型包括单发多框检测（Single-Shot Detection, SSD）模型a，以及YOLO（You Only Look Once）模型。
2023/11/20 11:25

---

# 第三部分 TensorFlow.js高级深度学习

第9~11章将通过实战带你遍览深度学习的三个高级领域：面向序列的模型、生成式模型和强化学习。
2023/11/20 11:26

---

## 第 6 章 处理数据

### 6.1 用tf.data管理数据

对于机器学习工程师而言，获取并操作大量的数据是一个关键技能。
2023/11/20 11:26

---

通常，开发者会用高阶API获取数据集底层存储的数据。
2023/11/20 11:27

---

第二种从数据集对象读取数据的方法是使用dataset.forEachAsync(f)对数据集中的每个样例执行一个函数。forEachAsync()的使用方式与JavaScript中数组和集合的forEach()方法的使用方式（即JavaScript原生的Array.forEach()和Set.forEach()）类似，它们的参数都是一个函数，该函数将逐个作用于数据中的每个元素。
2023/11/20 12:19

---

需要特别注意的一点是，Dataset.forEachAsync()和Dataset.toArray()都是异步函数。这点和Array.forEach()不同，因为后者是同步的。因此，这也是很容易犯错的一个地方。Dataset.toArray()返回的是一个promise对象，因此如果想用接近同步的方式处理它的话，需要对其使用await或者.then()。如果忘记使用await，那么promise不一定会按你预期的顺序生成结果，这就成了bug的潜在来源。一个常见的bug是，在promise还未得出结果、但数据集已经遍历完成时读取返回的结果，此时会错误地以为数据集是空的。
2023/11/20 12:20

---

Dataset.forEachAsync()和Array.forEach()之所以一个是异步的、一个是同步的，是因为数据集中的数据通常是从一个远程数据源创建、计算或下载得到的。此处使用异步可以使我们高效地利用等待数据生成的时间进行计算。
2023/11/20 12:20

---

比如，原始数据通常包含很多多余的元素，使用数据前需要先过滤这些元素。有时，数据中的部分属性需要进行预处理、序列化或重命名。或者，原始数据中的元素可能是有序排列的，因此必须先将其顺序打乱，才能将它们用于模型训练和评估。再者，还需要将数据集划分为彼此不重叠的训练集和测试集。正如你所见，数据预处理几乎是不可避免的。如果你手头的数据集已经无须数据清洗并且是可开箱即用的，那么一定是有人提前帮你做过数据清洗和预处理！
2023/11/20 12:21

---

谓词函数
2023/11/20 12:23

谓词函数（Predicate Function）是一种返回布尔值的函数，其目的是评估输入值是否符合特定的条件。谓词函数通常用于过滤、筛选或测试集合中的元素。在编程中，谓词函数是一种常见的函数类型，特别在函数式编程范式中经常使用。

谓词函数的特点包括：

1. **返回布尔值：** 谓词函数始终返回 true 或 false，表示输入值是否满足特定条件。

2. **用于过滤：** 谓词函数通常用于过滤数据集合，例如数组、列表或对象。通过谓词函数，可以保留或排除集合中的元素。

3. **无副作用：** 谓词函数通常应该是无副作用的，即其执行不应该改变系统状态或引起其他意外行为。

下面是一个简单的 JavaScript 谓词函数的例子：

```javascript
// 谓词函数，检查数字是否为偶数
function isEven(number) {
  return number % 2 === 0;
}

// 使用谓词函数过滤数组
const numbers = [1, 2, 3, 4, 5, 6];
const evenNumbers = numbers.filter(isEven);

console.log(evenNumbers); // 输出 [2, 4, 6]
```

在这个例子中，`isEven` 函数是一个谓词函数，用于检查数字是否为偶数。然后，通过数组的 `filter` 方法使用这个谓词函数过滤出了数组中的偶数。

---

非常重要的一点是，无论是划分训练集还是测试集，改变原数据排序的方式是相同的。这是为了确保两个数据集中的样例没有重叠。也正因为如此，两个数据集的划分采用了相同的随机种子。
2023/11/20 12:24

---

用tf.data.map()标准化流式数据
2023/11/20 12:24

---

### 6.2 用model.fitDataset训练模型

tf.data的流数据处理API确实非常好用。我们也见证了如何用它优雅地处理数据。但tf.data API的主要目的是简化训练和评估时对模型的数据配置。tf.data在这方面又能提供哪些便利呢？
2023/11/20 12:25

---

每当需要训练模型时，我们的首选都是model.fit() API。正如之前所说的，model.fit()有两个必填的参数——xs和ys。xs变量必须是表示输入样例集合的张量。ys变量也必须是张量，它表示与输入样例对应的输出目标。
2023/11/20 12:25

---

### 6.3 获取数据的常见模式

截至2019年1月，组织数据科学和机器学习竞赛的网站Kaggle已拥有13 971个公有数据集，其中2/3使用的是CSV格式。
2023/11/20 12:28

---

注意，如果你选择后者，记得在CSV所在的服务器为CSV启用CORS访问权限
2023/11/20 12:28

---

最后一个注意事项：处理网络摄像头数据时，在用数据流做预测前，最好先获取、处理并垃圾回收原图像数据。这么做有以下两个原因。首先，将图像的张量数据先传入模型，可以保证模型的权重已加载到GPU的显存，从而避免模型启动时的卡顿。其次，这能给摄像头硬件一些时间预热，从而尽早开始生成真正可用的图像。根据硬件的不同，有的摄像头在启动时会生成一些空白的图像。代码清单6-18展示了《吃豆人》示例程序是如何做到这一点的（代码摘自webcam-transfer-learning/index.js）
2023/11/20 12:30

---

### 6.4 处理有缺陷的数据

一般而言，你应该花时间确保数据和你预期的是一致的。这方面有很多有用的工具，包括Observable、Jupyter、Kaggle Kernel和Colab这样的互动笔记型工具，以及像Facets这样的有可视化界面的工具。
2023/11/20 12:31

---

### 6.5 数据增强

像这样通过用程序人工改变原样例而生成的样例一般叫作伪样例。向数据集添加伪样例的过程叫作数据增强（data augmentation）。
2023/11/20 12:32

---

随机进行数据增强生成的猫的图像。通过随机选择旋转、反射、平移和偏斜程度，单个有标签样例可以生成一系列新的训练样例
2023/11/20 12:33

---

注意，增强算法会应用于每个样例。需要注意的另一点是，不应该将它用于验证集或测试集。如果对测试集也进行增强，那么对模型的评估是有偏差的，因为推断阶段的输入的数据是没有增强的。
2023/11/20 12:33

---

### 6.7 小结

数据是推动深度学习革命的关键力量。如果无法获取大量、规整的数据，大多数深度学习应用就无法实现。
2023/11/20 12:34

---

## 第 7 章 可视化数据和模型

通过第6章的学习，你已经知道在建立机器学习模型前可视化并理解数据的好处。我们已经介绍过如何用Facets这个基于浏览器的工具，以快速、可互动的方式观察手头的数据。本章中将介绍一个名为tfjs-vis的新工具。你可以用它编写代码，并以自定义的方式可视化数据。和直接观察原始数据或用Facets这类拆箱即用的工具相比，使用它有些额外的好处：使可视化流程更灵活多变，并帮助我们更深入地理解数据。
2023/11/20 12:35

---

### 7.1 数据可视化

热图是一种将二维数组展示为由彩色单元格组成的网格的图。每个单元格的颜色表示它所对应的数组元素的大小。作为一个惯例，一般会用蓝色和绿色这样“较冷”的颜色表示较小的值，用橙色和红色这样“较暖”的颜色表示较大的值。“热图”的名字正是出自于此。深度学习中最常见的热图可能要数混淆矩阵（参见第3章的鸢尾花分类示例）和注意力矩阵（参见第9章的数据转换示例）。tfjs-vis的tfvis.render.heatmap()函数专用于绘制这类图。
2023/11/20 12:35

---

作为可视化设计师，应该用高效的方式将数据中最相关且最有价值的部分展现出来。
2023/11/20 12:36

---

对于大于一周的时间跨度，在制图前，我们先降采样（downsample）时间序列。例如，假设用户选中的时间跨度为“Month”（即30天）。那么，该范围内的原数据量为30 × 24 × 6 = 4320个数据点。如代码清单7-7所示，在绘制以月为跨度的数据时，程序每6个数据点才会采集一个数据。这把需要绘制的数据量降到了720个。相较于原数据量，这极大地减少了渲染的开销。但是对于人眼而言，减少至原来1/6的数据量不会有任何影响。
2023/11/20 12:37

---

这是因为绘制图前勾选了UI中的“Normalize Data”多选框。在第2章讨论波士顿房价预测模型时，我们简要地提过标准化这一概念。第2章标准化的方法是从数据中减去均值，然后将它们除以标准差。这是为了改进模型的训练。此处使用的标准化方法和之前完全相同。然而，它并不仅是为了提升天气预测模型（下一节中将讲解模型相关的内容）的准确率，同时还为了方便可视化。为何这对可视化有益呢？如果在绘制气温和气压的图时，试着取消选择“Normalize Data”多选框，你就知道为何有必要这么做了。气温数据的数值范围是-10～40（摄氏度），而气压的数值范围则是980～1000。如果不经过标准化就将它们放在同一个坐标系中，那么两种相差甚大的值中较大的部分会驱使轴坐标值扩展到一个非常大的范围。结果，两个曲线看上去都会是扁平且没什么变化的。标准化通过将所有样本映射到一个均值为零、标准差为1的分布上避免了这种问题。
2023/11/20 12:38

---

即气温上升时，大气密度就会下降。
2023/11/20 12:38

---

### 7.2 可视化训练后的模型

因此，深度神经网络相当于一个信息提纯的流水线（information distillation pipeline）。原始数据会被源源不断地输入流水线中，流水线则会不断地转换数据，剔除数据中和当前任务无关的部分，放大并逐步完善有助于当前任务的部分。
2023/11/20 12:39

---

## 第 8 章 欠拟合、过拟合，以及机器学习的通用流程

么做的最主要目的是及时发现欠拟合（underfitting）和过拟合（overfitting）
2023/11/20 12:39

---

### 8.2 欠拟合、过拟合，以及应对措施

训练机器学习模型的过程中，我们通常希望监控模型是否如预期般捕捉到数据集中的模式。如果模型不能很好地捕捉数据中的模式，那么就称该现象为欠拟合（underfit）；反之，如果模型过度学习这些模式，以至于它不能将所学到规则的泛化到新数据上，那么就称该现象为过拟合（overfit）。当模型出现过拟合时，可以通过正则化（regularization）这样的应对措施将其拉回正轨。
2023/11/20 12:40

---

最终，训练集和验证集的损失都在0.9左右振荡，用绝对温度表示为8.476 × 0.9 ≈ 7.6摄氏度（之前介绍过，8.476是CSV文件中气温列的标准差）。也就是说，训练后的线性回归模型的平均预测误差是7.6摄氏度（或为13.7华氏度）。很明显，这个模型预测水平非常糟糕，它提供的气象预测也是不可信的。这就是欠拟合。
2023/11/20 12:41

---

然而，模型能力的增强会带来一个副作用：它会使模型对训练集的拟合能力远超出对验证集的拟合能力，而后者包含模型训练时未曾见过的数据。这个现象就是过拟合。
2023/11/20 12:42

---

该函数的第二个参数，即tf.regularizers.l2()的返回值，叫作L2正则化器（L2 regularizer）。如果将上面的代码和代码清单8-3中的buildMLPModel()函数结合起来看，你会发现，L2正则化器会被传入隐藏密集层的配置对象的kernelRegularizer属性。这会将L2正则化器绑定到密集层的核上。如果一个权重（例如密集层的核）绑定了正则化器，那么就可以说该权重被正则化了。与此类似，如果模型的部分或全部权重被正则化了，那么就可以说该模型被正则化了。
2023/11/20 12:42

---

但是，为什么核值减小能缓解过拟合并增强模型的泛化能力呢？可以借助奥卡姆剃刀原理（Occam's razor principle）来直观地理解这一点。这是因为L2正则化所实现的正是这一原理的体现。一般而言，当权重参数的值较大时，模型会倾向于拟合输入特征中的细节。而当权重参数的值较小时，模型则会忽略这些细节。在极端情况下，核值可能为零；也就是说，模型会完全无视对应的输入特征。L2正则化会鼓励模型更“功利”地去学习数据集。它会使模型尽可能避免较大的权重值，除非使用较大的值可以带来更大的回报（即目标和预测间误差的减少比正则化器的损失带来的好处更多）。
2023/11/20 12:42

---

我们提供了一个示意图，用于快速辨别训练中是否存在这些现象（见图8-6）。如图8-6a所示，只要模型的损失值不是很理想（比预期值高），无论是在训练集上还是验证集上，那么都是欠拟合。图8-6b展示了过拟合的典型模式。如图所示，尽管训练集上的性能看起来相当不错（损失值很低），但是验证集的损失值相对来说不尽如人意（很高）。尽管训练集损失看起来有继续下降的趋势，但是验证集损失已经停止下降并有升高的倾向
2023/11/20 12:45

---

将来可能会涌现新的、能更好解决这些问题的模型。它们可达到的损失值可能比图8-6c中所展示的还低。如果真的是这样，那么图8-6c对应的模型就可以看作欠拟合。我们需要使用新模型类型来应对这种欠拟合，并且再次用正则化来应对新训练周期中可能出现的过拟合。
2023/11/20 12:45

---

### 8.3 机器学习的通用流程

一类值得特别注意的不可解决的问题是非平稳（nonstationary）环境中的概念漂移（concept drift）问题，在这类问题中，输入和输出关系会随时间改变。假设你的目标是构建一个针对服装的推荐引擎。输入是用户的购物历史，并且仅有一年的数据。此处的关键问题是，人们的着装偏好会随着时间而改变。去年还在验证集上表现出优异性能的模型，可能今天就无法达到同样的水准。记住，机器学习只能学习数据集中存在的模式。一个可行的解决方案是，不断获取最新的数据，并以此训练新的模型。
2023/11/20 12:46

---

张量中的值应该缩放到较小且居中的范围，例如在[-1, 1]或[0, 1]区间中。
如果不同特征（例如气温和风速）的取值范围不同（异质数据），那么一定要先将数据标准化。一般会通过z分数标准化算法将每个特征变为均值为0、标准差为1。
得到输入数据和目标（输出）数据的张量表示后，就可以开始开发模型了。
2023/11/20 12:46

---

添加更多层；
增加每层的尺寸；
使用更多的训练轮次。
2023/11/20 12:46

---

## 第 9 章 针对序列和文本的深度学习

### 9.2 构建针对文本的深度学习模型

什么是词嵌入（word embedding）？就和one-hot编码一样（见图9-6），词嵌入是一种将单词表示为向量的方法（即TensorFlow.js中的一维张量）。然而与之前不同的是，在词嵌入方法中，向量元素的值可以通过训练得到，而不是必须按照某种死板的规则（例如one-hot编码中单词到索引的映射关系）进行硬编码。换言之，针对文本设计的神经网络使用词嵌入时，词嵌入向量会成为模型中可训练的权重参数。它们在反向传播中的更新规则就和模型中其他的权重参数一样。
2023/11/20 12:48

---

图9-8　一维卷积（tf.layers.conv1d()）工作原理的示意图。为了简化示意图，此处只在示意图的左侧展示了一个输入样例。假设输入序列的长度为12，conv1d层的卷积核尺寸为5。那么对于每个滑动位置，算法会从输入序列中提取一个长度为5的切片。随后，该切片会和conv1d层的卷积核进行点乘，得到输出序列的一个切片。对于每一个可选的滑动位置，都会执行上述运算，最后获得的结果就是完整的输出序列（即示意图右侧展示的结果）
2023/11/20 12:53

---

如何截断和填充序列。为何需要截断（truncation）和填充（padding）这两个操作呢？这是因为TensorFlow.js模型要求fit()的参数是一个张量，而张量必须有具体的形状。因此，尽管影评的长度不是固定的（短的仅有10个单词，长的多达2400个单词），但是我们必须选择一个特定的长度（maxLen）作为输入特征张量的第二个维度，从而得到一个形状为[numExamples, maxLen]的张量。
2023/11/20 12:56

---

由于词嵌入是针对文本的深度神经网络的重要组成部分，研究者已经为机器学习从业者预训练了很多开箱即用的词嵌入向量。得益于此，我们不必再像本示例中所做的那样，训练自己的词嵌入向量。GloVe（Global Vectors的缩写）是最著名的预训练词向量之一。它由斯坦福自然语言处理研究组（Stanford Natural Language Processing Group）提供。
2023/11/20 12:58

---

### 9.3 采用注意力机制的序列到序列任务

文本摘要：为一篇长达上万字的文章生成一个简短（比如100字以内）的梗概。
2023/11/20 12:58

---

预测文本的后续内容：通过句子的前几个单词预测后续的内容。这对于邮件应用程序和搜索引擎UI的自动完成和智能推荐功能非常有用。
2023/11/20 12:58

---

事实上，模型有两个输入，而不是一个。如图9-10所示，可以将模型大致分为两个部分：编码器（encoder）和解码器（decoder）。模型的第一个输入会进入编码器部分。它是输入的日期字符串本身，表示为字符索引组成的序列，其形状为[numExamples, INPUT_LENGTH]。其中INPUT_LENGTH是模型支持的输入日期格式中的最大长度（本示例中为12）。如果实际输入小于该长度，那么会在输入的最后填充零。第二个输入会传入模型的解码器部分。它是将转换结果右移一个采样点后的张量，其形状为[numExamples, OUTPUT_LENGTH]。
2023/11/20 12:59

---

大脑会尝试做两件事情：一是具象化概念本身，二是回忆至今所说过的话。后者对于确保发言的自洽、完整和不重复至关重要。
2023/11/20 13:00

---

模型的工作原理也是如此：为了生成输出中每个字符，它必须使用两个来源的信息：一个是输入的日期字符串，一个是至此已生成的输出字符。
2023/11/20 13:00

---

### 9.4 延展阅读

在日期转换的样例中，我们曾介绍过一种基于argMax()的解码技巧。这种技巧通常叫作贪心解码（greedy decoding）算法，因为它在每个处理步骤提取出的都是概率最高的符号。另一种流行的技巧是集束搜索（beam-search）解码算法。这种算法会在更大的搜索范围内观察可能的输出序列，由此来决定最佳的输出字符。该算法的具体内容请参考Jason Brownlee的文章“How to Implement a Beam Search Decoder for Natural Language Processing”。
2023/11/20 13:01

---

## 第 10 章 生成式深度学习

生成以假乱真的图像、音频和文本是深度神经网络最令人印象深刻的一些应用。当下，深度神经网络已经能够创建一些非常逼真的人脸图像1、合成听起来自然流畅的语音2，以及编写令人信服且自洽的文本3。这还只是它众多成果中的一小部分。这样的生成式模型（generative model）有很多用途，包括辅助艺术创作、基于一定条件修改现有的内容，以及增强现有的数据集来支持其他深度学习任务。4
2023/11/20 13:02

---

### 10.1 用LSTM生成文本

果你有一个启用了CUDA的GPU，那么可以给命令加上--gpu选项，这样训练就会在GPU上进行，从而进一步提升训练速度。--lstmLayerSize选项的作用就相当于Web界面中用于填写LSTM层尺寸的文本框。上面的命令会创建一个堆叠两个层的LSTM层模型，每个LSTM层各有128个单元。
2023/11/20 13:03

---

混沌值就是这样调控生成文本的随机性的。混沌值背后的英文术语“temperature”来自热力学。因为在热力学中，系统的温度（temperature）越高，其内部就越混沌。对于本示例而言，这是个很恰当的类比，因为随着我们增加代码中的“温度”，最后得到的文本确实也更为混沌。混沌值的大小有个“绝佳的平衡点”。低于这个平衡点，生成的文本看起来重复又机械；高于这个平衡点，生成的文本又过于不可测和怪异。
2023/11/20 13:03

---

### 10.2 变分自编码器：找到图像的高效、结构化表示

本征向量所处的向量空间叫作本征空间（latent space）或者z空间（z-space）。
2023/11/20 13:04

---

高斯分布（Gaussian distribution）有两个参数：均值和方差（或与此等效的标准差）。
2023/11/20 13:04

---

### 10.3 用GAN生成图像

除了“凭空”生成令人叹服的逼真图像外，GAN生成的图像还可以通过某些输入数据和参数进行调节。这样一来就催生了各种针对不同任务的实用应用。例如，GAN可以从低分辨率的输入图像生成高分辨率图像（图像超分辨率重构）、填补图像中缺失的部分（图像修复）、将黑白图像转换成彩色的（图像着色），以及根据人的某个姿势的图像生成同一个人的另一个姿势的图像。此外，还有些新研发出的GAN模型可以生成非图像数据，例如音乐。19能够生成无限多的逼真的素材，对于绘画、音乐和游戏设计等领域有巨大的价值，但GAN的应用范围不止于此。它还可以在很难获得训练样例的场景中，通过生成训练样例来辅助深度学习。例如，在训练自动驾驶的神经网络的场景中，可以用GAN来生成逼真的街景。
2023/11/20 13:06

---

辅助分类器生成式对抗网络（auxiliary classifier generative adversary network, ACGAN）21。由此训练得到的模型可以生成以假乱真的、MNIST风格的数字图像。与此同时，得益于ACGAN采用的辅助分类器（auxiliary classifier），我们还可以控制每个生成的图像的类别（0～9，共10种类别）
2023/11/20 13:06

---

GAN是如何做到生成逼真的图像的呢？这是通过模型两个部分的相互作用实现的，这两个部分分别是生成器（generator）和判别器（discriminator）。可以将生成器看作造假者，它的目标是创造毕加索画作的以假乱真的赝品；将判别器看作鉴定专家，它的职责是辨别眼前的作品是不是赝品。造假者（生成器）会为了骗过鉴定专家（判别器）而不断创造越来越逼真的赝品，而鉴定专家也会不断提升自己的鉴别能力，从而避免被骗。这两个部分的对立，正是GAN模型的名字中“对抗”（adversarial）部分的由来。值得玩味的是，正是造假者和鉴定专家之间对抗，促使这两个部分的能力都得到了提升，尽管它们在设计上是对立的。
2023/11/20 13:07

---

生成器会使用conv2dTranspose层转换图像张量，而不是使用熟悉的conv2d层。可以将conv2dTranspose粗略地看作conv2d的逆运算。它有时也被叫作反卷积（deconvolution）。
2023/11/20 13:07

---

这些GAN模型的损失曲线有一个独有的特征，即它们并不像其他类型神经网络的损失曲线一样是呈单调下降趋势的。相反，判别器（图中的dLoss）和生成器（图中的gLoss）的损失曲线并不是单调上升或下降的，而是在变化中维持着一种错综复杂的关系。
2023/11/20 13:08

---

### 10.6 小结

生成式模型和本书之前介绍的判别式模型有所不同。它们的设计目标是对训练集中样例的生成方式和统计分布进行建模。因此，它们可以生成符合真实样例分布的人造样例。
2023/11/20 13:08

---

## 第 11 章 深度强化学习的基本原理

在本章之前，本书都聚焦于同一种机器学习类型，即监督式学习。在监督式学习中，训练好的模型会根据输入信息输出正确的答案。无论是预测输入图像的类别标签（参见第4章），还是根据过去的气象数据预测未来的气温（参见第8章和第9章），使用的都是同一个范式：将静态的输入映射到静态的输出。第9章和第10章中介绍的序列生成模型要稍微复杂些，因为它们输出的是一个序列，而不是单个数值或类别。但是，如果将序列拆分成更小的部分，那还是可以将这些问题变成单输入到单输出的映射。
2023/11/20 13:09

---

本章将聚焦于另一种机器学习类型：强化学习（reinforcement learning，RL）。RL的主要目标并不是输出静态的数据，而是通过训练模型（在RL领域中叫作智能体，即agent），使其能在特定环境中执行某些行为，从而最大化一种叫作奖励（reward）的度量任务成功程度的指标。
2023/11/20 13:09

---

同时，深度学习革命中一些最令人惊叹的发展都结合了深度学习和RL的威力，这包括能够以超人类技巧通关雅达利游戏的人工智能玩家，以及能够在围棋和国际象棋赛场上击败人类世界冠军的下棋算法。1
2023/11/20 13:09

---

### 11.1 定义强化学习问题

行为
2023/11/20 13:10

---

奖励
2023/11/20 13:10

---

观察（observation）
2023/11/20 13:11

---

### 11.2 策略网络和策略梯度：平衡倒立摆示例

就不得不谈谈RL领域中一个经典且重要的话题，即权衡探索（exploration）和利用（exploitation）。探索指随机的尝试，也是智能体发现好的行为决策的前提条件。利用指做出智能体已知的最优决策，从而最大化奖励。这两者是不可兼得的，因此找到它们之间的平衡对于设计有效的RL算法而言是至关重要的。在训练的初期，我们会希望在较大的范围内探索可能的策略，不过一旦找到了一些较好的策略，就应该缩小范围，基于这些较好的策略进行微调。因此，在很多算法中，探索的力度一般会随着训练的深入逐渐缩小。在平衡倒立摆问题中，tf.multinomial()这个采样函数已经潜在包含了探索的要素。这是因为随着训练的深入，模型对决策的信心指数会逐渐上升，tf.multinomial()输出的结果也会变得越来越确定。
2023/11/20 13:12

---

返回的梯度值会告诉策略网络应该如何改变权重，才能让以后做出的决策更接近实际做出的决策。这些梯度值和从训练回合中得到的奖励共同组成了RL方法的基础。这就是为何这个方法会被划入RL领域里叫作策略梯度（policy gradient）的子领域中。
2023/11/20 13:13

---

### 11.3 价值网络和Q学习：《贪吃蛇》游戏示例

这种复杂的奖励结构和稀疏的分布是策略梯度和REINFORCE方法不适用于贪吃蛇问题的主要原因。策略梯度方法更适用于奖励高频发生且结构简单的场景，例如平衡倒立摆问题。
2023/11/20 13:15

---

# 第四部分 总结与结语

## 第 12 章 模型的测试、优化和部署

机器学习和传统的软件工程有一个关键区别，即它会自主探索任务的规则和经验法则。
2023/11/20 13:18

---

### 12.1 测试TensorFlow.js模型

有些部分适用传统的单元测试方法，例如创建和训练模型的代码，以及对模型的输入和输出进行预处理和后期处理的代码。其他部分则需要为机器学习量身定制测试和监测方法。这些部分包括保障数据质量的样例校验代码、监测模型训练后的体积和推断速度的代码，以及针对模型训练后的预测结果的细粒度的校验代码和评估代码
2023/11/20 13:19

---

expect(model.inputs.length).toEqual(1);     ←---- (本行及以下3行) 断言模型的输入形状和输出形状符合预期
expect(model.inputs[0].shape).toEqual([null, maxLen]);
expect(model.outputs.length).toEqual(1);
expect(model.outputs[0].shape).toEqual([null, 1]);
2023/11/20 13:19

---

expect(history.history.loss.length).toEqual(2);     ←---- 对模型进行短暂的训练。训练耗时非常短，但并不精确
expect(history.history.acc.length).toEqual(2);

```
const predictOuts = model.predict(xs);     ←---- (本行及以下6行) 调用模型进行一次预测，确保API 符合预期
expect(predictOuts.shape).toEqual([2, 1]);
```

2023/11/20 13:19

---

expect(values[0][0]).toBeGreaterThanOrEqual(0);
expect(values[0][0]).toBeLessThanOrEqual(1);
expect(values[1][0]).toBeGreaterThanOrEqual(0);
expect(values[1][0]).toBeLessThanOrEqual(1);
2023/11/20 13:20

---

### 12.2 模型优化

一般可以将这两种优化分别叫作模型的质量（quality）优化和模型的性能（performance）优化。性能指模型执行任务需要多少时间和资源。质量指结果与理想水平有多接近。
2023/11/20 13:21

---

优化一词有多重含义。在本节的语境下，优化指的是模型体积的减少和计算速度的提升。
2023/11/20 13:21

---

神经网络的非量化版float32权重通常不适用这类压缩技巧，因为权重值的变化过于不规则，很少存在重复的模式。以我们的经验来看，对于非量化版的模型权重而言，gzip最多能减小10%～20%的体积。16位版的权重量化效果也与此类似。但是，如果模型采用的是8位量化，压缩率就会有显著提升（对于小型模型，体积减小最多可达30%～40%；对于大型模型，体积减小最多可达20%～30%。详情参见表12-2）。
2023/11/20 13:22

---

总体来看，训练后的权重量可以帮助大幅减少本地存储和远程传输TensorFlow.js模型时的模型体积。
2023/11/20 13:22

---

对于浏览器（WebGL）部署环境，GraphModel转换的提速比例达到20%～30%，而Node.js环境中的提速则更为明显（70%～90%）。
2023/11/20 13:23

---

### 12.3 部署TensorFlow.js模型到不同的平台和环境

很多云平台供应商会以服务的方式提供训练好的机器学习模型的预测结果。这包括Google Cloud Vision AI和Microsoft Cognitive Services。终端用户只需要在HTTP请求中提供预测所需的输入，例如目标检测任务中的图像，然后云服务就会返回模型输出的预测结果，例如目标在图像中的标签和位置。
2023/11/20 13:31

---

使用Electron.js这样的JavaScript框架能开发跨平台的桌面端应用程序。
2023/11/20 14:15

---

Electron.js应用程序同时运行在基于Node.js的后端进程和基于Chromium的前端进程上。
2023/11/20 14:16

---

如果选择部署到后端进程，可以使用@tensorflow/tfjs-node包；前端环境则可以使用@tensorflow/tfjs包（见图12-8）
2023/11/20 14:17

---

如果将模型部署到前端，深度学习的工作负荷就会分配给WebGL。对于小到中等体积的模型，或者推断速度不是关键的场景，这种方法是可取的，因其能使软件更为轻量。同时，得益于硬件对WebGL的广泛支持，对于很多GPU而言，它可以开箱即用。
2023/11/20 14:17

---

微信小程序的API使开发者可以轻松地使用手机的各种传感器，包括摄像头、麦克风、加速计、陀螺仪、GPS等。然而，小程序API提供的机器学习能力非常有限。使用TensorFlow.js作为小程序的机器学习解决方案有几大优势。以前，如果开发者想在应用程序中嵌入机器学习能力，则需要在服务器端或云端另准备一套机器学习系统用于推断。这就将大部分小程序开发者挡在了构建和使用机器学习技术的门外。对绝大部分小程序开发者而言，在小程序外部另准备一套机器学习系统超出了所能承受的范围。有了TensorFlow.js后，就可以直接在小程序的原生环境中开发机器学习系统。此外，因为这是一种客户端解决方案，所以它还有助于减小网络流量压力并改善网络延迟。同时，它也可以利用WebGL进行GPU加速。
2023/11/20 14:20

---

对绝大部分应用程序而言，如果不能使用GPU，模型的运行速度就会过慢。有了这个插件后，微信小程序就能达到和移动端浏览器中JavaScript应用程序相当的模型推断速度。事实上，我们在实践中发现，微信的传感器API性能要比浏览器中的更好。
2023/11/20 14:20

---

近期推出的设备，如NVIDIA Jetson Nano和树莓派4，都搭载了含有现代图形处理器的片上系统（system-on-chip, SoC）。TensorFlow.js底层使用的WebGL代码可以利用这些设备上的GPU加速计算。无界面的WebGL软件包（tfjs-backend-nodegl）使TensorFlow.js代码可以纯粹依靠这些设备上的GPU加速运行（见图12-9）。通过让GPU分担TensorFlow.js的工作负荷，开发者可以解放CPU的算力，让它同时控制设备的其他部分。
2023/11/20 14:22

---

## 第 13 章 总结与展望

### 13.1 回顾关键概念

深度学习是很多机器学习形式中的一种。在深度学习中，模型由多个步骤组成，其中每个步骤都是对数据的一种转换，并且一个接着一个（这也是“深度”一词的由来）。这些转换运算被封装在名为层的模块中。深度学习模型一般是很多层的叠加，或者说很多层组成的图。这些层的参数叫作权重。权重是一种帮助层把输入转换成输出的数值，训练过程中会不断地更新它们。模型在训练中学到“知识”会被保存在权重中，因此训练过程的主要目标就是为这些权重寻找一组合适的值。
2023/11/20 14:24

---

深度学习最惊人的一点就是它的简单，这是相对而言的。在它之前的机器学习技巧要复杂得多，取得的成果却不如它。十年前，没人能预知仅靠用梯度下降训练出的参数化模型就能在机器感知问题上取得如此不可思议的成果。现在来看，只要参数化模型的规模够大，并且有足够多的有标签样例，取得好的结果就没有什么困难的。就像理查德·费曼对宇宙的评论一样，“它并不复杂，只是量大罢了”。1
2023/11/20 14:24

---

在深度学习中，一切都可以表示为数字序列——换言之，向量。可以将向量看作几何空间中的一个点。模型的输入（表格、图像、文本等）都会先被向量化，或者说被转换为输入向量空间中点的集合。类似地，目标（标签）也会被向量化，并转换为它们在目标向量空间中点的集合。然后，深度神经网络的每一层都会对流经它的数据进行简单的几何转换。各个神经层环环相扣，共同形成了一个由一系列简单几何转换组合成的复杂几何转换。这种复杂的转换会尝试将输入向量空间中的点映射到目标向量空间。各个层的权重会将这种转换参数化，然后基于转换的质量，迭代式地更新。这种几何转换的一个关键特征是，它是可微（differentiable）的。这是梯度下降的一个必要条件。
2023/11/20 14:25

---

大量的有标签数据集。这些数据集涵盖诸多数据类型，包括感知型数据（图像、音频和视频）、数值型数据和文本数据。这意味着我们有充足的数据来训练大型模型。这些数据是消费互联网崛起的副产品。移动设备的普及和存储设备的飞速进步（基于摩尔定律）进一步加速了数据量的增长。
2023/11/20 14:25

---

一系列复杂的开源软件将深度学习的计算能力普及给广大开发者和学生，同时隐藏了它底层的巨大复杂度。这些软件包括CUDA语言、浏览器的WebGL API，以及像TensorFlow.js、Python版TensorFlow和Keras这样的深度学习框架（这些框架可以自动进行微分计算，并提供易用的高阶模块，例如层、损失函数和优化器）。深度学习已经逐渐从专家（研究者、AI领域的研究生和有学术背景的工程师）独享的工具，变成每个程序员都可以使用的工具。TensorFlow.js框架就是这种趋势的一个典型例子。它将两个丰富且充满活力的生态——JavaScript的跨平台生态和快速演进中的深度学习生态——结合到了一起。
2023/11/20 14:26

---

### 13.2 回顾深度学习的流程和TensorFlow.js中的算法

具体而言，应该将数据划分成三个分布一致但互无重叠的数据集：训练集、验证集和测试集。验证集和测试集的数据一定不能和测试集重叠。
2023/11/20 14:27

---

除此之外，数据的预处理代码还应该用测试代码进行覆盖，以避免出现bug。
2023/11/20 14:27

---

==将数据转换为张量，或者说多维数组。==这类数据结构可以说是机器学习框架（例如TensorFlow.js和TensorFlow）中模型的通用语言。通常还需要预处理（例如标准化）张量化后的数据，从而让它们更适用于模型。
2023/11/20 14:27

---

开发出能超越常识性基准性能的模型。将非机器学习模型的性能作为常识性的基准（比如，人口预测的回归问题中直接预测人口平均值，时间序列预测问题中直接将上一个数据点作为预测结果），并以此证明开发出的机器学习模型确实能够为当前问题带来性能上的提升。但这种性能提升不是必然的（参见第(1)步）。
2023/11/20 14:28

---

在训练集上达到比验证集上更好的预测准确率
2023/11/20 14:28

---

据此得出模型最大所需的容量是多少。找到这个容量的临界点后，才可以开始使用正则化以及其他手段减少过拟合。
2023/11/20 14:28

---

上面的流程主要适用于监督式学习，这也是很多实际问题中会涉及的一种机器学习形式。
2023/11/20 14:29

---

向量数据（无时间顺序和空间顺序）：MLP模型（基于密集层）。
图像数据（黑白图像、灰度图像或彩色图像）：二维卷积（2D convnet）。
表示为音频数据的时频谱：二维卷积或RNN。
文本数据：一维卷积（1D convnet）或RNN。
时间序列数据：一维卷积或RNN。
立体数据（例如三维的医学影像数据）：三维卷积（3D convnet）。
视频数据（图像序列）：三维卷积（如果需要捕捉动态效果）；二维卷积与RNN或一维卷积之一的组合，其中二维卷积负责逐帧提取视频的特征，RNN或一维卷积负责处理特征序列。
2023/11/20 14:30

---

在不远的将来，一般的卷积很可能会被深度可分离卷积（depthwise separable convolution）大范围（甚至完全）取代。这是因为后者的作用是等效的，而且更快、更高效。它对应TensorFlow.js中的tf.layers.separableConv2d层。如果你要从头构建一个神经网络，强烈建议你使用深度可分离卷积。tf.layers.separableConv2d层可以直接替换tf.layers.conv2d层。由此构建出的神经网络不仅更轻量、更快，而且性能还可能更好。
2023/11/20 14:30

---

所有npm包中名称以@tensorflow-models/开头的都是由TensorFlow.js团队维护并提供第一方支持的，其他的npm包则由第三方开发者提供。
2023/11/20 14:31

---

人们对深度学习的一大误解是将其过度拟人化（anthropomorphization）。也就是说，将深度神经网络看作对人的感知与认知的模仿。将深度神经网络拟人化在好几个层面是明显错误的。首先，当人们尝试理解某个感知性刺激（例如小女孩的面部图像或牙刷图像）时，他们不仅会理解输入的亮度和色彩模式，而且还会从输入的看似随机的模式中提取出深层的、更重要的含义（例如图像中有小女孩、有牙刷，以及两者之间的关联性）。深度神经网络的工作原理与人脑完全不同。对于一个能将图像输入映射到文本输出的图像标注模型而言，将其理解为能像人脑一样理解图像的含义是错误的。在有些场景中，只要实际测试数据和训练所用的图像稍有不同，就可能导致模型生成看起来很荒诞的文本标注（见图13-2）。
2023/11/20 14:33

---

对抗性样例：==肉眼不可见的变化==可以诱导深度convnet的分类结果出错。
2023/11/20 14:33

---

### 13.3 深度学习的发展趋势

首先，无监督式学习（unsupervised learning）和半监督式学习（semisupervised learning）可能会有重大发展。这会对所有深度学习子领域产生深远的影响，因为虽然有标签数据集非常罕见且成本高昂，但无标签数据集在各个商业领域都非常充足。如果能发明一种方法，用少量的有标签数据引导对大量无标签数据的学习，那么深度学习领域会发掘出许多新的应用场景。
其次，深度学习的硬件会不断提升，产生出越来越强大的神经网络加速器（例如下一代的张量处理器6）。这样，研究者可以用更大规模的数据集训练出更强大的神经网络。可以预见，很多机器学习任务当前的最佳准确率纪录在未来会被打破。这些机器学习任务包括计算机视觉、语音识别、自然语言处理和生成式模型。
模型的架构设计和超参数优化会越来越自动化。这个趋势已经可以看到一些苗头了，其中具有代表性的是AutoML7和Google Vizier8等技术。
神经网络模块的共享和可复用性会进一步提升。基于预训练模型的迁移学习领域会更上一层楼。顶尖的深度学习模型正在变得日益强大和通用。它们训练所用的数据集的规模也在不断增长。因为自动化的架构搜索和超参数调优（参见前两个预测），所以这些模型有时会消耗巨大的算力。因此，和不断重新训练相比，复用这些预训练模型就成了一个更合理、更经济的选择。这些模型可以直接用于推断，也可以用于迁移学习。在某种程度上，深度学习和传统的软件工程变得更为接近了，因为它们都需要依赖并复用高质量的软件库，并由此实现整个领域的标准化和高速发展。
深度学习可能会找到一些新的应用领域。在这些新领域，它会被用来改进现有的解决方案，同时开启一些新的应用场景。就我们所知，潜在的应用场景真的是无穷的。这些新领域包括：农业、金融、教育、交通、医疗、时尚、体育和娱乐。对于深度学习从业者而言，这些领域蕴藏着无限的机遇。
随着深度学习渗透越来越多的应用领域，人们会越来越关注如何在边缘设备（edge device）上进行深度学习，因为这些边缘设备是最接近终端用户的。因此，深度学习领域可能会发展出一些更轻量、更节能的神经网络架构，并能达到和当前大型模型相匹敌的预测准确率和速度。
2023/11/20 14:34

---

### 13.4 继续探索的一些指引

一种有效地获取实际机器学习（尤其是深度学习）经验的方法是参与Kaggle组织的竞赛。真正学会机器学习的唯一方法是自己动手编程构建模型并为其调优，这也是本书所秉持的哲学。从本书提供的大量供你研究、微调和修改的代码示例就可见一斑。但是对于如何实际进行机器学习而言，这些都没有你自己用TensorFlow.js这样的框架从头构建一个模型和机器学习系统来得有效。在Kaggle平台上，你可以找到大量不断更新的数据科学竞赛和数据集，其中很多都和深度学习有关。
2023/11/20 14:35

---

尽管大多数Kaggle用户会采用Python生态中的工具（例如TensorFlow和Keras）解决比赛中的问题，但是Kaggle上的绝大部分数据集是适用于所有编程语言的。因此，完全可以用TensorFlow.js这样的非Python深度学习框架解决绝大部分的Kaggle问题。通过实际参与一些竞赛（无论是个人还是组队），你可以切身体会本书介绍的一些高级最佳实践的实用性，尤其是超参数调优和避免验证集过拟合的部分。
2023/11/20 14:36

---

一个叫作**ArXiv Sanity Preserver**（意思是“ArXiv理智保护器”）的网站可以为你推荐新的ArXiv论文，同时帮助你跟踪深度学习的某个垂直领域（例如自然语言处理和目标检测）的新进展。此外，你还可以使用谷歌学术搜索（Google Scholar）服务跟踪你所关注的领域和作者发表的新论文。
2023/11/20 14:36

---

# 附录 A 安装tfjs-node-gpu及其依赖

在使用GPU加速版的TensorFlow.js（tfjs-node-gpu）前，必须先在计算机上安装CUDA和CuDNN。然而，这两个软件都只有在搭配与CUDA兼容的NVIDIA GPU时才能使用。因此，使用GPU加速版的TensorFlow.js前，必须先确保你的计算机的GPU符合上述要求，详见NVIDIA Developer网站页面“推荐开发者使用的GPU”。
2023/11/20 14:37

---

## A.1 在Linux上安装tfjs-node-gpu

从NVIDIA Developer网站下载CuDNN。为什么除了CUDA以外，还要安装CuDNN呢？这是因为CUDA是一个通用的计算库，它的用途不仅限于深度学习（例如，还可用于流体力学的计算）。CuDNN是由NVIDIA基于CUDA开发的，用于加速深度神经网络的运算。
2023/11/20 14:39

---

# 附录 B TensorFlow.js张量及运算的简明教程

## B.4 计算梯度

微分和梯度计算是由model.fit()方法和model.fitDataset()方法自动完成的
2023/11/20 14:41

---

# 术语表

GraphModel可以利用TensorFlow内部的性能优化机制，例如Grappler的计算优化和运算融合优化
2023/11/20 14:42

---

强化学习中的一种行为选择方法。它能够将智能体在随机探索行为和最优行为间的平衡性参数化。epsilon的值被约束在0～1范围内。它的值越大，智能体就越倾向于选择随机行为。
2023/11/20 14:43

---

一类有大量层且结构复杂的深度卷积神经网络。
2023/11/20 14:43

---

LayersModel同时支持推断（通过predict()方法）和训练（通过fit()方法和fitDataset()方法）。
2023/11/20 14:43

---

一个预训练的深度卷积神经网络，一般是基于ImageNet图像分类数据集训练而成的，并可用于迁移学习。和其他类似的卷积神经网络相比，它较为轻量，推断时消耗的算力也较小，因此它更适合用TensorFlow.js在资源受限的浏览器环境中运行。
2023/11/20 14:44

---

将句子中的单词（或者更笼统地说，将序列中的各项）表示成向量的方法。在这种表示中，和单词对应的元素会被设为1，其他的元素则会被设为0。可以将multi-hot编码看作one-hot编码的泛化形式。它会舍弃原句中单词的顺序信息。
2023/11/20 14:44

---

一种填补数据集中缺失值的技巧。例如，如果我们有一个关于车的数据集，其中有些车的数据缺失“重量”特征。这种情况下，就可以用车的平均重量来填补缺失的特征值。此外，还有一些更精巧的插值技巧。
2023/11/20 14:44

---

网格搜索（grid search）和其他更精巧的超参数调优算法都可以实现超参数调优。
2023/11/20 14:45

---

在深度学习中，当将单词表用于一组离散的元素时，单词表有时不能囊括所有可能的元素。当遇到一个不在单词表中的元素时，它会被映射到一个特殊的索引：超出单词表范围（OOV）。该索引可以进一步映射到one-hot编码或嵌入表示中的一个特殊元素上。参见单词表。
2023/11/20 14:45

---

单词表（vocabulary）

在深度学习中，单词表指一组离散的、互不相同的元素。这些元素可以用作神经网络的输入或输出。一般而言，单词表中的每个元素都可以映射到一个整数索引上，然后进一步转换为one-hot编码或嵌入表示。
2023/11/20 14:45

---

黄金值（golden value）

在测试机器学习系统的语境下，黄金值指模型对于某个输入应该生成的正确输出。例如，对于一个能够将音频分类为正确音乐流派的神经网络而言，如果输入的是贝多芬的《第五交响曲》，那么黄金值就是“古典音乐”这个标签。
2023/11/20 14:46

---
