
[[白话深度学习]]
### 神经网络学习过程：
1. **权重和偏差：**
   - 在神经网络中，权重（weights）和偏差（biases）是模型的参数。
   - 每一层的神经元都与一组权重和一个偏差相关联。
   - 权重表示输入的重要性，偏差用于调整模型的灵活性。
2. **模型学习：**
   - 在训练过程中，神经网络通过学习适应输入和目标之间的关系。
   - 通过调整权重和偏差，模型逐渐提高对训练数据的拟合能力。
3. **反向传播：**
   - 反向传播是一种优化算法，用于调整网络参数以最小化预测输出与实际目标的差距（损失）。
   - 通过计算损失梯度，反向传播将误差逐层传递回网络，更新权重和偏差。
4. **深度学习的层次结构：**
   - 深度学习强调多层次的结构，即深层神经网络。每一层都可以学习不同层次的抽象特征。
   - 通过多层次的权重和偏差，神经网络能够学习从原始输入到最终输出的复杂映射。
5. **激活函数的作用：**
   - 激活函数引入非线性，使得神经网络能够学习更复杂的函数。它们使网络能够捕捉输入之间的非线性关系。
# 多层感知机（MLP）：
- 作者详细解释了多层感知机，这是一种常见的深度学习模型，包含多个隐藏层。
- 讨论了MLP的训练过程，使用梯度下降等优化算法进行参数更新。
多层感知机（Multilayer Perceptron，MLP）是一种常见的深度学习模型，它包含多个隐藏层，每个隐藏层都由多个神经元组成。作者详细解释了多层感知机的训练过程，其中使用梯度下降等优化算法进行参数更新。以下是关于这些概念的更详细说明：
### 多层感知机（MLP）：
1. **基本结构：**
   - MLP包含输入层、多个隐藏层和输出层。
   - 输入层接受输入数据，每个隐藏层都包含多个神经元，输出层产生最终的预测结果。
2. **隐藏层和神经元：**
   - 每个隐藏层包含多个神经元，每个神经元都连接到前一层和后一层的神经元。
   - 每个连接都有一个权重，每个神经元有一个偏差。
3. **激活函数：**
   - 在每个隐藏层和输出层，激活函数引入非线性，允许模型学习更复杂的函数。
   - 常用的激活函数包括ReLU、Sigmoid和Tanh。
### MLP的训练过程：
1. **前向传播：**
   - 输入数据通过网络的前向传播，从输入层到输出层。
   - 在每个隐藏层和输出层，进行线性变换和激活函数操作。
2. **损失函数：**
   - 训练过程中，需要定义一个损失函数来度量模型预测与实际标签之间的差距。
   - 常用的损失函数包括均方误差（MSE）和交叉熵损失。
3. **反向传播：**
   - 通过反向传播算法，计算损失对每个参数的梯度。
   - 这些梯度用于更新参数，以最小化损失。
4. **优化算法：**
   - 使用梯度下降等优化算法来更新参数。
   - 常见的优化算法包括随机梯度下降（SGD）、Adam等。
# 卷积神经网络（CNN）：
- 介绍了卷积神经网络，专门用于处理图像数据。解释了卷积层、池化层等核心组件。
- 讨论了CNN在图像分类和物体检测中的应用。
卷积神经网络（Convolutional Neural Network，CNN）是专门用于处理图像数据的深度学习模型。它包含卷积层、池化层等核心组件，通过局部感受野和权值共享等机制提取图像中的特征。以下是关于CNN的核心组件和应用的详细说明：
### 卷积神经网络（CNN）：
1. **卷积层（Convolutional Layer）：**
   - 卷积层使用卷积操作对输入图像进行特征提取。卷积核在图像上滑动，通过局部感受野计算特征映射。
   - 卷积操作利用权值共享的方式，减少参数数量，增加模型的可训练性。
2. **池化层（Pooling Layer）：**
![步幅为2，池化窗口为$2\times 2$的最大池化层](https://files.mdnice.com/user/55803/12ffd381-1ae3-46e9-9868-67cdecd2523c.png)
   - 池化层用于降采样，减小特征映射的尺寸，减轻计算负担。常见的池化操作包括最大池化和平均池化。
3. **激活函数（Activation Function）：**
   - 在卷积层和池化层之后，通常会应用激活函数引入非线性，使网络能够学习更复杂的特征。
4. **全连接层（Fully Connected Layer）：**
   - 在卷积层和池化层之后，通常会添加全连接层用于分类。全连接层将卷积层输出拉平，并连接到输出层。
### CNN在图像分类和物体检测中的应用：
1. **图像分类：**
   - CNN在图像分类任务中取得了巨大成功。通过学习图像的局部特征和层次结构，CNN能够准确地将图像分类为不同的类别。
2. **物体检测：**
   - CNN也广泛应用于物体检测任务。一些流行的物体检测框架，如Faster R-CNN、YOLO（You Only Look Once）等，使用CNN来识别图像中的物体并定位其位置。
3. **迁移学习：**
   - 由于CNN在大规模图像数据上的学习能力，迁移学习在CNN中得到了广泛应用。在训练好的模型基础上，可以在不同的任务上进行微调，提高模型在新任务上的性能。
4. **语义分割：**
   - CNN还用于语义分割任务，即将图像中的每个像素分配到相应的类别，实现对图像的像素级别理解。
### 示例代码片段：
以下是一个简化的Python代码片段，演示了使用卷积神经网络进行图像分类的基本流程（使用TensorFlow和Keras）：
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
# 构建卷积神经网络模型
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
# 编译模型
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# 训练模型（示例数据）
model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))
```
这个简单的CNN模型包含卷积层、池化层和全连接层，用于图像分类任务。在实际应用中，模型结构和参数需要根据具体任务进行调整。
# 循环神经网络（RNN）：
- 讲解了循环神经网络，适用于处理序列数据，如自然语言处理任务。
- 强调了RNN中的短时记忆和长时记忆的概念，以及LSTM（长短时记忆网络）的改进。
循环神经网络（Recurrent Neural Network，RNN）是一种适用于处理序列数据的深度学习模型，特别在自然语言处理（NLP）任务中得到广泛应用。在讲解RNN时，通常强调了短时记忆和长时记忆的概念，并介绍了LSTM（长短时记忆网络）作为对RNN的改进。
### 循环神经网络（RNN）：
1. **基本结构：**
   - RNN具有循环连接，允许信息在网络中传递，并且能够处理不同长度的序列数据。
   - 每个时间步，RNN接受输入和前一个时间步的隐藏状态，产生输出和当前时间步的隐藏状态。
2. **短时记忆和长时记忆：**
   - RNN中存在短时记忆的问题，即对于离当前时间步较远的信息，模型难以捕捉。
   - 这是由于梯度消失或梯度爆炸问题，导致长序列的信息难以传递。
### 长短时记忆网络（LSTM）：
1. **解决短时记忆问题：**
   - LSTM是对RNN的改进，通过引入门控机制，能够更有效地处理长序列。
   - 包括输入门、遗忘门、输出门，通过控制信息的流动，实现对短时记忆和长时记忆的有效管理。
2. **门控机制：**
   - 输入门：控制新信息的输入。
   - 遗忘门：控制过去信息的保留。
   - 输出门：决定输出哪一部分信息。
3. **公式表示：**
   - 输入门：$i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi})$
   - 遗忘门：$f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf})$
   - 输出门：$o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho})$
   - 更新记忆：$g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg})$
   - 记忆更新：$c_t = f_t \cdot c_{t-1} + i_t \cdot g_t$
   - 隐藏状态：$h_t = o_t \cdot \tanh(c_t)$
### 示例代码片段：
以下是一个简化的Python代码片段，演示了使用LSTM进行序列任务（使用TensorFlow和Keras）：
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
# 构建LSTM模型
model = Sequential()
model.add(LSTM(64, input_shape=(seq_length, feature_dim)))
model.add(Dense(output_dim, activation='softmax'))
# 编译模型
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# 训练模型（示例数据）
model.fit(train_sequences, train_labels, epochs=10, batch_size=32, validation_data=(val_sequences, val_labels))
```
这个简单的LSTM模型用于处理序列数据，其中 `seq_length` 是序列长度，`feature_dim` 是每个时间步的特征维度。在实际应用中，需要根据具体任务和数据调整模型结构和参数。
# 深度学习框架：
- 书中使用MXNet框架作为实现深度学习模型的工具，但也有对其他框架如TensorFlow和PyTorch的提及。
- 提供了实际代码示例，帮助读者理解和实践所学的概念。
MXNet（Apache MXNet）是一个开源的深度学习框架，它在深度学习中有一些重点应用。以下是MXNet在深度学习中的一些主要应用方面：
1. **多领域的深度学习任务：**
   - MXNet被广泛用于多个领域的深度学习任务，包括计算机视觉、自然语言处理、语音识别等。它提供了灵活性和可扩展性，适用于不同类型的深度学习应用。
2. **分布式深度学习训练：**
   - MXNet设计时考虑了分布式训练的需求，支持在多个设备、多台机器上进行分布式深度学习训练。这使得MXNet适用于大规模数据和复杂模型的训练。
3. **动态计算图：**
   - MXNet采用动态计算图的方式，与静态计算图的框架有所不同。这使得MXNet更适合处理变长序列等需要动态构建计算图的任务。
4. **混合精度训练：**
   - MXNet支持混合精度训练，即在训练过程中同时使用32位和16位浮点数。这有助于提高训练速度和减少内存占用。
5. **模型部署：**
   - MXNet提供了用于模型导出和部署的工具，使得在生产环境中部署深度学习模型变得更加容易。支持多种平台，包括服务器端、移动端和边缘设备。
6. **Gluon API：**
   - MXNet引入了Gluon API，这是一个动态神经网络API，使得模型的定义更加简单和直观。Gluon API支持深度学习的快速迭代和实验。
### 4.深度学习理论学习
我把深度学习的入门仿照机器学习，也分为两个部分，先学理论，再实战打比赛；
==其实说心里话，深度学习入门比机器学习入门要简单的多；==
我们都知道深度这块主要就是分为NLP和CV；
NLP任务上大概可以分为四种：文本分类 文本匹配 序列标注 文本生成，
CV任务大致也可以分为图像理解和生成：理解这块大致可以分为：分类、检测、分割、追踪； 生成这块基本就是GAN模型
对于入门来说，我们不用学这么多，我们只需要学籍基础的神经网络，然后通过文本分类和图片分类任务去熟悉掌握整个[徐娜林](https://www.zhihu.com/search?q=%E5%BE%90%E5%A8%9C%E6%9E%97&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D)和预测流程，比如数据处理，模型搭建等呢吧；
所以我推荐的这两门课程也是很出名的：
就是大家常说的[cs231n](https://www.zhihu.com/search?q=cs231n&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D) 和CS224n；
我来告诉大家怎么看这两个视频，同样不是全部都看；
1. **推荐的视频cs231n；**
B站视频链接见思维导图；
整个视频在B站是分为了33讲，作为入门来说，主要是学习p1-p22;
你去做前两个，实现图像分类任务，实现[卷积神经网络](https://www.zhihu.com/search?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D)：bn，dropout，cnn 都要看一下；
第三个作业比较复杂，大家不用去看，只需要做前两个；
**注意，不需要自己从零去做这个作业，直接看给的代码仓库，去看人家怎么实现的，当然你如果有自信而且想要锻炼自己，没问题，可以从零去实现。但是对于大部分人，你去对照着代码一行行的看，去理解为什么这儿写，输出输入是什么；**
在这个过程，就会涉及到一点，就是框架的学习，我推荐大家使用Pytorch；
框架框架学习，我这里我后面会讲到，我先在这里插一句，就是大家可以去看B站刘二大人，地址在这里：见思维导图备注
它这个pytorch学习曲线比较平滑，大家在在看计算机视觉视频之后，完成代码的部分，如果有不懂的地方，穿插着去看这个刘二大人的视频；
反向传播梯度回传，[损失函数](https://www.zhihu.com/search?q=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D)，优化算法，多层感知机，卷积神经网络，普通的循环神经网络，以及一些dropout和BN掌握住；
**2. [自然语言处理](https://www.zhihu.com/search?q=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D)：**
推荐一个视频，非常经典的 CS224n：
链接：见思维导图备注
**这个课程不是需要都看，要有选择的看：**
**在B站的官方主页，它包含了18讲的内容；在入门阶段，你只需要看P1-P5和P8，P9,P11；**
代码的学习过程中，不用去过度的关注调参之类的，而是关注代码是怎么写的；因为调参这块tricks后面我会有专门的部分提升；
3.Pytorch框架学习
pytorch框架的学习：其实这个[pytorch](https://www.zhihu.com/search?q=pytorch&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D)学习应该是融合在上面这个计算机视觉学习中的；可以在看完视频只有，写作业之前，先刷一遍这个Pytorch教学视频；
B站的刘二大人：《PyTorch深度学习实践》完结合集 [https://www.bilibili.com/video/BV1Y7411d7Ys?from=search&seid=1631997590037031874&spm_id_from=333.337.0.0](https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1Y7411d7Ys%3Ffrom%3Dsearch%26seid%3D1631997590037031874%26spm_id_from%3D333.337.0.0)
但是它好像没有源代码，评论区有小伙伴手敲了代码，地址在这：[https://blog.csdn.net/bit452/category_10569531.html](https://link.zhihu.com/?target=https%3A//blog.csdn.net/bit452/category_10569531.html)
### 5.深度学习竞赛实战：
重点来了，上面谈到的这些深度学习的东西，都是在给你打基础；
但是要记住，我们学习深度学习是为了实战：我给大家准备了两个学习曲线非常平滑的实战项目；
**一个是新闻分类项目，一个是街景字符识别，也就是图片分类项目，有的人可能会认为这两个项目非常简单，但是我认为千万不要小瞧这两个项目，扎扎实实做完这两个项目，对你的帮助绝对比你想象的要大；**
**先说NLP的新闻文本分类任务；地址在这里**：见思维导图备注
就像我所说的，这个任务是一个NLP中一个基础任务-[文本分类](https://www.zhihu.com/search?q=%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2274710236%7D)任务；这也是绝大部分从业的业务型NLP工程师日常工作最常见的工作需求；所以掌握好这个任务非常关键；
那么怎么掌握呢？在天池上，有开源的赛题解析，我挑选几个我认为很好的notebook给到大家；
bert；这个可以先不看，等你入了深度学习的门，认为自己想搞NLP这个方向了，你再去看相关的论文；我把链接放在这里吧：[https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.24.6406111aE3Lglg&postId=118259](https://link.zhihu.com/?target=https%3A//tianchi.aliyun.com/notebook-ai/detail%3Fspm%3D5176.12586969.1002.24.6406111aE3Lglg%26postId%3D118259)
百面机器学习；视频最后面我会提供给大家 这本书非常好，真的非常好；
