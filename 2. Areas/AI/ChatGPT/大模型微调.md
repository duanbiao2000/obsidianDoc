---
aliases: 
date: 2025-03-15 08:24
update: 
categories: 
rating: 
tags:
---


**问题3：软提示的作用是什么？**
?
A. 增加上下文长度  
B. 限制模型生成的长度  
C. 调整模型输出的风格或格式  
D. 提供更多的输入数据  

**问题4：在RAG中，通常在哪个阶段检索外部数据库或知识库？**
?
A. 在模型生成之前  
B. 在模型生成过程中  
C. 在模型生成之后  
D. 不需要检索数据库  



**问题7：API定制的主要目的是什么？**
?
A. 提高模型的输出质量  
B. 集成外部工具或服务  
C. 增加模型的输入数据  
D. 降低模型的训练成本  

**答案：**

**问题3：C**  
**问题4：A**  
**问题7：B**
## 文本简化
对于闭源大模型如OpenAI的GPT-4，由于模型权重和结构封闭，无法直接进行全参数微调或修改底层架构参数。但可以通过以下非侵入性方法实现类似效果：

1. **提示工程**：通过设计输入提示来引导模型输出。
2. **提示微调**：在上下文中插入软提示以引导模型输出。
3. **检索增强生成**：在输出前检索外部数据库，增强模型知识覆盖。
4. **领域适配**：将领域特定文本注入上下文，增强模型在特定领域表现。
5. **Fine-Tuning（GPT-3.5）**：对GPT-3.5进行全参数微调。
6. **API定制**：定义模型可以调用的外部函数或工具。

总结：在无法直接修改权重的情况下，RAG + Prompt Engineering是最有效的策略。

### 核心术语的英文解释：

1. **Prompt Engineering**：Designing input prompts to guide the model's output.
2. **Soft Prompting**：Inserting soft prompts in the context to guide the model's output.
3. **Retrieval Augmented Generation (RAG)**：Enhancing the model's knowledge coverage by retrieving external databases before the output.

可以从以下几个方向对闭源大模型进行“微调”或“定制”👇：
---
## 🚀 **1. 提示工程（Prompt Engineering）**
**思路：**
- 通过设计精巧的输入提示（Prompt）来引导模型的输出。
- 类似于“对模型进行编程”，通过控制输入结构、上下文长度、格式等，最大化利用预训练模型的潜力。
✅ 适用场景：
- 无法修改底层模型
- 需要快速适配新任务
- 资源消耗最小
🔎 **技巧：**
- **Zero-Shot Prompting** – 在不提供示例的情况下直接要求模型完成任务
- **Few-Shot Prompting** – 提供几个示例，让模型学习格式和模式
- **Chain-of-Thought (CoT) Prompting** – 引导模型“思考”过程，提升复杂任务的准确性
- **Self-Consistency** – 通过多次生成，选择最常见或一致的结果
💡 **示例（Few-Shot Prompting）：**
```text
Translate the following sentences from English to French:
1. Hello, how are you? → Bonjour, comment ça va ?
2. What time is it? → Quelle heure est-il ?
3. I would like to order a coffee. → 
```
💡 **示例（CoT Prompting）：**
```text
Q: If I have 3 apples and give away 1, how many do I have left? 
A: Let's think step by step. First, I have 3 apples. After giving away 1, I am left with 3 - 1 = 2 apples.
Final answer: 2
```
---
## 🧠 **2. 提示微调（Soft Prompting）**
**思路：**
- 在上下文中插入一段“软提示”（Soft Prompt），让模型在生成过程中将其作为额外的上下文。
- OpenAI 的 API 支持通过上下文长度来模拟软提示的作用。
✅ 适用场景：
- 定制回答风格或格式
- 需要模型保持特定语气或领域适配
💡 **示例：**
```text
[软提示]: You are a helpful, professional assistant who explains things clearly and logically.
Q: What is the capital of France?  
A: The capital of France is Paris. 
```
👉 **本质：** 软提示就像在输入中嵌入了一个“微调层”，让模型根据提示的内容调整输出风格。

---
## 🔎 **3. 检索增强生成（RAG）**
**思路：**
- 通过在输出前检索外部数据库或知识库，将相关信息插入到输入中，增强模型的知识覆盖面。
- OpenAI 的 API 允许通过将检索结果插入到输入上下文中来引导输出。
✅ 适用场景：
- 需要保持信息时效性
- 动态更新外部知识
- 处理特定领域的复杂任务
💡 **示例：**
1. 在 GPT-4 生成回答前，从向量数据库（如 FAISS）中检索相关信息：
2. 将检索到的信息作为提示的一部分，增强生成输出。
```python
import openai
# 检索外部知识
retrieved_info = "The capital of France is Paris."
# 将检索结果插入提示
prompt = f"""
Context: {retrieved_info}
Q: What is the capital of France?
A: 
"""
# 调用 OpenAI API
response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=[{"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}]
)
print(response['choices'][0]['message']['content'])
```
👉 本质上是通过“增加上下文长度”来模拟微调的效果。

---
## 🧬 **4. 领域适配（Domain Adaptation）**
**思路：**
- 将大量领域特定的文本或数据注入到上下文中，让模型在特定领域内表现更好。
- OpenAI 支持通过 `function calling` 或 `tool use` 在上下文中引入外部数据。
✅ 适用场景：
- 需要特定领域的精度提升
- 需要适配行业术语或特定格式
💡 **示例：**
- 通过 API 加载医学数据库或法学数据库的内容，作为模型输出前的辅助信息。
- 通过 OpenAI 的插件机制（如在 ChatGPT Plus 中）连接外部知识库。
```python
# 示例：在医学领域中引导模型
context = """
Patient symptoms: Cough, fever, muscle pain.
What is the possible diagnosis?
"""
response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=[{"role": "system", "content": "You are a medical expert."},
            {"role": "user", "content": context}]
)
print(response['choices'][0]['message']['content'])
```
👉 本质上是将外部知识注入到“上下文窗口”中，来提升模型在特定领域的表现。

---
## 🛠️ **5. Fine-Tuning（受限开放的微调）**
目前 OpenAI 仅允许在**GPT-3.5** 和更早版本的模型上进行全参数微调（GPT-4 仍然不开放微调）。
### ✅ 你可以对 GPT-3.5 进行的微调包括：
- 定制回答格式
- 领域知识适配
- 调整语气与风格
### 🚫 GPT-4 的限制：
- 不允许对 GPT-4 进行全参数微调
- 但可以通过前述方法（Prompt Engineering, RAG, Soft Prompting）实现“伪微调”
---
## 💡 **6. API 定制（Function Calling & Tool Use）**
**思路：**
- 定义模型可以调用的外部函数或工具。
- 通过引导模型在生成过程中调用外部工具，来动态获取信息或执行特定操作。
✅ 适用场景：
- 需要动态数据或特定操作
- 需要集成外部工具或服务
💡 **示例：**
- 调用数据库、API 或脚本，获取最新的股市行情、天气、新闻等。
```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get the current weather for a location.",
            "parameters": {
                "location": "string"
            }
        }
    }
]
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "What's the weather in New York?"}],
    tools=tools
)
```
👉 Function Calling 让 GPT-4 具备了“插件能力”，可以在生成过程中调用外部系统。

---
## ✅ **总结：如何“微调”闭源模型？**
| 方法                    | 适配性 | 灵活性 | 成本 | 效果    |
| --------------------- | --- | --- | -- | ----- |
| Prompt Engineering    | 高   | 高   | 低  | ⭐⭐⭐   |
| Soft Prompting        | 中   | 中   | 低  | ⭐⭐⭐⭐  |
| RAG                   | 高   | 中   | 中  | ⭐⭐⭐⭐⭐ |
| Function Calling      | 中   | 高   | 低  | ⭐⭐⭐⭐  |
| Fine-Tuning (GPT-3.5) | 中   | 中   | 高  | ⭐⭐⭐⭐⭐ |
➡️ 在无法直接修改权重的情况下，**RAG + Prompt Engineering** 是最有效的策略。
