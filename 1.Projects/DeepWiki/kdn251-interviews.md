---
date: 2025-05-15 18:27
tags:
  - 算法
source: https://deepwiki.com/kdn251/interviews/
---

- 我们在描述算法复杂度时，通常最关心的是**大 O 符号**，因为它给出了算法在最坏情况下的性能保证。
- **大 Θ 符号**提供了更精确的复杂度描述，当我们知道算法的上下界相同时使用。
- **大 Ω 符号**在分析算法的理论下限时有用。
- **小 o 和小 ω 符号**用于更精细地比较算法的增长速度，说明一个算法的增长速度严格快于或慢于另一个函数。


**总览：理解数据结构的本质**

首先，不要死记硬背 O(1) 和 O(n)。理解为什么某些操作是 O(1) 而另一些是 O(n) 才是关键。

- **O(1) 意味着“一步到位”：** 你可以直接找到或操作目标，不需要按顺序查看很多元素。
- **O(n) 意味着“可能需要查看所有”：** 在最坏的情况下，你可能需要遍历整个数据结构才能找到、插入或删除元素。

**逐个击破，建立联系：**

1. **Array (数组)**
    
    - **本质：** 一块连续的内存空间，元素按顺序存储，每个元素都有一个固定的索引（像酒店房间号）。
    - **Access (访问 - O(1))：** 知道房间号（索引），直接开门进去，一步到位。
    - **Search (搜索 - O(n))：** 不知道房间号，只能挨个房间敲门询问，最坏情况要问遍所有房间。
    - **Insert (插入 - O(n))：** 想在中间插入一个元素，后面所有元素都要往后挪一个位置，像一队人中间插入一个人，后面的人都要往后退。最坏情况在开头插入，所有元素都要移动。
    - **Delete (删除 - O(n))：** 删除中间一个元素，后面所有元素都要往前挪一个位置，像一队人走了一个，后面的人要往前补上空位。最坏情况删除第一个元素，所有元素都要移动。
2. **Linked List (链表)**
    
    - **本质：** 元素分散在内存中，每个元素（节点）包含数据和指向下一个元素的“指针”（像寻宝游戏中的线索）。
    - **Access (访问 - O(n))：** 没有房间号，只能从第一个线索开始，一个接一个地找到目标，最坏情况要找到最后一个。
    - **Search (搜索 - O(n))：** 和访问类似，只能从头开始，一个接一个地比较，最坏情况要找到最后一个。
    - **Insert (插入 - O(1))：** 知道要插入的位置（通常通过指针找到），只需要修改几个指针的指向，就像在寻宝路线中插入一个新的线索，只需要连接前后两个线索。
    - **Delete (删除 - O(1))：** 知道要删除的元素（通常通过指针找到），只需要修改前一个节点的指针，跳过要删除的节点，就像在寻宝路线中移除一个线索，只需要连接前后的线索。**注意：找到要插入或删除的节点本身是 O(n) 的操作。这里指的是在已知位置的情况下进行插入和删除。**
3. **Stack (栈)**
    
    - **本质：** 像一叠盘子，后放的在上面，只能从顶部操作（后进先出 - LIFO）。
    - **Access (访问 - O(n))：** 要访问底部的盘子，必须先拿走上面的盘子，最坏情况要拿走所有。
    - **Search (搜索 - O(n))：** 类似访问，只能从顶部开始一个一个查看。
    - **Insert (插入 - O(1))：** 只能放在顶部，一步到位（压入 - push）。
    - **Delete (删除 - O(1))：** 只能从顶部拿走，一步到位（弹出 - pop）。
4. **Queue (队列)**
    
    - **本质：** 像排队，先来后到（先进先出 - FIFO）。
    - **Access (访问 - O(n))：** 要访问队伍中间或后面的人，需要先让前面的人离开，最坏情况要等到目标前面所有人都离开。
    - **Search (搜索 - O(n))：** 类似访问，只能从队头开始一个一个查看。
    - **Insert (插入 - O(1))：** 只能在队尾加入，一步到位（入队 - enqueue）。
    - **Delete (删除 - O(1))：** 只能从队头离开，一步到位（出队 - dequeue）。

**记忆技巧总结：**

- **联系实际：** 将数据结构比作生活中的例子，更容易理解其特性。
- **关注本质：** 理解每个数据结构是如何组织数据的，这是时间复杂度的根本原因。
- **对比记忆：** 比较数组和链表，栈和队列的异同，加深理解。
- **强调 O(1) 和 O(n) 的含义：** “一步到位” vs. “可能需要遍历所有”。
- **理解操作的瓶颈：** 思考在每个数据结构中，哪些操作需要移动大量元素或遍历整个结构。
## 树

#### 二叉树的类型

- **满二叉树** ：每个节点有 0 个或 2 个子节点的树
- **完美二叉树** ：所有内部节点都有两个子节点，且所有叶子节点深度相同的二叉树
- **完全二叉树** ：除了最后一层之外，每一层都是满的，并且最后一层的所有节点都尽可能地靠左
### 二叉搜索树（BST）

二叉搜索树是一种特殊类型的二叉树，它保持以下属性：每个节点中的值必须是：

- 大于或等于左子树中存储的任何值
- 小于或等于右子树中存储的任何值

这种排序属性使得搜索、插入和删除操作更加高效。

#### BST 时间复杂度

- 访问：平衡树中为 `O(log(n))` ，最坏情况下为 `O(n)`
- 搜索：平衡树中为 `O(log(n))` ，最坏情况下为 `O(n)`
- 插入：平衡树中为 `O(log(n))` ，最坏情况下为 `O(n)`
- 移除：平衡树中为 `O(log(n))` ，最坏情况下为 `O(n)`
## 图
好的，我们来像费曼先生那样， разбираться (razbirat'sya - разбираться，俄语，意为“搞清楚”) 这些不同类型的图。想象一下我们用点表示不同的地点，用线表示连接这些地点的道路。不同的图类型就像描述不同类型的道路网络。

**1. 无向图 (Undirected Graph)**

- **本质：** 连接两个地点的道路是双向的。如果你能从地点 A 到地点 B，那么你也能从地点 B 回到地点 A。边的连接没有特定的方向。
- **想象：** 就像你家附近的街道，如果你能从你家走到朋友家，你也能沿着同一条路从朋友家走回你家。
- **表示：** 如果节点 u 和节点 v 之间有一条边，我们可以简单地说它们是“连接的”，顺序并不重要。

**2. 有向图 (Directed Graph)**

- **本质：** 连接两个地点的道路是单向的。如果你能从地点 U 到地点 V，并不意味着你也能直接从地点 V 回到地点 U。边的连接有明确的方向。
- **想象：** 就像城市里的单行道。你可以从这条路的起点开到终点，但你不能直接沿着这条路的反方向行驶。
- **表示：** 从节点 u 到节点 v 的边通常表示为 u → v，明确了方向性。

**3. 加权图 (Weighted Graph)**

- **本质：** 每条连接两个地点的道路都有一个相关的“成本”或“权重”。这个权重可以代表距离、时间、费用等等。
- **想象：** 就像一张地图，每条道路旁边都标明了它的长度（例如公里数）或者通过这条道路所需的时间。
- **表示：** 每条边都会附带一个数值，表示它的权重。例如，连接节点 u 和节点 v 的边，其权重可能是 5。

**4. 连通图 (Connected Graph)**

- **本质：** 从图中的任何一个地点出发，你都可以通过一系列的道路到达图中的任何其他地点。整个图是一个“整体”，没有被分割成互相无法到达的几个部分。
- **想象：** 就像一个所有岛屿之间都有桥梁相连的群岛。你可以从任何一个岛屿出发，通过桥梁到达任何其他的岛屿。
- **表示：** 对于图中的任意两个节点 u 和 v，都存在一条从 u 到 v 的路径（可能经过多个中间节点）。

**5. 循环图 (Cyclic Graph)**

- **本质：** 图中存在至少一条“回路”或“环”。这意味着你可以从某个地点出发，沿着一系列的道路走一圈，最终回到出发点，并且途中不会重复经过任何一条边（在简单环中）。
- **想象：** 就像城市里的一条环形公路，你沿着这条路一直开，最终会回到你开始的地方。
- **表示：** 存在一个由不同节点组成的序列 v₁, v₂, ..., vk，使得 (v₁, v₂), (v₂, v₃), ..., (vk-₁, vk), (vk, v₁) 都是图中的边。

**总结与记忆：**

- **方向性：** 无向图的边是双向的，有向图的边是单向的。
- **成本：** 加权图的边有相关的数值权重。
- **可达性：** 连通图中的所有节点之间都有路径相连。
- **回路：** 循环图包含至少一个可以回到起点的路径。

理解这些图的类型就像理解不同类型的道路网络如何限制或允许我们从一个地方移动到另一个地方，以及每条道路可能带来的“成本”。在解决各种问题时，选择合适的图类型来建模是非常重要的。

## HashTable
好的，我们来像费曼先生那样， разбираться (razbirat'sya - разбираться，俄语，意为“搞清楚”) 哈希表（Hash Table）的时间复杂度。这就像我们使用一个非常聪明的图书馆索引系统来快速找到书籍。

**核心思想：通过哈希函数快速定位**

哈希表的关键在于使用一个“哈希函数”（Hash Function）。这个函数接收你想要存储或查找的“键”（Key），然后计算出一个“哈希值”（Hash Value），这个哈希值对应着数据在哈希表中存储的“桶”（Bucket）的索引。

**两种情况：理想与冲突**

就像一个图书馆的索引系统，如果每本书都有一个唯一的索引，并且可以直接找到对应的书架（理想情况），那么查找就非常快。但是，如果两本书的索引一样，我们就需要额外的方法来处理这种情况（冲突）。

1. **平均情况 (Average Case) - 近乎完美的世界**
    
    - **想象：** 我们的哈希函数工作得非常好，能够将不同的键均匀地分布到不同的桶中，很少发生冲突。
    - **Access (访问 - N/A):** 哈希表通常不直接提供“按索引”的访问方式，你需要提供键来访问值。所以，这个操作通常不适用。
    - **Search (搜索 - O(1)):** 要查找一个键，我们首先使用哈希函数计算出它的哈希值，然后直接跳转到对应的桶。如果桶是空的或者只包含我们要找的键，那么搜索只需要一步，所以是 O(1)。这就像在图书馆索引中查到书的唯一编号，然后直接找到对应的书架和书籍。
    - **Insert (插入 - O(1)):** 要插入一个新的键值对，我们先计算键的哈希值，然后将键值对放到对应的桶里。如果桶是空的，或者有足够的空间（例如使用链表或开放寻址处理冲突），插入通常只需要一步，所以是 O(1)。这就像在对应的书架上找到一个空位放书。
    - **Delete (删除 - O(1)):** 要删除一个键值对，我们先计算键的哈希值，找到对应的桶，然后移除该键值对。如果桶中只有一个键值对或者我们能快速定位到要删除的键值对（通过链表等方式），删除通常只需要一步，所以是 O(1)。这就像在书架上找到指定的书并拿走。
2. **最坏情况 (Worst Case) - 冲突大爆发**
    
    - **想象：** 我们的哈希函数非常糟糕，或者我们插入了大量的键，导致所有的键都被哈希到了同一个桶里，发生了大量的冲突。
    - **Access (访问 - N/A):** 同样不适用。
    - **Search (搜索 - O(n)):** 如果所有的键都哈希到了同一个桶里，那么搜索就变成在这个桶里的所有元素中进行线性搜索。如果桶是用链表实现的，我们需要遍历整个链表才能找到目标键（或确定它不存在），所以时间复杂度是 O(n)，其中 n 是哈希表中键值对的总数。这就像图书馆里所有的书都被堆在同一个书架上，你需要一本一本地翻才能找到你想要的。
    - **Insert (插入 - O(n)):** 在最坏情况下，如果所有的键都哈希到了同一个桶里（并且使用链表处理冲突），那么插入新的键值对可能需要遍历整个链表才能找到链表的末尾进行插入，所以时间复杂度是 O(n)。如果使用开放寻址等其他冲突解决策略，也可能出现需要探测整个哈希表才能找到空位的情况。
    - **Delete (删除 - O(n)):** 类似插入，在最坏情况下，可能需要遍历整个桶（例如一个很长的链表）才能找到要删除的键值对。

**总结与记忆：**

- **哈希函数的质量至关重要：** 好的哈希函数能够均匀分布键，减少冲突，从而使平均情况下的性能接近 O(1)。
- **冲突处理是关键：** 哈希表需要有效的冲突解决策略（例如链地址法、开放寻址法）来处理多个键哈希到同一个桶的情况。即使有好的哈希函数，也无法完全避免冲突。
- **平均情况是常数级别：** 在通常情况下，哈希表的搜索、插入和删除操作都非常快，接近常数时间 O(1)。
- **最坏情况是线性级别：** 在极端情况下（大量冲突），这些操作的性能会退化到线性时间 O(n)。

所以，记住哈希表的时间复杂度时，要理解平均情况下的高效性来自于良好的哈希函数和冲突处理，而最坏情况下的线性时间是由于极端冲突导致的。我们设计哈希表时，目标就是尽量避免最坏情况的发生，让平均性能占主导地位。

## 算法

### Time Complexity Comparison Table

| Complexity | Name         | Example Algorithms                            |
| ---------- | ------------ | --------------------------------------------- |
| O(1)       | Constant     | Hash table operations, Stack/Queue operations |
| O(log n)   | Logarithmic  | Binary search, BST operations                 |
| O(n)       | Linear       | Linear search, array traversal                |
| O(n log n) | Linearithmic | Efficient sorting (Quicksort, Mergesort)      |
| O(n²)      | Quadratic    | Simple sorting (Bubble, Insertion, Selection) |
| O(2ⁿ)      | Exponential  | Recursive Fibonacci, Power set generation     |
| O(n!)      | Factorial    | Permutations, Brute force traveling salesman  |
好的，我们来像费曼先生那样， разбираться (razbirat'sya - разбираться，俄语，意为“搞清楚”) 这张排序算法的分类图及其时间复杂度。这张图清晰地展示了不同的排序算法是如何分类的，以及它们在时间效率上的表现。

**核心思想：不同的策略，不同的效率**

就像整理一堆散乱的书籍，你可以选择不同的方法：一本一本地找到正确位置插入（插入排序），不断比较交换相邻的错误顺序的书籍（冒泡排序），将书堆分成小堆分别排序再合并（归并排序），等等。不同的排序策略会导致不同的效率。

**图表解读：**

这张图将常见的排序算法分为了三个主要的类别，它们都以“Input Array”（输入数组）为起点，最终目标都是得到“Sorted Array”（排序后的数组）。

1. **In-place Sorting (原地排序)**
    
    - **定义：** 这类排序算法在排序过程中，大部分情况下只需要常数级的额外空间（O(1)）。它们直接在输入的数组上进行操作，通过交换数组中的元素来达到排序的目的。
    - **代表算法：**
        - **QuickSort (快速排序) - O(n log n)**
            - **本质：** 选取一个“基准”元素，将数组划分为小于基准和大于基准的两部分，然后递归地对这两部分进行排序。
            - **费曼式理解：** 就像你随机挑出一本书作为“中间”值，然后把比它“小”的书放在一边，比它“大”的书放在另一边，再对这两堆书重复这个过程。
            - **时间复杂度 O(n log n)：** 平均情况下，每次划分都能有效地缩小问题的规模，所以效率较高。最坏情况下可能退化到 O(n²)。
2. **Divide & Conquer (分而治之)**
    
    - **定义：** 这类算法将问题分解成更小的子问题，递归地解决这些子问题，然后将子问题的解合并起来得到原问题的解。
    - **代表算法：**
        - **MergeSort (归并排序) - O(n log n)**
            - **本质：** 将数组递归地分成两半，分别对每一半进行排序，然后将排好序的两半合并成一个有序的数组。
            - **费曼式理解：** 就像你把一堆书分成两小堆，分别让两个人把这两小堆书排好序，然后你再把这两堆排好序的书合并成最终有序的一堆。
            - **时间复杂度 O(n log n)：** 无论输入数据的顺序如何，归并排序的时间复杂度都是稳定的 O(n log n)，但它通常需要额外的 O(n) 空间来存储合并过程中的临时数组。
3. **Distribution Sort (分配排序)**
    
    - **定义：** 这类算法不通过比较元素的大小来进行排序，而是根据元素的数值特性（例如数值范围、位数）将元素分配到不同的“桶”或位置，然后将这些桶或位置中的元素按顺序收集起来。
    - **代表算法：**
        - **Bucket Sort (桶排序) - O(n + k)**
            - **本质：** 将输入数据分配到若干个“桶”中，每个桶存储一个范围内的元素。然后对每个桶中的元素进行排序（可以使用其他排序算法），最后将所有桶中的元素按顺序合并起来。
            - **费曼式理解：** 就像你把一堆书按照它们的高度范围放到不同的箱子里（桶），然后你再把每个箱子里的书排好序，最后把所有箱子里的书按顺序拿出来。
            - **时间复杂度 O(n + k)：** 其中 n 是输入元素的数量，k 是桶的数量。如果 k 的大小与 n 成正比，则时间复杂度可以达到 O(n)。桶排序的效率高度依赖于数据的分布和桶的数量。
        - **Radix Sort (基数排序) - O(nk)**
            - **本质：** 按照元素的位数（例如个位、十位、百位...）进行排序。每次排序都使用一种稳定的排序算法（例如计数排序）将元素按照当前位的值放到相应的位置。重复这个过程直到所有位数都被处理完。
            - **费曼式理解：** 就像你先按照书的页码的个位数进行排序，然后按照十位数排序（保持个位数相同的书的相对顺序），再按照百位数排序，以此类推，直到所有位数都排完。
            - **时间复杂度 O(nk)：** 其中 n 是输入元素的数量，k 是数字的位数（或者字符串的长度等）。如果 k 是一个常数（例如，对固定范围的整数排序），则时间复杂度可以看作 O(n)。

**总结与记忆：**

- **原地排序 (QuickSort)：** 空间效率高（通常 O(1)），但时间复杂度在最坏情况下可能较高。
- **分而治之 (MergeSort)：** 时间复杂度稳定 (O(n log n))，但通常需要额外的空间。
- **分配排序 (BucketSort, RadixSort)：** 可以达到线性时间复杂度，但对输入数据的分布或特性有要求。

理解这些不同排序算法的分类和它们背后的思想，以及它们在不同情况下的时间复杂度，能帮助我们为特定的任务选择最合适的排序方法。就像选择工具一样，了解每种工具的特点才能更好地使用它们。
## 图遍历算法
好的，我们来像费曼先生那样， разбираться (razbirat'sya - разбираться，俄语，意为“搞清楚”) 这张图遍历算法及其应用的图。这张图清晰地展示了图遍历的两种主要方法，以及它们在解决各种图相关问题中的应用。

**核心思想：系统地探索图**

想象你在一张复杂的迷宫地图上，想要探索所有的房间或者找到从入口到出口的路径。图遍历算法就是系统地访问图中的每一个节点（房间）和每一条边（通道），确保不会遗漏任何部分。

**图表解读：**

这张图以“Starting Node”（起始节点）为起点，展示了两种主要的图遍历算法，它们都会记录“Visited Nodes”（已访问节点），并且最终都可以应用于解决多种“Applications”（应用）。

1. **Graph Traversal Algorithms (图遍历算法)**
    
    - **Depth First Search (DFS - 深度优先搜索)**
        
        - **本质：** 从起始节点开始，沿着一条路径尽可能深地探索，直到到达末尾无法继续前进时，才回溯到上一个节点，再探索另一条路径。就像你在迷宫里选择一条路一直走下去，走到死胡同再退回来尝试其他路。
        - **费曼式理解：** 想象你是一只好奇的小蚂蚁，遇到岔路口总是选择一条路一直向前爬，直到爬不动了才往回走，看看有没有其他没爬过的路。
        - **记住：** “深”字代表优先探索深度。
    - **Breadth First Search (BFS - 广度优先搜索)**
        
        - **本质：** 从起始节点开始，首先探索所有相邻的节点，然后探索这些相邻节点的相邻节点，依此类推，一层一层地向外扩展。就像水波在池塘中扩散一样。
        - **费曼式理解：** 想象你扔一块石头到平静的池塘里，水波会一圈一圈地向外扩散，先到达离你最近的点，然后逐渐到达更远的点。
        - **记住：** “广”字代表优先探索广度（同一层级的节点）。
2. **Visited Nodes (已访问节点)**
    
    - **本质：** 这两种算法都需要记录已经访问过的节点，以避免重复访问，防止在包含环的图中陷入无限循环，并确保每个节点只被处理一次。就像你在迷宫地图上标记已经走过的房间，避免重复探索。
3. **Applications (应用)**
    
    - **Connected Components (连通分量)**
        
        - **如何应用：** 通过从一个未访问的节点开始进行 DFS 或 BFS，可以找到所有与该节点连通的其他节点，形成一个连通分量。重复这个过程，直到所有节点都被访问，可以找到图中的所有连通分量。就像在地图上找到所有相互连通的岛屿群。
    - **Path Finding (路径查找)**
        
        - **如何应用：** DFS 可以用于查找两个节点之间是否存在路径。BFS 可以用于查找两个节点之间的**最短路径**（在无权图中）。在探索过程中记录每个节点的“父节点”，当找到目标节点时，可以回溯找到路径。就像在迷宫地图上找到从入口到出口的路线，BFS 还能找到最短的路线。
    - **Cycle Detection (环路检测)**
        
        - **如何应用：** 在 DFS 过程中，如果遇到一个已经访问过的、并且不是当前节点的父节点的节点，则说明图中存在环。在 BFS 中，也可以通过记录节点的访问状态来检测环。就像在复杂的道路网络中，判断是否存在可以回到起点的环形路。
    - **Topological Sorting (拓扑排序)**
        
        - **如何应用：** 拓扑排序只能应用于有向无环图 (DAG)。DFS 可以用于实现拓扑排序。基本思想是先找到所有入度为 0 的节点，然后将它们加入排序结果，并移除从这些节点出发的边，重复这个过程。就像安排一系列有依赖关系的任务，确保每个任务在其依赖的任务完成后才开始。

**总结与记忆：**

- **DFS 像探险家，一往无前，直到尽头才回头。** 适用于查找路径是否存在、检测环等。
- **BFS 像侦察兵，稳扎稳打，一层一层地探索。** 适用于查找最短路径、按层级处理节点等。
- **记录已访问节点是关键，避免重复和无限循环。**
- **不同的图遍历方法适用于解决不同的图相关问题。**

理解这两种基本的图遍历算法及其特性，以及它们如何应用于解决实际问题，就像掌握了探索复杂网络的两种基本工具。选择合适的工具取决于你想要解决的具体问题。

[Repository Structure and Organization | kdn251/interviews | DeepWiki](https://deepwiki.com/kdn251/interviews/3-algorithms-reference) 待续