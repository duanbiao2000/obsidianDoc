好的 Sam，我们来构建一个用于增强自我认知的 Agent 的 **Prompt Flow + 模板结构**。目标是让 Agent **能追踪、评估、反思并优化自己的行为和输出**。

---

## 一、整体设计：Self-Aware Agent Prompt Flow 架构

```
[任务指令 Prompt]
        ↓
[初步思考 Prompt] → [输出结果]
        ↓
[自我评估 Prompt（Self-Eval）]
        ↓
[元认知分析 Prompt（Meta-Reflect）]
        ↓
[改进建议 Prompt（Refinement）]
        ↓
[更新提示 / 策略 / 工具选择]
```

可视化为多段式推理链，类似 Tree-of-Thought + Reflexion，但强调「自我认知的表达」与「自修复」。

---

## 二、模板拆解与范例

### 1. **任务指令 Prompt**

```text
你是一个具备深入分析能力的智能助手，现在的任务是：
【任务描述】

请以结构化方式给出你的解答，并标注关键推理点。
```

例：

```text
你是一个创业顾问，现在的任务是分析某 SaaS 产品的市场机会与风险。请列出关键用户群、潜在痛点、市场风险。
```

---

### 2. **初步思考 Prompt（CoT）**

```text
请你使用“逐步思考”的方式解决这个任务。不要直接跳到结论，先列出：
1. 所需信息有哪些？
2. 推理路径是什么？
3. 你对该问题的理解是否有盲点？
```

---

### 3. **自我评估 Prompt（Self-Eval）**

```text
以下是你刚才的回答：
【粘贴回答】

请你从以下维度自评这段输出：
- 回答是否逻辑清晰？
- 是否遗漏关键维度？
- 是否可能存在幻觉或不可靠内容？
- 是否存在不合理假设？

最后，请给出一个评分（1-10）和一句反思总结。
```

---

### 4. **元认知分析 Prompt（Meta-Reflect）**

```text
你现在是一个“思维教练”，任务是帮助自己优化思维方式。

请对刚才的思考过程进行分析，回答：
- 哪一部分推理是强的？为什么？
- 哪些地方存在未经验证的跳跃？
- 若重新来做，有没有更好的推理路径？

输出格式：
【强点】
【弱点】
【改进建议】
```

---

### 5. **改进建议 Prompt（Refinement）**

```text
基于上面的反馈，请重新生成一个更优化的回答。你可以：
- 重写部分内容
- 替换推理方式
- 明确表达逻辑链
```

---

## 三、进阶功能模块建议（可扩展）

|模块名称|说明|
|---|---|
|CoT 可视化|记录 Agent 每轮推理过程，展示成结构图|
|Embedding 记忆库|将每轮输入输出存入向量数据库，支持类比与 drift 检测|
|思维风格模板集|提供“工程师式思考”、“哲学家式思考”、“用户导向式思考”等风格 prompt 模板|
|自我演化触发器|若连续三次评分低于 X，则自动触发 Meta-Agent 替换 Prompt / 工具 / 模块逻辑|

---

## 四、使用场景参考

- **LLM 自动测试和反馈闭环优化**
    
- **AI 代码评审助手的自我质量把控**
    
- **多 Agent 协作系统的“自反 Agent”**
    
- **AI 写作或推理质量控制**
    

---

## 五、如果你要动手实现

我可以基于 LangChain / AutoGen / Flowise 帮你输出：

- 完整的多阶段 Prompt 配置（JSON / YAML）
    
- Streamlit Demo 展示
    
- 自评评分函数（OpenAI Function Calling / DSL 构建）
    

你想先在哪个平台上落地这个 Prompt Flow？比如：

- Notebook 流程原型？
    
- LangChain runnable？
    
- LangGraph/Flowise？
    

我可以一步步配合你 build。