---
view-count: 8
---


> **先保语义安全 & 行为稳定 → 再追求 Token 节省**

可以拆成几类因素来看。

---

## 1. 最先考虑：哪些信息“绝不能动”

这类信息，一旦压缩错了，模型行为就会**质变**，而不是“稍微差一点”。

### 1.1 任务定义 & 预期产出

- 任务是什么（Task）
- 对谁说（Audience）
- 要输出什么形式（Output format / schema）

这些我几乎**从不删，只会改写得更紧凑**。

例如：

> 「撰写关于量子计算未来影响的800-1000字科普文」

就可以压到：

> `TASK: 面向科普读者，写“量子计算未来影响”文章，800-1000字。`

信息没少，只是换了更密度高的表达。

### 1.2 关键约束（Constraints）

- 不能做什么（安全/合规）
- 必须遵守的风格/语气/界限（例如不能编造数据、保留引用）
- 会改变“输出形态”的指令

只要是**一删就会让行为类别变了**的，都不碰，最多用更短的表达：

- 原：  
  > 请不要编造参考文献，如果不确定，请明确说明不确定。
- 压缩：  
  > 约束：不得虚构引用；不确定需显式标注。

---

## 2. 优先删的：对行为几乎没贡献的“噪音”

### 2.1 礼貌 & 社交语气

诸如：

- 「你是一个非常专业、非常聪明的助手」
- 「请你务必认真、仔细地完成以下任务」

通常对大模型几乎没信息量，直接删。

### 2.2 冗余的“长句解释”

你例子里的第一轮优化就做得很好：

- 把「请确保语言通俗易懂，避免过多技术细节，同时保持内容的专业性和吸引力」  
  → 压成 「语言：通俗易懂，专业吸引，避免技术细节。」

我会系统性地：

- 拆长句 → 列点
- 去掉连接词，只保留**属性词 + 属性值**

---

## 3. 信息密度：用“结构化+关键词”替代自然语言

你第二种压缩方式就是我实际最常用的模式之一：

> 自然语言说明 → 变成「字段：值」的配置表

### 3.1 固定 Prompt 模板骨架

我基本会长期固定这几个段落标题：

```text
ROLE:
TASK:
CONTEXT:
CONSTRAINTS:
STYLE:
OUTPUT:
DATA:
```

好处：

- 信息一眼能扫完
- 方便后续程序/Agent 自动读写这些段落
- Token 非常可控

### 3.2 用“短语”替代“句子”

- 把「量子位 vs 经典比特：叠加和纠缠」  
  → 「量子位 vs 比特：叠加/纠缠」

只要模型能正常解码，我会尽量：

- 用 `/` 替代 “和、以及”
- 用缩写（MS、GPU、LLM 等模型熟悉的缩写）
- 删除“废词”：其实、然后、在这个背景下、可以说是…

---

## 4. 在压缩时我会刻意保护的三类信息

### 4.1 歧义消解信息

**凡是用来“防止误解”的内容，我会非常小心压缩。**

比如：

- 「目标读者是对科技有基本了解的普通大众」  
  这会影响：
  - 用不用公式
  - 解释到多细
  - 能不能假定量子力学知识

我会压成：

> `Audience: 对科技有基础认知的一般读者（非专业）`

而不是直接删掉“读者是谁”。

### 4.2 输出结构 / Schema

这个是我认为**最不可删**的一块：

- 要不要分段？
- 段落顺序是什么？
- 是否需要标题/小标题？
- 是否需要 JSON / Markdown 表格？

我通常会至少保留类似：

```text
结构：
1. 引言
2. 现状
3. 应用（药物/金融/...）
4. 挑战
5. 结论
```

并尽量不再压缩，因为这直接决定结果是否“可机读 / 易后处理”。

### 4.3 失败模式提示

如果我对某个任务非常了解常见坑（比如：爱编引用、爱乱推理），我会保留一行高密度约束：

```text
Failure modes to avoid:
- 编造具体数字/引用
- 使用超出DATA的结论
```

这类信息 **性价比极高**：1–2 行能显著提升稳定性，很少会是我砍掉的目标。

---

## 5. 多轮对话场景：我如何压缩“历史”

在 chat / agent 场景里，最大头往往不是 system prompt，而是**对话历史**。

我会按优先级排序：

1. **将历史总结成“状态摘要”**  
   - 用一小段 summary 替代十几轮往返
   - 保留：
     - 已确认的事实
     - 用户偏好/约束
     - 尚未解决的问题

2. **提取“决策影响点”**  
   - 哪句话改变了目标？
   - 哪一步引入了新的约束？

3. **丢弃社交闲聊 & 已完成的子话题细节**

在代码层面会有一个：

- `summarize_history(history) -> compressed_context`

用专门的摘要模式 prompt 去做这步，然后再把 `compressed_context` 塞回主任务 prompt 的 `CONTEXT:` 段。

---

## 6. 实际操作时，我会按这个顺序动手

一个实用 checklist：

1. **锁死 3 块不动：**
   - TASK / OUTPUT / CONSTRAINTS（核心约束）
2. **去噪：**
   - 删礼貌话、赞美话、重复强调
3. **结构化：**
   - 把自然语言改成 `字段: 值`、列表、缩写
4. **局部缩写：**
   - 合并词（叠加/纠缠）、缩短符号（vs, &）
5. **多轮对话时：**
   - 用“摘要+关键决策点”代替原始史

在这之后，如果还不够省 Token，我才会考虑：

- 减少示例数量（few-shot 里从 3 个降到 1 个）
- 压缩 research notes（像你例子中的 DATA 段）

---

## 7. 回到你的问题：我优先考虑什么？

用一句话概括：

> **先想“这条信息不见了会不会改变行为类别”，再想“它值不值得花这么多 Token”。**

换成更工程化的排序就是：

1. **语义安全 / 任务边界**（不能动）  
2. **歧义消解 / 输出结构**（慎动）  
3. **约束 & 失败模式提示**（高 ROI，尽量保留）  
4. **礼貌/冗余自然语言**（优先删）  
5. **表达形式**（用结构化/缩写提高信息密度）

如果你愿意，可以把你自己的一个真实长 prompt 发给我，我可以按这个优先级现场帮你压一版，并标出“我为什么敢删/不敢删这句”，这样会更直观。