---
view-count: 3
---

## **技能点1：事件驱动微服务 & 分布式消息**

### **第一层：基石概念** ★

|概念|核心|为什么|
|---|---|---|
|**EDA（事件驱动架构）**|发布/订阅 → 服务解耦 + 异步通信|复杂业务异步化|
|**CAP定理**|一致性 ↔ 可用性 ↔ 分区容错 (选2)|分布式系统权衡|
|**最终一致性**|短期不一致 → 最终一致|CAP下的可用性方案|
|**Saga模式**|分布式事务 = 本地事务序列|跨服务原子性|
|**幂等性**|重复执行 = 单次执行结果|消息重试/重复处理安全|
|**消息可靠性**|持久化 + 确认 + 死信队列|不丢消息|

### **第二层：应用模式** △

|场景|技术选择|关键配置|
|---|---|---|
|订单处理流|RabbitMQ/Kafka|`durable=True` + `delivery_mode=PERSISTENT`|
|库存扣减|消费者 + 幂等ID|`basic_qos(prefetch_count=1)` + `basic_ack`|
|任务失败恢复|死信队列 + 重试|`basic_nack(requeue=True)`|
|高吞吐流处理|Kafka (分区+消费组)|并行消费 + 偏移量管理|

### **第三层：反常识** ❗

|陷阱|真相|
|---|---|
|❗ 消息队列=实时处理？|✗ 异步特性 → 延迟必然存在|
|❗ 发送成功=业务成功？|✗ 需确认消费端处理成功|
|❗ Saga一定强一致？|✗ 最终一致性；需补偿机制|
|❗ prefetch_count越高越快？|✗ 过高 → 消费端过载；需平衡|

### **第四层：代码骨架**

```python
# 生产者（订单服务）
publish_event(order_data):
  - json.dumps(data)
  - channel.basic_publish(..., delivery_mode=PERSISTENT)
  - 异常处理:连接失败 → 重试或存储本地

# 消费者（库存服务）
consume_event(ch, method, body):
  - json.loads(body) → order_data
  - 业务处理(可能失败)
  - success → ch.basic_ack()
  - fail → ch.basic_nack(requeue=True) → 死信队列

# 配置
- durable=True      → 服务重启消息不丢
- prefetch_count=1  → 一次一条，处理完再取
- basic_qos()       → 消费端背压
```

### **技能检查清单**

- [ ] 理解 CAP 权衡：为什么最终一致性 > 强一致性？
- [ ] 实现幂等：订单ID/requestID 去重
- [ ] 设计 Saga：多服务事务补偿逻辑
- [ ] 处理死信：失败消息的隔离与人工处理

---

## **技能点2：MLOps - 生产级AI模型部署**

### **第一层：基石概念** ★

|概念|核心|为什么|
|---|---|---|
|**MLOps**|DevOps 原则 → ML完整生命周期自动化|模型从实验 → 生产 → 监控|
|**模型版本控制**|代码版本 + 数据版本 + 模型版本|可复现性 + 回溯|
|**数据漂移**|生产数据分布 ≠ 训练数据|模型性能下降根源|
|**模型漂移**|模型预测能力衰减|周期重训|
|**特征存储**|共享特征库 → 训练/serving一致|避免特征差异 bug|
|**A/B测试 + Canary**|灰度发布新模型 → 评估真实效果|风险控制|

### **第二层：部署架构** △

```
训练管道(Airflow/Kubeflow)
    ↓
模型注册中心(MLflow)
    ↓
模型服务(FastAPI/TensorFlow Serving)
    ↓ (A/B/Canary)
线上推理(容器化 + K8s)
    ↓
监控系统(Prometheus + 自定义指标)
    ↓ (漂移检测)
触发重训
```

### **第三层：代码骨架**

```python
# 服务启动
@app.on_event("startup")
  load_model(MODEL_PATH) → joblib.load()

# 健康检查（K8s liveness probe）
@app.get("/health")
  return {status: "ok", model_loaded: bool}

# 预测接口
@app.post("/predict")
  features → model.predict() → response
  异常 → HTTPException(503)

# 监控指标（Prometheus）
- 请求延迟: histogram
- 预测类别分布: gauge
- 模型版本: label
```

### **第四层：部署清单**

|步骤|实现|
|---|---|
|**模型训练保存**|`joblib.dump(model, path)`|
|**容器化**|Dockerfile: 复制模型 + 启动uvicorn|
|**镜像构建**|`docker build -t model-service .`|
|**K8s部署**|liveness/readiness probe + resource limit|
|**灰度发布**|新旧版本 Pod 占比逐步调整|
|**监控告警**|预测延迟 > threshold → 降级/告警|

### **反常识** ❗

|陷阱|真相|
|---|---|
|❗ 模型训练精度高 = 上线好？|✗ 需考虑数据漂移、延迟、成本|
|❗ 一次部署永远可用？|✗ 数据漂移 → 性能衰减 → 周期重训|
|❗ 模型大 = 精度好？|✗ 需权衡：精度 vs 延迟 vs 成本|

### **技能检查清单**

- [ ] 实现模型版本控制与切换
- [ ] 设计特征一致性检查
- [ ] 监控模型性能指标
- [ ] 实现灰度发布流程

---

## **技能点3：高性能异步编程与并发控制**

### **第一层：基石概念** ★

|概念|核心|为什么|
|---|---|---|
|**异步I/O**|不阻塞 → 事件循环驱动|高并发处理I/O密集任务|
|**协程**|轻量级 → 用户态调度|比线程更轻，几千个无压力|
|**事件循环**|中央调度器 → 任务队列驱动|单线程异步执行|
|**GIL（全局解释器锁）**|Python多线程 = 伪并行|CPU密集 → 用进程；I/O密集 → 用线程/协程|
|**临界区 & 同步**|Lock/Semaphore/Queue|避免竞争条件|
|**并发 vs 并行**|并发=任务切换；并行=真正同时|理解操作系统调度|

### **第二层：应用场景** △

|场景|技术|优势|
|---|---|---|
|I/O密集（HTTP请求/DB）|asyncio + aiohttp|几千并发无压力|
|CPU密集（计算）|ProcessPoolExecutor|真正并行|
|混合（I/O + CPU）|asyncio + ThreadPool|灵活组合|
|实时数据流|async生产者/消费者|背压管理|
|游戏/交易系统|事件循环 + 高精度定时器|低延迟|

### **第三层：代码骨架**

```python
# 异步函数（协程）
async def fetch_url(session, url):
  async with session.get(url) as response:
    return await response.json()

# 并发执行（gather保持顺序）
async def main():
  tasks = [fetch_url(session, url) for url in urls]
  results = await asyncio.gather(*tasks, return_exceptions=True)

# 并发网络请求
async with aiohttp.ClientSession() as session:
  → 复用连接（重要！）

# 超时 + 错误处理
try:
  await asyncio.wait_for(task, timeout=10)
except asyncio.TimeoutError:
  → 处理超时
```

### **第四层：性能优化**

|优化点|实现|
|---|---|
|**连接复用**|单个 ClientSession 复用 vs 每次新建|
|**超时设置**|`timeout=10` → 防止僵尸请求|
|**异常处理**|`return_exceptions=True` → 单个失败不影响其他|
|**背压**|`asyncio.Semaphore(n)` → 限制并发数|
|**事件循环优化**|`uvloop` 替代 asyncio 默认|

### **反常识** ❗

|陷阱|真相|
|---|---|
|❗ async更快？|✗ async只在I/O等待时优势大|
|❗ 协程就是多线程？|✗ 协程是伪并行(单线程)；多线程才是真并行|
|❗ await就异步了？|✗ 必须是异步函数(async def)且有事件循环|
|❗ 并发越高越好？|✗ 过高 → 连接数限制 / 服务端过载；需限流|
|❗ Thread pool for I/O？|✗ 用asyncio更轻；Thread pool for CPU|

### **技能检查清单**

- [ ] 区分 I/O密集 vs CPU密集，选择并发策略
- [ ] 实现异步HTTP并发请求（aiohttp）
- [ ] 处理超时 + 异常 + 背压
- [ ] 性能对比：同步 vs 异步 的耗时差异
- [ ] 理解GIL对多线程的限制

---

## **三个技能点的快速诊断**

### 什么时候用什么？

```
问题类型？
├─ 多个微服务间松耦合通信
│  └─ → 技能点1: 事件驱动 + 消息队列
│     关键词: Kafka, RabbitMQ, Saga, 幂等性
│
├─ 模型从训练 → 部署 → 监控生命周期
│  └─ → 技能点2: MLOps
│     关键词: 版本控制, 漂移检测, A/B测试, 灰度发布
│
├─ 高并发I/O场景（HTTP/网络/DB）
│  └─ → 技能点3: 异步编程
│     关键词: asyncio, aiohttp, 协程, 事件循环
│
└─ CPU密集计算
   └─ → 技能点3: 进程池
      关键词: ProcessPoolExecutor, GIL绕过
```

---

## **完整生产级应用示例**

### **场景：推荐系统微服务架构**

```
用户请求
    ↓
[API Gateway]
    ↓
[推荐服务 - 异步编程]
  asyncio + aiohttp
  并发调用: 特征服务 + 模型服务 + 缓存
    ↓
[模型服务 - MLOps]
  FastAPI + TensorFlow Serving
  A/B测试: v1 vs v2 灰度发布
    ↓
[特征计算 - 事件驱动]
  消费 Kafka topic
  特征实时更新 + 特征存储
    ↓
响应用户 (P99延迟 < 100ms)
```

### **核心要点**

1. **异步**: API层并发获取多个微服务数据
2. **MLOps**: 模型版本管理 + 灰度发布
3. **事件驱动**: 特征更新通过消息队列异步同步

---

## **复习触发点**

|时长|内容|用途|
|---|---|---|
|5min|三层基石表 + 技能诊断树|快速回忆|
|15min|加上应用模式 + 代码骨架|深化理解|
|30min|完整生产架构 + 反常识|设计系统|
|AI提问|_"这个系统的延迟如何优化？"_ → asyncio||
||_"模型如何灰度上线？"_ → A/B测试||
||_"消息丢失怎么办？"_ → 持久化+确认||

---

**生成时间**：2025-12-13 | **版本**：1.0 | **用途**：系统设计面试/生产部署