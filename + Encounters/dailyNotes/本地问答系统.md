---
aliases: Untitled
createdAt: 2024-12-10 18:55
updateAt: 2024-12-10 18:55
categories:
  - Mindset
tags:
  - Mindset/Reflection
---

![image.png](https://cdn.jsdelivr.net/gh/duanbiao2000/BlogGallery@main/picture/202412101858472.png)

这张图展示了基于大型语言模型（LLM）和向量存储（VectorStore）的本地问答系统（Local QA system）的工作流程。以下是根据图示梳理的详细流程：
### 1. 原始文档处理
- **原始文档**：包括PDF、Word、URL、Json等格式的文档。
- **文本转换**：将原始文档转换为{{文本}}格式。
- **文本分割**：将转换后的文本{{分割成多个片段}}（chunks）。
- **Embedding Model**：使用嵌入模型（如[BERT、Sentence Transformer]等）将每个文本片段转换为{{向量}}表示。
- **向量存储**：将这些向量存储到向量数据库（如[ADB-PG]）中。
### 2. 问题处理
- **聊天历史 + 新问题**：用户输入的新问题以及之前的聊天历史。
- **问题提炼**：将聊天历史和新问题输入到LLM中，提炼出融合的问题。
- **独立问题**：从提炼出的问题中提取出独立的问题。
### 3. 向量检索
- **向量检索**：使用[独立问题的向量表示]在向量数据库中进行检索，找到最相关的文本内容（知识）。
- **返回搜索内容**：将检索到的[最相关文本内容]返回给LLM。
### 4. 推理求解
- **推理求解**：LLM结合独立问题和相关知识进行推理求解，生成最终的答案。
- **答案**：将推理得出的答案返回给用户。
### 流程图总结
1. **原始文档处理**：
   - 文档转换为文本。
   - 文本分割成多个片段。
   - 使用[Embedding Model]将文本片段转换为向量。
   - 向量存储到[ADB-PG]。

2. **问题处理**：
   - 输入聊天历史和新问题。
   - 使用LLM提炼问题。
   - 提取出独立问题。

3. **向量检索**：
   - 使用独立问题的向量在ADB-PG中检索相关知识。
   - 返回最相关的文本内容。

4. **推理求解**：
   - LLM结合独立问题和相关知识进行推理。
   - 生成最终答案并返回给用户。

### 关键组件
- **Embedding Model**：用于将文本转换为向量表示。
- **VectorStore (ADB-PG)**：用于存储和检索向量。
- **LLM**：用于问题提炼、推理求解。

### 优点
- **高效检索**：通过[向量检索]快速找到相关知识。
- **融合信息**：结合聊天历史和新问题，提供更准确的答案。
- **灵活性**：可以处理多种格式的文档，并适应不同的问答场景。

### 应用场景
- **智能客服**：快速响应用户问题。
- **知识库查询**：提供精准的[知识检索]。
- **教育辅导**：辅助学生学习和解答问题。



