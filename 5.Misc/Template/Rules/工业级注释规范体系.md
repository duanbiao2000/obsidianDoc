---
view-count: 4
---
## 大公司推荐的注释规范体系

基于你的Google背景和五年编程经验，我直接分享**工业级标准**而不是入门资料：

### 1. **RFC 2119风格的需求级别标准**

RFC 2119定义了不同的需求等级——如"MUST""SHOULD"等，帮助避免歧义。这个思路可以应用到内部文档：

```python
# MUST: 每个public API必须有docstring
# SHOULD: 复杂算法应添加行内注释解释思路
# MAY: 显而易见的代码可以不注释
```

### 2. **Google Python风格指南（你最熟悉的标准）**

Google标准要求docstring使用三引号格式，摘要行不超过80字符，以句号/问号/感叹号结尾。核心规范包括：

**文档字符串分层：**

- **模块级** - 描述文件整体目的、使用场景
- **类级** - 类的职责、主要接口、使用示例
- **函数级** - docstring应描述调用语法和语义，而非实现细节；复杂代码应用代码旁的注释而非docstring

**实践示例：**

```python
def fetch_distributed_cache(keys: list[str], timeout_ms: int) -> dict[str, bytes]:
    """获取分布式缓存中的多个键值对。
    
    该函数自动处理缓存穿透、一致性哈希路由等。
    与同步版本相比，采用批量fetch减少网络往返。
    
    Args:
        keys: 要查询的键列表（必须非空）
        timeout_ms: 单个后端响应超时，默认5000ms。若超过10000ms会触发断路器
        
    Returns:
        键到值的映射。缺失的键不出现在字典中（而非设为None）
        
    Raises:
        ValueError: 如果timeout_ms不在[100, 10000]范围内
        CircuitBreakerError: 若后端连续失败超过阈值
        
    Note:
        此函数在高P99延迟场景下使用batch read优化，见设计文档#1234。
        关键路径已profile，修改需运行benchmark suite。
    """
```

### 3. **Facebook/Meta的注释哲学**

Facebook强调在代码旁的注释应聚焦于阐明整体目标和必要性，而非总结代码在做什么；推荐用完整句子，限制在79字符宽度。

**关键区别：**

```python
# ❌ 总结代码：这是Facebook反对的风格
items = [item for item in data if item.valid]  # 过滤有效项

# ✅ 解释目标：Facebook推荐的风格
items = [item for item in data if item.valid]  # 移除失效项以减少后续处理的内存占用
```

### 4. **场景导向的注释策略**

根据代码审查对象，采用不同注释风格：

|场景|注释方式|例子|
|---|---|---|
|**API文档阅读**|详细docstring + 类型提示|公开函数必须有Args/Returns/Raises|
|**新手onboarding**|大量模块级注释、示例代码|"# 这里为什么使用双指针？见算法教科书3.2节"|
|**code review**|精准的"为什么"注释|"# O(1)查询需要预计算哈希表，而非动态构建"|
|**性能优化代码**|标注trade-off和度量|"# FIXME: 递归深度限制100，超出改用迭代（见perf#567）"|
|**跨团队集成**|明确的边界条件|"# start和end都是闭区间[start, end]，与标准库range()不同"|

### 5. **MISRA/CERT标准（安全关键系统）**

虽然你在Google做应用开发，但了解这些有用：

MISRA是汽车行业的编码标准，强调一致性和安全性；CERT是开源且允许社区反馈的安全编码标准。这两种方法展示了两种极端：

- **MISRA风格**：严格统一，适合生命周期关键代码
- **CERT风格**：灵活开放，适合快速迭代

### 6. **现代企业的RFC系统**

许多工程组织采用内部RFC流程，强调"及时胜过完美"的哲学，代码审查工具（GitHub、GitLab）可以捕捉RFC讨论历史。

**大型决策的注释应包含：**

```python
# RFC-2024-001: 为什么从Redis换到Memcached？
# 
# 背景：P99延迟在高峰期超过200ms
# 决策：Memcached的一致性哈希在我们场景下性能更好
# 代价：失去持久化能力，但缓存本身就是易失性的
# 审评者：@team-infra (approved 2024-01-15)
# 撤销方案：见wiki/memcached_rollback.md
```

---

## Google & Facebook 注释规范对比与综合指南


|维度|Google 标准|Facebook 标准|核心差异|
|---|---|---|---|
|**设计哲学**|全面自足，文档优先|简洁实用，目标优先|G强调API文档完整性；F强调为什么而非是什么|
|**文档字符串**|强制、详细、结构化|可选、精简、面向阅读者|G: 类似API文档；F: 像代码注释一样简洁|
|**行内注释**|补充docstring|主要沟通渠道|F更依赖代码旁的解释|
|**长度限制**|摘要≤80字符|整体≤79字符宽度|都强调简洁，但G允许详细的多行描述|
|**格式化**|严格的Args/Returns/Raises|自然语言段落|G便于工具解析；F便于人类阅读|
|**修改代码时**|更新docstring|更新代码旁注释|G: 改实现也改说明文档；F: 改实现就得说明为什么改|

---

## Google Python 风格指南（详细版）

### 1. 模块级注释（Module Docstring）

```python
# google_style.py
"""模块简述：一句话说明本模块的核心职责。

更详细的描述（可选）：如果模块功能复杂，在空行后添加详细说明。
可以包括：
- 模块解决的问题
- 使用示例
- 相关的设计文档链接

Typical usage example:
    from google_style import DistributedCache
    cache = DistributedCache(servers=['server1', 'server2'])
    value = cache.get('key')
"""
```

**规范要点：**

- 首行是模块的单句摘要
- 摘要后空行，然后是详细描述
- 包含"Typical usage example"部分展示如何使用
- 模块级别适合解释整个文件的架构

### 2. 类级注释（Class Docstring）

```python
class DistributedCache:
    """分布式缓存管理类，支持一致性哈希和自动故障转移。
    
    该类封装了与多个缓存服务器的交互逻辑，包括：
    - 请求路由（基于一致性哈希）
    - 连接池管理
    - 故障检测与自动重试
    
    为了减少网络往返，该类使用批量操作。单个Get/Set的延迟约5ms，
    批量操作(batch_get)的延迟约10ms(而非5*N ms)。
    
    Attributes:
        servers: 缓存服务器地址列表
        timeout_ms: 单个请求的超时时间（毫秒）
        max_retries: 失败重试次数
        
    Example:
        cache = DistributedCache(
            servers=['cache1:6379', 'cache2:6379'],
            timeout_ms=5000
        )
        value = cache.get('user_123')
        cache.set('user_456', value, ttl_seconds=3600)
    """
```

**规范要点：**

- 首行是类的单句摘要
- 说明类的主要职责和设计考量
- Attributes部分列出public属性
- 提供完整的使用示例
- 如果有复杂的初始化逻辑，可在__init__的docstring中说明

### 3. 函数/方法级注释（Function Docstring）

```python
def batch_get(
    self,
    keys: list[str],
    timeout_ms: int = 5000,
    skip_missing: bool = True
) -> dict[str, bytes]:
    """从缓存批量获取多个键的值。
    
    此方法是get()的性能优化版本。单个get()会为每个键发起一次网络请求，
    而batch_get()将所有键打包在一个请求中发送，显著减少往返延迟。
    
    在高并发场景下，batch_get()的P99延迟约为10ms，而单个get()的P99
    延迟约为50ms（取决于缓存层拓扑）。
    
    Args:
        keys: 要查询的键列表。必须非空，最多1000个键（受网络包大小限制）。
        timeout_ms: 单个后端响应的超时时间。有效范围[100, 10000]。
                    超过10000ms会被视为慢查询并触发断路器。
        skip_missing: 如果为True（默认），返回的字典中不包含缺失的键；
                      如果为False，缺失的键对应值为None。
    
    Returns:
        键到值的映射字典。如果skip_missing=True，缺失的键不出现；
        如果skip_missing=False，缺失的键值为None。
        值的编码格式为UTF-8（与set()兼容）。
    
    Raises:
        ValueError: 如果keys为空或timeout_ms不在有效范围内。
        ConnectionError: 如果无法连接到任何缓存服务器。
        TimeoutError: 如果所有后端都在timeout_ms内未响应。
    
    Note:
        此方法已通过benchmark suite验证（见性能测试结果#2024-01）。
        修改实现时必须运行完整的性能测试，以保持延迟SLA。
        
    See Also:
        get(): 单键查询的简单版本
        batch_set(): 对应的批量写操作
    """
    # 实现代码...
```

**规范要点：**

- Args: 每个参数一行，包括类型、含义、默认值、约束条件
- Returns: 说明返回值的类型、含义、边界情况
- Raises: 列出可能抛出的异常及触发条件
- Note: 性能特性、设计决策、已知限制、profile结果
- See Also: 相关函数的交叉引用

### 4. 代码行内注释（Inline Comments）

```python
def _route_to_server(self, key: str) -> str:
    """根据一致性哈希选择目标服务器。"""
    # 计算键的哈希值。使用xxHash而非MD5是因为：
    # 1. xxHash速度快3倍（关键路径上频繁调用）
    # 2. 对于缓存键分布不需要密码学强度
    # 3. 与Facebook Memcached社区的选择一致
    hash_value = xxhash.xxh64(key).intdigest()
    
    # 在哈希环上找到最近的服务器。若选中的服务器故障，
    # _find_next_available()会自动跳到下一个服务器（见故障转移文档）
    server_index = hash_value % len(self.servers)
    return self._find_next_available(server_index)
```

**规范要点：**

- 解释"为什么"这样做，而非"在做什么"
- 说明设计决策和trade-off
- 可以引用相关文档、issue号等
- 复杂算法可以在注释中给出伪代码或参考

### 5. TODO/FIXME/XXX标记

```python
# TODO: 当升级到Python 3.10+时，用match语句重构这个if-elif链
# FIXME: 这里有race condition。多线程并发调用时缓存状态可能不一致。
#        修复方案：见issue #1234，需要添加线程锁
# XXX: 性能瓶颈！此处的O(n)循环在keys>1000时成为hot path。
#      临时方案可行但需要在下个sprint重构为hash table（已profile）
```

---

## Facebook 注释规范（详细版）

### 核心哲学

Facebook 的注释哲学更简洁直接：**注释应该阐明整体目标和必要性，而非总结代码在做什么**。

### 1. 模块级注释

```python
# distributed_cache.py
#
# Distributed cache manager with consistent hashing and failover support.
# Uses batch operations to reduce network round-trips in high-concurrency
# scenarios. See design doc at: wiki/cache-redesign-2024.
#
# Key assumptions:
# - All cache servers are behind a stable load balancer
# - Network is reliable (no Byzantine failures)
# - Keys are <= 512 bytes (enforced by memcached protocol)
```

**规范要点：**

- 简洁的单行或多行注释
- 直接说明模块的目的，避免冗长的docstring
- 包含相关的设计文档、wiki链接
- 列举关键假设和约束条件

### 2. 类级注释

```python
# Manages connections to multiple cache servers and routes requests
# based on consistent hashing. Automatically handles server failures
# by skipping to the next available server in the hash ring.
class DistributedCache:
    def __init__(self, servers, timeout_ms=5000):
        # Validate input parameters before initialization
        if not servers:
            raise ValueError("servers list cannot be empty")
        if timeout_ms < 100 or timeout_ms > 10000:
            raise ValueError("timeout_ms must be in range [100, 10000]")
        
        self.servers = servers
        self.timeout_ms = timeout_ms
```

**规范要点：**

- 使用多行注释块说明类的责任
- 不使用 Attributes 这样的结构化字段
- 重点放在"这个类为什么存在"而非"它有什么属性"

### 3. 函数级注释

```python
def batch_get(self, keys, timeout_ms=5000, skip_missing=True):
    # Optimized version of get() that batches multiple requests into
    # a single network round-trip. Reduces P99 latency from ~50ms to ~10ms
    # in production. Cost: must aggregate results on client side.
    # See perf analysis: go/batch-get-optimization-2024
    
    if not keys:
        raise ValueError("keys cannot be empty")
    if timeout_ms not in range(100, 10001):
        raise ValueError("timeout_ms must be in [100, 10000]")
    
    # Pack keys into a single request to minimize network overhead.
    # Memcached protocol has a 1MB request limit, so we batch up to
    # 1000 keys per request (empirically determined).
    results = self._fetch_from_backends(keys, timeout_ms)
    
    # Filter out missing keys if requested. This is the common case
    # since we don't want None values cluttering the response.
    return {k: v for k, v in results.items()} if skip_missing else results
```

**规范要点：**

- 不使用 Args/Returns/Raises 这样的结构
- 注释聚焦于：为什么这样设计、关键的性能特性、trade-off
- 在代码行内说明非显而易见的逻辑
- 参考内部文档时使用 go/xxx 短链接

### 4. 代码行内注释（Facebook风格更频繁）

```python
def _route_to_server(self, key):
    # Use xxHash instead of MD5 because we don't need cryptographic
    # strength, just good distribution. xxHash is 3x faster on the
    # hot path (called millions of times per second).
    hash_value = xxhash.xxh64(key).intdigest()
    
    # Find the server in the hash ring. If it's down, skip to the next one.
    # Failover is automatic; we just try the next index in round-robin order.
    server_index = hash_value % len(self.servers)
    return self._find_next_available(server_index)
```

**规范要点：**

- 比Google更频繁地添加行内注释
- 解释为什么选择这个算法/方案而非其他
- 说明性能影响和trade-off
- 不需要 docstring 来说明参数类型（假设代码足够清晰）

### 5. 特殊标记

```python
# HACK: Temporarily increase timeout to 30s for this specific customer
# because their network is unusually slow. Real fix: migrate them to
# the new cached topology (ETA: Q2 2024). See ticket #8901.
if customer_id == "special_customer_123":
    timeout_ms = 30000

# BUG: Race condition here. Multiple threads can enter the critical
# section simultaneously if the lock acquisition fails. Proper fix
# requires refactoring to use a distributed lock. Workaround: retry
# with exponential backoff (current code).
```

---

## 两种风格的适用场景

### 使用 Google 标准的场景

1. **开源库和公共API** - 需要为外部用户提供完整、自足的文档
2. **企业框架层代码** - 需要维持一致的接口文档标准
3. **团队新人onboarding** - 结构化的docstring便于快速学习
4. **API文档生成** - Sphinx/自动化工具可以直接解析Google风格
5. **长期维护的核心模块** - 完整文档有利于长期可维护性

**典型项目：** Google内部库、TensorFlow、Django等

### 使用 Facebook 标准的场景

1. **高速迭代的业务代码** - 注释跟随代码变化更灵活
2. **关键性能路径** - 注释强调为什么的选择，便于优化决策
3. **内部工具和脚本** - 不需要对外部用户的API承诺
4. **代码审查密集的团队** - 简洁的注释加快审查速度
5. **微服务和模块边界明确的系统** - 模块职责单一，不需要详细文档

**典型项目：** Facebook内部基础设施、快速迭代的后端服务

---

## 综合版本：最佳实践混合标准

针对大多数专业项目（特别是Google规模的团队），建议采用这个混合方案：

### 原则

1. **分层清晰** - 模块级 > 类级 > 函数级 > 行内
2. **Google式的结构** - 用于API边界和公开接口
3. **Facebook式的简洁** - 用于内部实现和性能关键路径
4. **场景适配** - 根据代码的生命周期和修改频率调整

### 综合示例

```python
"""distributed_cache.py

分布式缓存管理器，支持一致性哈希和自动故障转移。
使用批量操作减少高并发场景下的网络往返。

设计文档: wiki/cache-redesign-2024
性能基准: go/cache-perf-2024
"""

class DistributedCache:
    """Distributed cache with consistent hashing and automatic failover.
    
    This class handles routing requests to multiple cache servers based on
    consistent hashing, with automatic failover to the next available server.
    Batch operations are optimized to reduce network round-trips.
    
    Attributes:
        servers: List of cache server addresses (host:port format)
        timeout_ms: Request timeout in milliseconds [100, 10000]
        
    Example:
        cache = DistributedCache(['server1:6379', 'server2:6379'])
        values = cache.batch_get(['key1', 'key2'])
    """
    
    def batch_get(self, keys: list[str], timeout_ms: int = 5000) -> dict:
        """批量获取缓存值，减少网络往返延迟。
        
        与单个get()相比，此方法将所有请求打包在一次网络往返中发送，
        在高并发场景下能将P99延迟从~50ms降低到~10ms。
        
        Args:
            keys: 要查询的键列表（最多1000个）
            timeout_ms: 后端响应超时时间（默认5000ms）
            
        Returns:
            键值对字典，缺失的键不出现
            
        Raises:
            ValueError: 如果keys为空或timeout_ms超出范围
            ConnectionError: 无法连接到任何缓存服务器
        """
        if not keys:
            raise ValueError("keys cannot be empty")
        
        # Pack multiple keys into a single request to minimize network overhead.
        # Memcached protocol has ~1MB limit, empirically we batch up to 1000 keys.
        # This single round-trip replaces N individual round-trips, saving ~40ms
        # per request in typical datacenter latency (1ms per hop * 20 hops * 2).
        results = self._fetch_from_backends(keys, timeout_ms)
        
        # Return only keys that exist. The absence of a key in the dict is
        # the idiomatic way to handle cache misses in our codebase (vs None values).
        return results
```

### 核查清单

使用此清单来判断每个注释是否足够：

- **模块级**: ✓ 一句话摘要 + 设计文档链接 + 关键假设
- **类级**: ✓ 职责说明 + 使用示例 + Attributes（仅public）
- **公开函数**: ✓ Args + Returns + Raises + 性能特性 + 设计决策
- **内部函数**: ✓ 为什么这样做（可以更简洁）
- **性能关键代码**: ✓ 为什么选择这个方案 + 性能指标 + trade-off
- **复杂算法**: ✓ 参考资料或伪代码 + 时间/空间复杂度
- **跨团队API**: ✓ 边界条件明确说明 + 典型使用示例

---

## 总结对比表

| 尺度       | Google                   | Facebook | 综合推荐                 |
| -------- | ------------------------ | -------- | -------------------- |
| **模块**   | 详细docstring              | 简洁注释块    | 一句摘要 + 设计文档链接        |
| **类**    | 完整docstring + Attributes | 简洁多行注释   | Docstring含Attributes |
| **公开函数** | 详细Args/Returns/Raises    | 注释说明目的   | 两者结合                 |
| **私有函数** | 完整docstring              | 简洁注释     | 简洁注释即可               |
| **性能代码** | 在Note中说明                 | 注释强调选择   | 行内注释 + 性能指标          |
| **工具支持** | Sphinx自动生成文档             | 便于代码审查   | Sphinx + 清晰的审查       |