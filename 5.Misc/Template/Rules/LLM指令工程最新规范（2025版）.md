---
view-count: 6
---
# LLM指令工程最新规范（2025版）

## 一、规范评估矩阵

### 保持有效的核心规范（Green - 依然关键）

|规范|有效性|进化说明|
|---|---|---|
|**结构化指令**|🟢 核心|从单纯的格式化升级到"信息层次结构优化"|
|**精确指定输入/输出**|🟢 核心|从"明确格式"升级到"上下文链路追踪"|
|**量化约束**|🟢 核心|从"数字限制"升级到"动态约束协商"|
|**定义边界条件**|🟢 核心|从"错误处理"升级到"容错设计"|
|**保持一致性**|🟢 核心|从"风格一致"升级到"认知一致"|

### 需要更新的规范（Yellow - 部分失效）

|规范|更新原因|新方向|
|---|---|---|
|**祈使句直接命令**|现代LLM更擅长理解目标导向而非指令|转向"目标描述 + 上下文推理"|
|**明确禁止项**|简单否定易引发"禁忌效应"，导致相反结果|转向"正面引导 + 替代方案"|
|**示例（可选）**|已被证实为必需，不再"可选"|升级为"必须，且需多模态示例"|

### 需要推翻的规范（Red - 过时失效）

|规范|失效原因|替代方案|
|---|---|---|
|**语言明确直接**|新模型对微妙的语言理解能力大幅提升|"多模态对齐"：用意图+需求而非命令|
|**提供操作细则**|过度规定导致模型创意受限|"框架 + 自主判断空间"：设定边界而非细节|

---

## 二、最新规范（2025年版本）

### 规范1️⃣：目标导向表述（替代"祈使句"）

**❌ 过时做法**：

```
"你要按照以下步骤生成对比表："
```

**✅ 最新做法**：

```
"目标：为用户提供清晰的特征对比，让他们快速做出决策。
上下文：用户需要在三个技术方案之间选择。
评估维度：成本、性能、维护难度、学习曲线。"
```

**核心差异**：

- 旧方式：命令式 → 新方式：目标导向式
- 旧方式：HOW → 新方式：WHY + WHAT，让模型推断HOW
- **好处**：模型能更好地权衡和创新，不会机械地遵循可能不适配的细节

**使用场景**：

- 需要创意输出的任务（内容生成、方案设计）
- 需要上下文理解的复杂任务
- 希望模型自主判断的开放性问题

---

### 规范2️⃣：信息层次结构（升级"结构化指令"）

**❌ 旧方式** - 只关心格式：

```markdown
- 列出原因
- 分别说明
- 总结结论
```

**✅ 新方式** - 明确认知层次：

```
【第一层】问题的本质定义
  输入：具体问题描述
  输出：问题的核心矛盾

【第二层】根本原因分析
  输入：问题本质
  输出：3-5个根因，按影响程度排序

【第三层】解决方案谱系
  输入：根因
  输出：针对每个根因的解法，含trade-off

【第四层】可执行性评估
  输入：方案谱系
  输出：优先级排序（按ROI排序，不是按提出顺序）

【第五层】行动计划
  输入：优先级方案
  输出：周期、成本、成功指标
```

**核心差异**：

- 旧方式：线性的步骤 → 新方式：递进的认知深度
- 旧方式：形式上的结构 → 新方式：意义上的层次

**好处**：

- 避免"虚假的结构化"（看起来有逻辑，其实很浅）
- 强制模型进行深度思考，每层都有明确的输入产生输出
- 便于追踪和修改：如果第二层不满意，可以单独重做而无需整体返工

---

### 规范3️⃣：上下文链路追踪（升级"输入/输出"）

**❌ 旧方式** - 割裂的I/O：

```
"输入：用户需求文本
输出：技术方案文档"
```

**✅ 新方式** - 链路完整：

```
【来源追踪】
  输入源：来自上一步的"问题诊断报告"（若无则基于用户直述）
  上文依赖：需要参考系统现状背景
  
【处理逻辑】
  1. 从诊断报告提取"关键制约因素"
  2. 对标"组织的技术栈偏好"（若有）
  3. 生成3个可行方案，各含完整trade-off分析
  
【输出规范】
  格式：Markdown表格 + 决策矩阵
  粒度：每个方案需含5个对比维度（成本、性能、学习曲线、维护难度、扩展性）
  量化：成本用$表示，性能用数字量化
  
【可追溯性】
  - 每个方案的依据需标注"来自诊断报告的哪个洞察"
  - 如果方案引入新的假设，需显式说明
  
【后续输入预期】
  下一步输入可能是："选择的方案是X，现在需要详细实现计划"
  → 为此预留接口：方案ID、可扩展参数等
```

**核心差异**：

- 旧方式：孤立的输入输出 → 新方式：链式的上下文追踪
- 旧方式：一次性任务 → 新方式：可迭代的工作流

**好处**：

- 避免"信息丢失"：每一步都能追溯来源
- 支持增量改进：如果中间某一步有问题，可以只调整那一步
- 模型能理解"这不是独立的问题，而是系列问题的第N个"

---

### 规范4️⃣：动态约束协商（升级"量化约束"）

**❌ 旧方式** - 僵化的数字限制：

```
"输出3个主要原因，不超过5条建议，长度100-150字"
```

**✅ 新方式** - 动态和有理由的约束：

```
【基础约束】
  - 原因数量：通常3个，但允许2-5个，如果存在（根因数<2或>5需说明理由）
  - 建议条数：按优先级递减，至少包含"必做"和"可选"两类
  - 长度目标：600-800字（足以表达完整逻辑），可超出但需说明为什么

【动态调整触发器】
  IF 问题复杂度高 THEN 允许增加根因数量，同时增加每个根因的说明深度
  IF 用户明确表示"要快速版本" THEN 压缩到200字核心要点，省略示例
  IF 输出包含高度技术化内容 THEN 保持详细程度，哪怕超出基础长度

【质量保证不降低】
  无论长度如何调整，必须保证：
  ├── 每条建议都可执行（不是抽象口号）
  ├── trade-off明确（不是假中立）
  └── 优先级合理（按ROI而非字数排序）
```

**核心差异**：

- 旧方式：数字约束是硬限制 → 新方式：数字约束是指导而非锁链
- 旧方式：规则相同适用所有情况 → 新方式：规则根据上下文灵活调整

**何时使用**：

- 需要模型判断"何时该精简，何时该详细"的任务
- 想要避免"为了凑字数而水字数"的情况
- 需要自适应输出的复杂任务

---

### 规范5️⃣：正面引导（替代"明确禁止"）

**❌ 旧方式** - 简单的禁止：

```
"禁止生成模糊的建议。
不要使用行业术语而不解释。
绝对不要忽视trade-off。"
```

**问题**：禁忌效应（Ironic Rebound）

- 你越说"不要做X"，模型越容易focus在X上
- 负面表述让模型构建了"错误做法的完整模型"

**✅ 新方式** - 正面引导 + 替代方案：

```
【质量标准】

而非"禁止模糊建议"，改为：
→ "每条建议需包含：具体操作（What）+ 预期效果（Why）+ 时间周期（When）
   示例：不要说'改进缓存策略'，要说'将热点数据缓存TTL从1小时改为24小时，
   预期降低数据库查询50%，实施周期1天'"

而非"不要用术语不解释"，改为：
→ "假设读者是该领域的新手。每次出现技术术语时，用一句话解释其含义。
   示例格式：'LRU缓存（即淘汰最久未使用数据的缓存策略）'"

而非"绝对不要忽视trade-off"，改为：
→ "必须明确说出每个方案的代价。格式：
   方案A：✅优势（列举）❌代价（列举）⚠️ 适用场景（明确何时选这个）"
```

**核心差异**：

- 旧方式：告诉模型"不要做什么" → 新方式：告诉模型"要做什么、怎么做"
- 旧方式：负面约束 → 新方式：正面示范

**神经科学依据**：

- 大脑处理"不要想X"时，实际会强化"X"的表征
- 改为"要做Y"时，直接构建正确的认知路径

---

### 规范6️⃣：多模态示例（从"可选"升级为"必须"）

**✅ 新规范：示例不再可选，且需多维度**

```
【示例的三种类型】

1️⃣ 格式示例（Format Example）
   目的：模型理解输出的结构
   示例：如果要求表格，给出一个真实的表格样本
   
   ✅ 好做法：
   """
   | 方案 | 成本 | 性能 | 风险 |
   |------|------|------|------|
   | A   | $5K  | 中等 | 低  |
   | B   | $15K | 高   | 中  |
   """

2️⃣ 逻辑示例（Logic Example）
   目的：模型理解处理逻辑
   示例：展示输入如何变成输出的推理过程
   
   ✅ 好做法：
   """
   输入问题："我们的API响应慢"
   推理链条：
   ├─ 诊断：是哪个环节慢？(数据库?网络?计算?)
   ├─ 深因分析：如果是数据库，是查询还是连接?
   └─ 方案：针对根因的具体改进
   
   输出示例："最可能的瓶颈是数据库N+1查询，推荐改为批量查询或缓存..."
   """

3️⃣ 反例示例（Counter-example）
   目的：说明什么是不好的输出，为什么不好
   示例：展示错误做法及其问题
   
   ✅ 好做法：
   """
   ❌ 不好的输出："改进架构和优化性能"
      为什么不好：太抽象，无法执行，没有trade-off分析
      
   ✅ 好的输出："将单体应用拆分为微服务，预期降低单服务复杂度，
      代价是引入分布式调试难度和网络延迟，适用于>10人团队"
   """
```

**核心规范**：

- 最少提供1个格式示例 + 1个逻辑示例
- 如果任务有"容易犯的错误"，加1个反例
- 示例数量 = 3 + (任务复杂度等级)

**不提供示例的代价**：

- 模型猜测你的要求 → 输出常常与预期相差
- 即使结果不满意，也难以指出"哪里不对"

---

### 规范7️⃣：容错设计（升级"边界条件"）

**❌ 旧方式** - 简单的条件分支：

```
"如果输入为空，返回提示。
如果遇到歧义，按默认规则处理。"
```

**✅ 新方式** - 主动设计容错层：

```
【容错的三个层级】

第一层：输入验证与转换
├─ 空输入：不是"返回提示"，而是"生成最通用的输出"
│  示例：用户没提供具体场景，就给出"三个常见场景的对比"
├─ 格式错误：自动修正而非报错
│  示例：用户给的是"列表"但要求"表格"，主动转换
└─ 信息不足：主动补充假设而非求澄清
│  示例：用户没说团队规模，假设"中等团队(5-10人)"并明确标注

第二层：处理过程中的适应
├─ 发现矛盾条件：主动告知，并给出"按条件优先级"的处理结果
│  示例：用户既要"快速方案"又要"最全面分析"
│        → 回复："按'快速优先'理解，输出精简版，并附注'详细版见附录'"
├─ 发现知识边界：坦诚，但不中断
│  示例："某个技术我不确定最新进展，基于2024年底数据回答..."
└─ 发现假设风险：显式提出，邀请用户修正
│  示例："我假设你是Python用户，如果用其他语言可以改变建议吗？"

第三层：输出的有效性保证
├─ 自检：输出前自己审视"这个答案是否回答了问题"
├─ 标注确定性：在答案前标注 ✅确定 / ⚠️ 有风险 / ❓ 需要确认
└─ 预留反馈通道：每个主要建议后标注"如果这个不适用，可以考虑..."
```

**核心差异**：

- 旧方式：边界条件是"如果不符合就失败" → 新方式：边界条件是"如何优雅地适应异常"
- 旧方式：被动地等待用户修正 → 新方式：主动地提出假设和风险

**好处**：

- 减少"往返询问"，提高第一次就接近目标的概率
- 建立信任：用户看到你在主动考虑异常情况
- 增加鲁棒性：任何格式的输入都能处理

---

### 规范8️⃣：认知一致而非风格一致（升级"保持一致性"）

**❌ 旧方式** - 只关心表面一致：

```
"整篇文章用一致的语气、术语和格式。"
```

**✅ 新方式** - 深层认知一致：

```
【三个一致性维度】

1️⃣ 概念一致性（最重要）
   规则：同一个概念全文统一指称，避免混用
   
   ✅ 好做法：
   第一次提到时："缓存层（在这个系统中是指Redis"
   后续提到时：一律用"缓存"，不会突然变成"Cache"或"存储层"
   
   ❌ 坏做法：
   前面说"缓存策略"，后面说"Cache管理"，读者会困惑"是不是同一个东西"

2️⃣ 逻辑一致性（次重要）
   规则：前面说的假设、约束在后面不能突然违反
   
   ✅ 好做法：
   前面说"假设团队规模<10人"
   后面给方案时："这个方案适合>20人的团队吗？
              不适合，因为我们前面假设的是小团队，
              如果你的团队更大，建议改用'方案B'"
   
   ❌ 坏做法：
   前面说假设小团队，后面给的方案是"招聘10个专门的SRE"

3️⃣ 风格一致性（最不重要）
   规则：文风、格式、举例风格保持一致
   （重要性最低，因为这可以被智能编辑工具自动修复）
```

**优先级**：概念一致性 >> 逻辑一致性 >> 风格一致性

---

## 三、最新指令模板（可直接使用）

### 高可靠性指令模板

```markdown
【任务目标】
用一句话说明最终想要什么（用户的真实诉求，而非机械任务）

【上下文背景】
- 用户所在行业/场景
- 当前的约束条件（预算、时间、团队规模等）
- 相关的历史背景或关键假设

【信息层次结构】
[第一层] 核心问题定义
  输入：<接收什么信息>
  输出：<生成什么产物>
  
[第二层] <你的具体需求>
  输入：<依赖第一层的什么输出>
  输出：<在什么格式下完成>

[后续层] ...（根据复杂度增加）

【约束与质量标准】
[基础约束]
  - 长度：<数字>（指导性，非硬性）
  - 维度：<关键维度列表>
  
[动态调整]
  如果<条件>，则<如何调整>
  
[质量指标]
  ✅ 好的输出特征：<列举>
  ❌ 需要避免的情况：<用正面改述，不用禁止>

【示例】
1️⃣ 格式示例
   <给出一个完整的样本输出>
   
2️⃣ 逻辑示例
   输入：<例子的输入>
   推理过程：<怎样思考得出结果>
   输出：<期望的结果>
   
3️⃣ 反例
   ❌ <不好的做法>
   为什么不好：<说明原因>

【容错与补充】
- 如果信息不足，我会假设<什么>并明确标注
- 如果发现矛盾，我会按<优先级>处理并说明
- 如果有确定性问题，我会标注风险等级

【一致性要求】
关键概念统一指称：<列出要统一的核心术语>
逻辑约束：<任何不能被违反的前提>
```

---

## 四、未来可能的演进方向（2026+）

### 可能被推翻的规范

|规范|推翻原因|可能的替代|
|---|---|---|
|**结构化指令**|多模态模型可能直接从图表理解，不需要显式结构化|"多模态直观呈现" + 隐式的逻辑结构|
|**精确量化约束**|未来模型可能更擅长"感受"意图而非遵循数字|"模糊目标 + 迭代反馈"而非"精确约束"|
|**上下文链路追踪**|如果模型支持更长的上下文和更好的记忆，可能不需要显式追踪|"隐式的多轮对话记忆"|

### 新兴的规范方向

|新方向|现状|前景|
|---|---|---|
|**意图-证据分离**|初期探索|告诉模型"你的答案需要哪些证据支撑"，而不是"怎么做"|
|**多智能体协作指令**|开始出现|多个模型协作时，指令的重点从"做什么"转向"如何分工和验证"|
|**实时自适应约束**|理论阶段|指令会根据模型的实际输出质量动态调整，而非人工事前定义|

---

## 五、快速决策树

用这个决策树快速选择应该使用哪些规范：

```
【问题类型是什么？】

IF 创意/设计类任务
   THEN 用"目标导向表述" + "信息层次结构" + "正面引导"
   
IF 分析/诊断类任务
   THEN 用"上下文链路追踪" + "动态约束协商" + "多模态示例"
   
IF 工程/实施类任务
   THEN 用"信息层次结构" + "容错设计" + "认知一致性"
   
IF 一次性快速输出
   THEN 只需"目标导向" + "基础示例"
   
IF 需要可迭代、可维护的流程
   THEN 完整使用"高可靠性指令模板"
```

---

## 总结

|时期|特征|核心方法论|
|---|---|---|
|**2023年初**|模型能力弱，需要手把手细节指导|祈使句 + 详细细则 + 硬约束|
|**2024年**|模型能力增强，理解目标和上下文|目标导向 + 层次化思维 + 动态约束|
|**2025年**|模型理解深化，需要提升思维深度|**意图优先 + 容错优先 + 反馈闭环**|
|**2026+**|多模态和跨智能体|"模型分工"而非"用户命令"|

**一句话更新**：从"告诉模型怎么做"进化到"帮助模型理解你的真实意图，然后相信它会找到最好的方式"。