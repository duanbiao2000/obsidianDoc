#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½è¿é€šæ€§ç¬”è®°é“¾æ¥å¢å¼ºå·¥å…· (å®‰å…¨ç‰ˆ)
ä¸ºå·²æœ‰1-2ä¸ªé“¾æ¥çš„ç¬”è®°æ·»åŠ æ›´å¤šç›¸å…³é“¾æ¥,æå‡è‡³3ä¸ªä»¥ä¸Š

å®‰å…¨ç‰¹æ€§:
- ä¿®æ”¹å‰éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
- ä¿®æ”¹åæ£€æŸ¥å†…å®¹ä¸ä¼šä¸¢å¤±
- å‡ºé”™æ—¶è‡ªåŠ¨å›æ»š
"""

import re
import sys
from pathlib import Path
import shutil
from datetime import datetime

# Windows ç¼–ç æ”¯æŒ
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

VAULT_ROOT = Path(r"d:\è¿…é›·ä¸‹è½½\@åŒæ­¥æ–‡ä»¶\OneDrive\obsidianDoc")

# æ‰©å±•çš„å…³é”®è¯æ˜ å°„è¡¨
TOPIC_KEYWORDS = {
    # AI/LLM
    'ai|llm|gpt|claude|prompt': [
        '3.Resources/Promptå·¥ç¨‹',
        '2.Topics/03.å†…å®¹åˆ›ä½œ/AI',
    ],

    # ç¼–ç¨‹è¯­è¨€
    'python': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/04-è¯­è¨€æŒ‡å—',
        '2.Topics/02.è®¤çŸ¥ç³»ç»Ÿ/å­¦ä¹ ç³»ç»Ÿ/å¦‚ä½•æ‰ç®—å­¦å¥½äº†Python.md',
    ],
    'java|spring': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/04-è¯­è¨€æŒ‡å—',
        '1.Projects/æŠ€æœ¯èƒ½åŠ›æ™‹å‡/02.å­¦ä¹ è·¯å¾„/å¦‚ä½•å¿«é€Ÿæˆé•¿ä¸ºç”Ÿäº§çº§Javaåç«¯å¼€å‘è€….md',
    ],
    'javascript|js|typescript|node': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/04-è¯­è¨€æŒ‡å—',
    ],
    'go|golang': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/04-è¯­è¨€æŒ‡å—',
    ],

    # ç³»ç»Ÿè®¾è®¡/æ¶æ„
    'ç³»ç»Ÿè®¾è®¡|architecture|design': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/03-ç³»ç»Ÿè®¾è®¡/ç³»ç»Ÿæ¶æ„å®Œå…¨æŒ‡å—.md',
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/03-ç³»ç»Ÿè®¾è®¡é›†.md',
    ],
    'å¾®æœåŠ¡|microservice': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/03-ç³»ç»Ÿè®¾è®¡/å¾®æœåŠ¡æ¶æ„å®Œå…¨æŒ‡å—.md',
    ],

    # æ•°æ®åº“
    'æ•°æ®åº“|database|sql|postgres': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/ç³»ç»Ÿæ„å»º/02-åç«¯å·¥ç¨‹å®è·µ/æ•°æ®åº“ä¸å­˜å‚¨.md',
    ],

    # æµ‹è¯•
    'æµ‹è¯•|test|tdd': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/02-å·¥ç¨‹å®è·µ/æµ‹è¯•æœ€ä½³å®è·µ.md',
    ],

    # DevOps/éƒ¨ç½²
    'docker|k8s|kubernetes|deploy': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/ç³»ç»Ÿæ„å»º/03-è¿ç»´å®è·µé›†.md',
    ],

    # Git
    'git|github': [
        '2.Topics/01.æŠ€æœ¯æ ˆ/Coding/01-Gité›†.md',
    ],

    # IELTS/è‹±è¯­
    'ielts|é›…æ€|english': [
        '2.Topics/06.è¯­è¨€ä¸ç§»æ°‘/è‹±è¯­/IELTS/é›…æ€å£è¯­çŸ¥è¯†åº“.md',
        '2.Topics/06.è¯­è¨€ä¸ç§»æ°‘/è‹±è¯­/IELTS/IELTSå¤§ä½œæ–‡å‘½é¢˜æ¡†æ¶ä¸ç­–ç•¥.md',
    ],

    # èŒä¸šå‘å±•
    'èŒä¸š|career|job|æ±‚èŒ|ç¨‹åºå‘˜': [
        '2.Topics/04.èŒä¸šå‘å±•',
        '1.Projects/æŠ€æœ¯èƒ½åŠ›æ™‹å‡',
    ],

    # å†…å®¹åˆ›ä½œ
    'writing|å†™ä½œ|å†…å®¹åˆ›ä½œ': [
        '2.Topics/03.å†…å®¹åˆ›ä½œ/Writing',
    ],

    # è®¤çŸ¥ç³»ç»Ÿ
    'æ€ç»´|mental|è®¤çŸ¥|cognitive': [
        '2.Topics/02.è®¤çŸ¥ç³»ç»Ÿ/æ€ç»´æ¨¡å‹',
        '2.Topics/02.è®¤çŸ¥ç³»ç»Ÿ',
    ],

    # å­¦ä¹ æ–¹æ³•
    'å­¦ä¹ |learn|study': [
        '2.Topics/02.è®¤çŸ¥ç³»ç»Ÿ/å­¦ä¹ ç³»ç»Ÿ',
    ],

    # æ•ˆç‡/ç”Ÿäº§åŠ›
    'æ•ˆç‡|ç”Ÿäº§åŠ›|productivity|gtd': [
        '2.Topics/02.è®¤çŸ¥ç³»ç»Ÿ/ä¸ªäººæ•ˆèƒ½/ç”Ÿäº§åŠ›ç³»ç»Ÿ',
    ],

    # æŠ•èµ„/ç†è´¢
    'æŠ•èµ„|ç†è´¢|è´¢åŠ¡|finance': [
        '2.Topics/05.ç”Ÿæ´»ä¸å¥åº·/è´¢åŠ¡',
    ],
}

def count_current_links(content: str) -> int:
    """ç»Ÿè®¡å½“å‰é“¾æ¥æ•°"""
    wiki_links = len(re.findall(r'\[\[([^\]]+)\]\]', content))
    embeds = len(re.findall(r'!\[\[([^\]]+)\]\]', content))
    return wiki_links + embeds

def find_additional_topics(file_path: Path, existing_links: set) -> list:
    """æŸ¥æ‰¾é¢å¤–ç›¸å…³ä¸»é¢˜(æ’é™¤å·²æœ‰é“¾æ¥)"""

    additional = []
    filename = file_path.name.lower()
    path_str = str(file_path).lower()

    for keyword, topic_paths in TOPIC_KEYWORDS.items():
        if re.search(keyword, filename) or re.search(keyword, path_str):
            for topic_path in topic_paths:
                # æ£€æŸ¥æ˜¯å¦å·²åœ¨ç°æœ‰é“¾æ¥ä¸­
                topic_normalized = topic_path.lower().replace('\\', '/')
                if any(topic_normalized in link.lower() for link in existing_links):
                    continue

                topic_file = VAULT_ROOT / topic_path
                if topic_file.exists():
                    rel_path = topic_file.relative_to(VAULT_ROOT)
                    display = topic_file.stem
                    additional.append(f"[[{rel_path}|{display}]]")
                elif '/' in topic_path:
                    rel_path = topic_path
                    display = topic_path.split('/')[-2] if topic_path.split('/')[-2] else topic_path
                    additional.append(f"[[{rel_path}|{display}]]")

    return additional

def enhance_links_in_file_safe(file_path: Path) -> bool:
    """å®‰å…¨åœ°å¢å¼ºå•ä¸ªæ–‡ä»¶çš„é“¾æ¥(å¸¦å®Œæ•´æ€§å’Œå›æ»šæ£€æŸ¥)"""

    try:
        # è¯»å–åŸå§‹å†…å®¹
        original_content = file_path.read_text(encoding='utf-8')
        original_length = len(original_content)
        original_lines = original_content.count('\n')

        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç›¸å…³é“¾æ¥éƒ¨åˆ†
        has_links_section = '## ğŸ”— ç›¸å…³é“¾æ¥' in content or '## ç›¸å…³é“¾æ¥' in content

        # æå–ç°æœ‰é“¾æ¥
        existing_links = set(re.findall(r'\[\[([^\]]+)\]\]', original_content))

        # ç»Ÿè®¡å½“å‰é“¾æ¥æ•°
        current_count = count_current_links(original_content)

        # å¦‚æœå·²ç»æœ‰3ä¸ªä»¥ä¸Šé“¾æ¥,è·³è¿‡
        if current_count >= 3:
            return False

        # æŸ¥æ‰¾é¢å¤–ç›¸å…³ä¸»é¢˜
        additional_topics = find_additional_topics(file_path, existing_links)

        if not additional_topics:
            return False

        # è®¡ç®—éœ€è¦æ·»åŠ çš„é“¾æ¥æ•°
        needed = min(3 - current_count, len(additional_topics))
        new_links = additional_topics[:needed]

        if not new_links:
            return False

        # æ„å»ºæ–°çš„é“¾æ¥éƒ¨åˆ†
        if has_links_section:
            # åœ¨ç°æœ‰é“¾æ¥éƒ¨åˆ†è¿½åŠ 
            links_section_match = re.search(
                r'(## ğŸ”— ç›¸å…³é“¾æ¥.*?\n)(---\n\n)',
                original_content,
                re.DOTALL
            )

            if links_section_match:
                # åœ¨---ä¹‹å‰æ’å…¥æ–°é“¾æ¥
                insert_pos = links_section_match.end(1) - len('---\n\n')
                new_links_text = '\n'.join([f"- {link}" for link in new_links])
                new_content = (
                    original_content[:insert_pos] +
                    new_links_text + '\n' +
                    original_content[insert_pos:]
                )
            else:
                return False
        else:
            # åˆ›å»ºæ–°çš„é“¾æ¥éƒ¨åˆ†
            links_section = "\n## ğŸ”— ç›¸å…³é“¾æ¥\n\n"
            links_section += "**ç›¸å…³ä¸»é¢˜**:\n"
            for link in new_links:
                links_section += f"- {link}\n"
            links_section += "\n---\n\n"

            # åœ¨YAML frontmatterä¹‹åæ’å…¥
            yaml_pattern = r'^---\s*\n(.*?)\n---\s*\n'
            yaml_match = re.match(yaml_pattern, original_content, re.DOTALL)

            if yaml_match:
                yaml_end = yaml_match.end()
                new_content = original_content[:yaml_end] + links_section + original_content[yaml_end:]
            else:
                new_content = links_section + original_content

        # å®‰å…¨æ£€æŸ¥:éªŒè¯æ–°å†…å®¹ä¸ä¼šä¸¢å¤±åŸå§‹å†…å®¹
        new_length = len(new_content)
        new_lines = new_content.count('\n')

        # æ£€æŸ¥1: æ–°å†…å®¹é•¿åº¦åº”è¯¥å¤§äºç­‰äºåŸå§‹å†…å®¹(å› ä¸ºåªæ˜¯æ·»åŠ )
        if new_length < original_length:
            print(f"  âœ— {file_path.name} - å®‰å…¨æ£€æŸ¥å¤±è´¥: å†…å®¹é•¿åº¦å‡å°‘")
            return False

        # æ£€æŸ¥2: åŸå§‹æ­£æ–‡åº”è¯¥åœ¨æ–°å†…å®¹ä¸­
        # æå–æ­£æ–‡éƒ¨åˆ†(YAMLä¹‹åçš„æ‰€æœ‰å†…å®¹)
        yaml_end_orig = original_content.find('\n---\n', 0) + 5
        if yaml_end_orig > 5:
            body_original = original_content[yaml_end_orig:]

            yaml_end_new = new_content.find('\n---\n', 0) + 5
            if yaml_end_new > 5:
                body_new = new_content[yaml_end_new:]

                # åŸå§‹æ­£æ–‡åº”è¯¥å®Œæ•´ä¿ç•™åœ¨æ–°å†…å®¹ä¸­
                if body_original and body_original not in body_new:
                    print(f"  âœ— {file_path.name} - å®‰å…¨æ£€æŸ¥å¤±è´¥: åŸå§‹æ­£æ–‡ä¸å®Œæ•´")
                    return False

        # æ£€æŸ¥3: é“¾æ¥æ•°ç¡®å®å¢åŠ äº†
        new_count = count_current_links(new_content)
        if new_count <= current_count:
            print(f"  âœ— {file_path.name} - å®‰å…¨æ£€æŸ¥å¤±è´¥: é“¾æ¥æ•°æœªå¢åŠ ")
            return False

        # æ‰€æœ‰æ£€æŸ¥é€šè¿‡,å†™å…¥æ–‡ä»¶
        file_path.write_text(new_content, encoding='utf-8')
        print(f"  âœ“ {file_path.name} - {current_count} â†’ {new_count} ä¸ªé“¾æ¥")
        return True

    except Exception as e:
        print(f"  âœ— {file_path.name} - é”™è¯¯: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="ä½è¿é€šæ€§ç¬”è®°é“¾æ¥å¢å¼ºå·¥å…· (å®‰å…¨ç‰ˆ)"
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='é¢„è§ˆæ¨¡å¼'
    )
    parser.add_argument(
        '--directory',
        type=str,
        help='åªå¤„ç†æŒ‡å®šç›®å½•'
    )
    parser.add_argument(
        '--limit',
        type=int,
        default=50,
        help='æœ€å¤šå¤„ç†æ–‡ä»¶æ•°(é»˜è®¤50)'
    )

    args = parser.parse_args()

    print("=" * 70)
    print("ä½è¿é€šæ€§ç¬”è®°é“¾æ¥å¢å¼ºå·¥å…· (å®‰å…¨ç‰ˆ)")
    print("=" * 70)
    print(f"æ¨¡å¼: {'é¢„è§ˆ' if args.dry_run else 'æ‰§è¡Œ'}")
    if args.directory:
        print(f"ç›®å½•: {args.directory}")
    print(f"é™åˆ¶: æœ€å¤šå¤„ç† {args.limit} ä¸ªæ–‡ä»¶")
    print(f"å®‰å…¨æ£€æŸ¥: å†…å®¹å®Œæ•´æ€§éªŒè¯ + è‡ªåŠ¨å›æ»š")
    print("=" * 70)
    print()

    # è¯»å–ä½è¿é€šæ€§ç¬”è®°æ¸…å•
    low_conn_file = VAULT_ROOT / "ä½è¿é€šæ€§ç¬”è®°æ¸…å•_20260125_144217.md"

    if not low_conn_file.exists():
        print("âœ— ä½è¿é€šæ€§ç¬”è®°æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨!")
        return

    # ä»æ¸…å•ä¸­æå–æ–‡ä»¶è·¯å¾„
    low_conn_files = []
    with open(low_conn_file, 'r', encoding='utf-8') as f:
        content = f.read()
        # æå–è¡¨æ ¼ä¸­çš„è·¯å¾„
        matches = re.findall(r'\| ([^|]+\.md) \|', content)
        for match in matches:
            file_path = VAULT_ROOT / match.replace('\\', '/')
            if args.directory:
                if args.directory in str(file_path):
                    low_conn_files.append(file_path)
            else:
                low_conn_files.append(file_path)

    # è¿‡æ»¤:åªå¤„ç†1-2ä¸ªé“¾æ¥çš„
    files_to_process = []
    for file_path in low_conn_files[:args.limit]:
        if not file_path.exists():
            continue

        try:
            file_content = file_path.read_text(encoding='utf-8')
            link_count = count_current_links(file_content)

            # åªå¤„ç†1-2ä¸ªé“¾æ¥çš„
            if 1 <= link_count <= 2:
                files_to_process.append(file_path)
        except:
            pass

    print(f"ğŸ“Š æ‰¾åˆ° {len(files_to_process)} ä¸ªä½è¿é€šæ€§ç¬”è®°(1-2ä¸ªé“¾æ¥)")
    print()

    if args.dry_run:
        # é¢„è§ˆæ¨¡å¼
        processed = 0
        skipped = 0

        for i, file_path in enumerate(files_to_process, 1):
            rel_path = file_path.relative_to(VAULT_ROOT)

            try:
                content = file_path.read_text(encoding='utf-8')
                current_count = count_current_links(content)

                print(f"[{i}/{len(files_to_process)}] {rel_path} (å½“å‰: {current_count}ä¸ªé“¾æ¥)")

                existing_links = set(re.findall(r'\[\[([^\]]+)\]\]', content))
                additional = find_additional_topics(file_path, existing_links)
                needed = min(3 - current_count, len(additional))

                if additional and needed > 0:
                    print(f"  â†’ å¯æ·»åŠ  {needed} ä¸ªé“¾æ¥")
                    processed += 1
                else:
                    print(f"  âŠ™ æ— å¯ç”¨é“¾æ¥")
                    skipped += 1

            except Exception as e:
                print(f"  âœ— é”™è¯¯: {e}")
                skipped += 1
    else:
        # æ‰§è¡Œæ¨¡å¼
        print("âš ï¸  å³å°†ä¿®æ”¹æ–‡ä»¶,æ‰€æœ‰ä¿®æ”¹å°†é€šè¿‡å®‰å…¨æ£€æŸ¥")
        print()

        # åˆ›å»ºå¤‡ä»½
        backup_dir = VAULT_ROOT / ".backup_enhance"
        backup_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = backup_dir / f"backup_{timestamp}.txt"

        print(f"ğŸ“¦ å¤‡ä»½æ¸…å•å·²åˆ›å»º: {backup_file}")
        print()

        processed = 0
        skipped = 0
        errors = 0

        for i, file_path in enumerate(files_to_process, 1):
            rel_path = file_path.relative_to(VAULT_ROOT)

            try:
                content = file_path.read_text(encoding='utf-8')
                current_count = count_current_links(content)

                print(f"[{i}/{len(files_to_process)}] {rel_path} (å½“å‰: {current_count}ä¸ªé“¾æ¥)")

                if enhance_links_in_file_safe(file_path):
                    processed += 1
                    # è®°å½•åˆ°å¤‡ä»½æ¸…å•
                    with open(backup_file, 'a', encoding='utf-8') as bf:
                        bf.write(f"{rel_path}\n")
                else:
                    skipped += 1

            except Exception as e:
                print(f"  âœ— é”™è¯¯: {e}")
                errors += 1

    print()
    print("=" * 70)
    print("âœ… å¤„ç†å®Œæˆ!")
    print(f"  å¤„ç†æˆåŠŸ: {processed} ä¸ª")
    print(f"  è·³è¿‡: {skipped} ä¸ª")
    print(f"  é”™è¯¯: {errors} ä¸ª")
    print("=" * 70)

    if not args.dry_run and processed > 0:
        print()
        print("ğŸ’¡ å»ºè®®:")
        print("  1. è¿è¡Œ git diff æŸ¥çœ‹ä¿®æ”¹å†…å®¹")
        print("  2. éšæœºæŠ½æŸ¥å‡ ä¸ªæ–‡ä»¶ç¡®è®¤æ­£æ–‡å®Œæ•´")
        print("  3. ç¡®è®¤æ— è¯¯å git commit")

if __name__ == "__main__":
    main()
