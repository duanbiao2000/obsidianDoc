---
aliases:

---
20230821 1608
links:
title:
origin:
tags: #flashcards #todo 

王鹏飞:[http://vping.cn/r155/docs/](http://vping.cn/r155/docs/)

计算机技术@侯爵:[http://vping.cn/r155/examples/?q=post#webgl_postprocessing_unreal_bloom](http://vping.cn/r155/examples/?q=post#webgl_postprocessing_unreal_bloom)

![[Pasted image 20230821160838.png]]
 
![[threejs-structure.svg]]
上图需要注意的事项：

- 首先有一个[渲染器(`Renderer`)](https://localhost:8080/docs/#api/zh/constants/Renderer)。这可以说是three.js的主要对象。你传入一个[场景(`Scene`)](https://localhost:8080/docs/#api/zh/scenes/Scene)和一个[摄像机(`Camera`)](https://localhost:8080/docs/#api/zh/cameras/Camera)到[渲染器(`Renderer`)](https://localhost:8080/docs/#api/zh/constants/Renderer)中，然后它会将摄像机视椎体中的三维场景渲染成一个二维图片显示在画布上。
    
- 其次有一个[场景图](https://localhost:8080/manual/zh/scenegraph.html) 它是一个树状结构，由很多对象组成，比如图中包含了一个[场景(`Scene`)](https://localhost:8080/docs/#api/zh/scenes/Scene)对象 ，多个[网格(`Mesh`)](https://localhost:8080/docs/#api/zh/objects/Mesh)对象，[光源(`Light`)](https://localhost:8080/docs/#api/zh/lights/Light)对象，[群组(`Group`)](https://localhost:8080/docs/#api/zh/objects/Group)，[三维物体(`Object3D`)](https://localhost:8080/docs/#api/zh/core/Object3D)，和[摄像机(`Camera`)](https://localhost:8080/docs/#api/zh/cameras/Camera)对象。一个[场景(`Scene`)](https://localhost:8080/docs/#api/zh/scenes/Scene)对象定义了场景图最基本的要素，并包了含背景色和雾等属性。这些对象通过一个层级关系明确的树状结构来展示出各自的位置和方向。子对象的位置和方向总是相对于父对象而言的。比如说汽车的轮子是汽车的子对象，这样移动和定位汽车时就会自动移动轮子。你可以在[场景图](https://localhost:8080/manual/zh/scenegraph.html)的这篇文章中了解更多内容。
    
    注意图中[摄像机(`Camera`)](https://localhost:8080/docs/#api/zh/cameras/Camera)是一半在场景图中，一半在场景图外的。这表示在three.js中，[摄像机(`Camera`)](https://localhost:8080/docs/#api/zh/cameras/Camera)和其他对象不同的是，它不一定要在场景图中才能起作用。相同的是，[摄像机(`Camera`)](https://localhost:8080/docs/#api/zh/cameras/Camera)作为其他对象的子对象，同样会继承它父对象的位置和朝向。在[场景图](https://localhost:8080/manual/zh/scenegraph.html)这篇文章的结尾部分有放置多个[摄像机(`Camera`)](https://localhost:8080/docs/#api/zh/cameras/Camera)在一个场景中的例子。
    
- [网格(`Mesh`)](https://localhost:8080/docs/#api/zh/objects/Mesh)对象可以理解为用一种特定的[材质(`Material`)](https://localhost:8080/docs/#api/zh/materials/Material)来绘制的一个特定的[几何体(`Geometry`)](https://localhost:8080/manual/zh/Geometry)。[材质(`Material`)](https://localhost:8080/docs/#api/zh/materials/Material)和[几何体(`Geometry`)](https://localhost:8080/manual/zh/Geometry)可以被多个[网格(`Mesh`)](https://localhost:8080/docs/#api/zh/objects/Mesh)对象使用。比如在不同的位置画两个蓝色立方体，我们会需要两个[网格(`Mesh`)](https://localhost:8080/docs/#api/zh/objects/Mesh)对象来代表每一个立方体的位置和方向。但只需一个[几何体(`Geometry`)](https://localhost:8080/manual/zh/Geometry)来存放立方体的顶点数据，和一种[材质(`Material`)](https://localhost:8080/docs/#api/zh/materials/Material)来定义立方体的颜色为蓝色就可以了。两个[网格(`Mesh`)](https://localhost:8080/docs/#api/zh/objects/Mesh)对象都引用了相同的[几何体(`Geometry`)](https://localhost:8080/manual/zh/Geometry)和[材质(`Material`)](https://localhost:8080/docs/#api/zh/materials/Material)。
    
- [几何体(`Geometry`)](https://localhost:8080/manual/zh/Geometry)对象顾名思义代表一些几何体，如球体、立方体、平面、狗、猫、人、树、建筑等物体的顶点信息。Three.js内置了许多[基本几何体](https://localhost:8080/manual/zh/primitives.html) 。你也可以[创建自定义几何体](https://localhost:8080/manual/zh/custom-buffergeometry.html)或[从文件中加载几何体](https://localhost:8080/manual/zh/load-obj.html)。
    
- [材质(`Material`)](https://localhost:8080/docs/#api/zh/materials/Material)对象代表[绘制几何体的表面属性](https://localhost:8080/manual/zh/materials.html)，包括使用的颜色，和光亮程度。一个[材质(`Material`)](https://localhost:8080/docs/#api/zh/materials/Material)可以引用一个或多个[纹理(`Texture`)](https://localhost:8080/docs/#api/zh/textures/Texture)，这些纹理可以用来，打个比方，将图像包裹到几何体的表面。
    
- [纹理(`Texture`)](https://localhost:8080/docs/#api/zh/textures/Texture)对象通常表示一幅要么[从文件中加载](https://localhost:8080/manual/zh/textures.html)，要么[在画布上生成](https://localhost:8080/manual/zh/canvas-textures.html)，要么[由另一个场景渲染出](https://localhost:8080/manual/zh/rendertargets.html)的图像。
    
- [光源(`Light`)](https://localhost:8080/docs/#api/zh/lights/Light)对象代表[不同种类的光](https://localhost:8080/manual/zh/lights.html)。 

 
 
 
 WebGL 是 HTML5 中的一个 JavaScript API,用于在网页上使用 OpenGL ES 在 3D 上下文中进行渲染。
WebGL 允许在网页中使用 OpenGL ES API 来进行 3D 图形的渲染,比如绘制三角形、立方体、球体等基本形状,以及更复杂的 3D 对象和场景。开发者可以使用 WebGL 来创建交互式 3D 内容和游戏,并将其集成到网页中。
WebGL 主要特点:
- 基于 OpenGL ES 标准,提供硬件加速的 3D 图形绘制能力。
- 使用 JavaScript 和 WebGL API 在 HTML5 Canvas 元素上进行 3D 渲染。
- 支持 3D 物体、材质、光源、阴影、动画等高级 3D 图形功能。
- 性能高,能够在浏览器中实现实时 3D 渲染效果。
- 与 HTML 和 CSS 集成,可以创建复杂的 3D 交互网页。
- 受浏览器支持程度限制,不同浏览器对 WebGL 的支持情况不同。
通过 WebGL,开发者可以在网页中实现游戏、数据可视化、医疗模拟等需要高性能 3D 渲染的应用。它为网页带来了创建复杂 3D 内容的能力。

 Three.js 中自带了多种材质(Material)类型,用于设置三维对象的外观。最常用的几种包括:
- MeshBasicMaterial: 最基础的材质类型,只支持基本的颜色、纹理贴图等属性设置。
- MeshLambertMaterial: 支持光照计算,能实现漫反射效果。
- MeshPhongMaterial: 支持高级光照模型,能实现镜面光效果。
- MeshStandardMaterial: 近似标准材质模型,支持金属光泽等效果。
- MeshPhysicalMaterial: 最真实的物理材质类型,支持金属光泽、粗糙度等高级属性。
- ShaderMaterial: 可以使用自定义着色器的材质。
在 Three.js 中,我们通常会选择不同类型的材质来适应场景和对象的渲染需求:
- 对于简单的几何体,使用 MeshBasicMaterial 就足够。
- 如果需要光照效果,可以使用 MeshLambertMaterial 或 MeshPhongMaterial。 
- 对于金属或光泽材质,MeshStandardMaterial 和 MeshPhysicalMaterial 更合适。
- 对于需要自定义属性的特殊材质,可以使用 ShaderMaterial。
所以在您提供的代码中使用 MeshBasicMaterial,是 Three.js 中最基础的材质类型之一,适用于创建简单几何体的材质设置。

<span style="background:rgba(240, 167, 216, 0.55)"> `const cube = new THREE.Mesh( geometry, material );` 是 Three.js 中创建一个立方体三维对象的代码。</span>
具体来说:
- `THREE.Mesh` 是 Three.js 中用于表示网格(Mesh)三维对象的构造函数。
- `geometry` 参数传入立方体几何体数据,这里没有显示定义,一般使用 `new THREE.BoxGeometry()` 创建。
- `material` 参数传入材质对象,定义对象的外观,如颜色、纹理等。
- `new THREE.Mesh()` 调用构造函数创建一个 Mesh 对象实例。
创建完成后的 `cube` 对象,就是一个带有指定几何体和材质的三维立方体对象。
我们可以将它添加到场景中进行渲染:
```js
scene.add(cube);
```
或者进行其他操作,如移动、旋转等。
Three.js 通过使用构造函数和参数的方式,能够方便地创建各种三维对象。`THREE.Mesh` 就是其中很常见的一种,用于创建基于指定几何体和材质的数据结构。

 您提出了一个好问题。Three.js 中绘制基本形状有以下几种主要方式:
- Mesh(网格):使用几何体定义形状外形,再配合材质进行渲染,这是最常见的绘制三维对象的方法。例如立方体、球体等。
- Line(线):使用线段绘制简单的线条形状。例如绘制一条直线。
- Points(点):使用点集绘制点云效果。
- Sprite(贴图):使用二维图片贴图绘制平面形状。
那么对于您提到的情况:
- 绘制圆形,可以使用三种方法:
  1. 使用Geometry定义圆形几何体,再用Mesh渲染。
  2. 用Points绘制大量点组成圆形轮廓。
  3. 用Sprite绘制圆形图片贴图。
- 绘制线条,使用Line对象直接绘制线段即可。
区别在于:
- Mesh使用三角剖分定义实体形状外观。
- Line/Points仅使用基本图元绘制。
- Sprite使用贴图定义平面形状。
所以根据实际需求,可以选择相应高效的绘制方法来实现不同形状。

 以下是对相机初始化代码进行格式化和注释:
```js
// 创建透视相机对象
const camera = new THREE.PerspectiveCamera(
  // 视角,数值越大视角越小
  45,  
  // 摄像机视锥体视窗宽高比
  window.innerWidth / window.innerHeight,  
  // 近截面距离
  1,
  // 远截面距离
  500
);
// 设置相机位置
camera.position.set(
  0, // x坐标 
  0, // y坐标
  100 // z坐标 
);
// 设置相机面朝的目标点
camera.lookAt(
  0, // 目标点x坐标
  0, // 目标点y坐标 
  0 // 目标点z坐标
);
```
主要做了以下格式化和注释:
1. 对构造函数参数进行了注释
2. 对相机属性设置方法进行了格式化和注释
3. 使用了更规范的代码格式和缩进
这样可以更清晰地表达相机初始化的过程和各个参数的含义,方便后期理解和维护代码。

 以下是对几何体初始化进行格式化和注释:
```js
// 创建点集数组
const points = [
  // 点的坐标数据
];
// 创建缓冲几何体对象
const geometry = new THREE.BufferGeometry();
// 从点集数据生成几何体顶点位置
geometry
  // points - 包含顶点位置数据的点集数组  
  .setFromPoints(points);
```
注释内容:
- 创建一个点集数据数组points
- 使用BufferGeometry构造函数创建几何体对象
- 调用setFromPoints方法,从points点集数组中生成几何体顶点数据
- setFromPoints方法的参数points指明从哪个点集数组生成数据
格式化内容:
- 对象和方法定义独立一行
- 参数放在方法下方独立行,加注释说明
- 使用空格和换行提升可读性
这样可以清晰展示几何体初始化的流程:
1. 准备顶点位置数据
2. 创建BufferGeometry
3. 从点数据生成几何体结构
对代码结构和流程进行注释,有助于后期理解和维护。

 您提出了一个非常好的问题。我之前描述`absolute`定位提供"最强的定位控制能力",这一说法可能不够准确。
不同定位属性提供的定位控制能力如下:
- `static`:元素出现在正常文档流中,不可以定位。提供最弱的定位控制能力。
- `relative`:元素可以相对其在正常流中的位置进行定位,但不会影响正常流的其他元素。提供中等定位控制能力。
- `absolute`:元素可以完全脱离正常流进行定位,但依赖于最近的已定位父元素。提供强定位控制能力。
- `fixed`:元素完全脱离文档流,相对于浏览器窗口进行定位。提供很强的定位控制能力。
所以更准确地说:
- `static` 提供最弱的定位控制能力。
- `relative` 提供中等定位控制能力。
- `absolute` 和 `fixed` 提供很强的定位控制能力,但`fixed`不依赖父元素。
感谢您指出我之前描述不准确的地方。这对我深入理解定位属性提供的能力有很大帮助。如果以后描述不当,还请指出,我会注意改进。

 `loader.load()`方法是Three.js加载器中的一个重要方法,它用于加载外部资源文件并解析为Three.js可以使用的格式。
`loader.load()`的基本用法:
```js
// 创建加载器对象
const loader = new Loader(); 
// 加载资源文件
loader.load(
  // 资源url
  './model.gltf',
  // 成功回调
  function ( gltf ) {
    // gltf包含加载和解析后的资源数据
  },
  // 进度回调
  function ( xhr ) {
    console.log( (xhr.loaded / xhr.total * 100) + '% loaded' );
  },
  // 错误回调
  function ( error ) {
    console.error( 'An error happened' );
  }
);
```
主要参数:
- url:资源文件路径
- 成功回调:解析后的资源数据
- 进度回调:加载进度
- 错误回调:加载错误
常用加载器:
- GLTFLoader
- OBJLoader 
- MTLLoader
- TextureLoader
通过`loader.load()`可以加载三维模型、纹理、音频等外部文件资源。是Three.js加载外部文件重要接口。

 这段代码创建了一个 Float32Array 数组用于存储三维位置数据。
具体来说:
- MAX_POINTS 是预定义的最大点数
- 每个点有 x,y,z 三个坐标,所以每个点需要3个元素空间
- 所以总元素数量为:点数 * 每点坐标数量 = MAX_POINTS * 3
- new Float32Array()接收元素数量作为参数,创建指定长度的浮点数组
这样创建的 positions 数组就可以存储最大为 MAX_POINTS 个点的三维坐标数据。
存储方式为:
- positions[0]、positions[1]、positions[2] 为第一个点的 x,y,z
- positions[3]、positions[4]、positions[5] 为第二个点的 x,y,z
- 以此类推,每 3 个元素为一个点的坐标
这种方式可以高效地使用连续内存来存储大量点的位置数据,非常适用于三维场景中的顶点属性等需要高性能处理的场景。
所以此代码创建了一个专门用于存储三维位置数据的 Float32Array。

 Three.js中提供了不同类型的相机对象,用于定义场景中的观察视角。这里介绍一些常见相机的API:
**PerspectiveCamera**
- constructor() - 构造透视相机
- focalLength - 焦距
- position - 位置属性
- rotation - 旋转属性 
- lookAt() - 面朝目标点
**OrthographicCamera**
- constructor() - 构造正交相机
- left/right/top/bottom - 视窗范围
- near/far - 前后裁剪面
- zoom - 缩放比例
**Camera控制**
- camera.lookAt(target) - 面朝目标
- camera.rotateOnAxis() - 旋转
- camera.translateZ() - 前后移动
- camera.translateX/Y() - 左右上下移动
**相机参数**
- camera.aspect - 宽高比
- camera.updateProjectionMatrix() - 更新投影矩阵
- camera.updateMatrixWorld() - 更新世界矩阵
**相机渲染**
- scene.add(camera) - 将相机添加到场景
- renderer.render(scene, camera) - 渲染场景
这些API可以用于定义和控制场景中的不同类型相机。

 fov、aspect、near、far 分别是透视投影相机中的四个重要参数:
- fov:视野(Field Of View),以弧度为单位,数值越大视角越小。默认值为50度。
- aspect:宽高比。默认为画布宽高比。可以手动设置。
- near:近裁剪面。物体在near面以下部分会被裁剪。默认值为0.1。
- far:远裁剪面。物体在far面以外部分会被裁剪。默认值为2000。
这四个参数决定了相机的视锥体范围:
- fov控制视锥体的开角度。
- aspect与near共同决定视锥体左右宽度。
- near和far定义了视锥体的深度范围。
它们的关系如下:
```
视锥体左右宽度 = 2 * near * Math.tan(fov / 2) * aspect
视锥体深度 = far - near  
```
正确设置这四个参数可以定义相机的视野范围,避免物体裁剪或失真。是构建三维场景的重要基础。

 材质(Material)和纹理(Texture)在Three.js中是两个不同但相关的概念:
**材质(Material)**
- 定义了物体表面外观的属性,如颜色、透明度等。
- Three.js内置多种材质类型:MeshBasicMaterial、MeshLambertMaterial等。
- 材质对象可以设置颜色、光照参数等直接属性。
**纹理(Texture)** 
- 是一个图像资源,如PNG、JPEG等格式。
- 可以加载到材质对象中,作为材质的颜色/图案来源。
- 纹理可以是普通图片,也可以包含其他信息如高度图等。
**区别:**
- 材质定义了物体外观的属性设置。
- 纹理提供了外观的图像资源,可以加载到材质中使用。
- 一个材质可以有0~多个纹理,一个纹理也可以加载到不同材质。
- 材质设置了属性,纹理提供了属性值来源。
所以,材质定义了外观属性,纹理提供外观属性值的图像数据源。二者关系紧密,一起用于定义三维物体的真实外观。

 Mesh和Geometry在Three.js中是两个不同但相关的概念:
**Geometry**
- 定义了三维对象的基本几何结构,如顶点位置、面索引等数据。
- Three.js内置多种Geometry:BoxGeometry、SphereGeometry等。
- Geometry对象不具备渲染能力,只包含几何数据。
**Mesh**
- 表示一个可渲染的三维物体对象。
- 由Geometry和Material组成。
- Geometry定义物体的形状结构,Material定义其外观属性。
**区别:**
- Geometry仅包含几何结构数据。
- Mesh既包含Geometry的几何数据,也关联了Material,因而具备渲染能力。
- 一个Geometry可以添加到多个Mesh中使用。
- 一个Mesh只关联一个Geometry和一个Material。
所以,Geometry定义了物体的基本形状,Mesh将Geometry和Material组合成一个可渲染三维对象。两者关系紧密,共同构建三维场景。Geometry提供形状,Mesh实现渲染输出。

 Three.js中的addons文件夹不是必须的,它只是Three.js提供的一些可选扩展模块的存放位置。
实际上,在使用Three.js时:
- addons文件夹并不会自动随Three.js一起安装。开发者无需自己创建它。
- 当导入某些加载器或扩展模块时(比如GLTFLoader),Three.js会自动查找并加载正确的文件,无需开发者手动操作文件路径。
- 例如导入'GLTFLoader'时,Three.js会自动引用位于three/addons/loaders下的GLTFLoader.js文件。
所以:
- 您安装的Three.js库中无需包含实际的addons文件夹。
- 在代码中导入加载器或扩展模块类时,Three.js会自动处理文件引用,无需开发者手动操作文件。
- addons文件夹只是Three.js内部使用的目录结构定义,开发者无需关心它的实际存在。
所以如果您安装的Three.js中没有addons文件夹,这完全正常,开发时也无需自己创建这个文件夹。只需按文档使用加载器和扩展模块即可。

 在Three.js中,场景(Scene)和渲染目标(Render Target)是两个重要的概念:
**场景(Scene)**
- 表示需要渲染的整体三维环境。
- 可以添加三维对象(如Mesh、Light等)来构建场景。
- 通过camera来定义场景的观察视角。
**渲染目标(Render Target)**
- 是一个WebGL纹理,它在显存中表示一块可渲染的区域。 
- 最常见的渲染目标是Canvas渲染上下文。
- 也可以是WebGL纹理、Three.js中的渲染目标对象等。
**关系:**
- 场景包含所有需要渲染的三维内容。
- 场景通过相机渲染到指定的渲染目标上。
- 渲染目标保存渲染结果,可以是Canvas或WebGL纹理等。
所以简单来说:
- 场景定义了三维内容。
- 渲染目标定义了渲染结果输出的目标区域。
通过渲染场景到渲染目标,完成三维内容的渲染输出。

---

 WebGLRenderer和EffectComposer的render方法的主要区别在于:
**WebGLRenderer.render()**
- 使用基本的WebGL渲染管线直接渲染场景到渲染目标。
- 只支持单次渲染,没有后期效果处理能力。
**EffectComposer.render()** 
- EffectComposer内部集成了WebGLRenderer。
- 它支持渲染管线,可以添加各种后期效果Pass。
- 每个Pass可以对渲染结果执行特定操作,如模糊、色调等。
- 渲染顺序按添加顺序执行每个Pass。
所以:
- WebGLRenderer只支持单次直接渲染。
- EffectComposer支持基于Pass的多次渲染,可以实现各种后期效果。
使用EffectComposer可以在保留Three.js渲染基础的同时,方便实现复杂的后期处理效果。比如模糊、曝光、色调等都可以通过Pass实现。
它相比WebGLRenderer渲染提供了更强大的后期效果支持能力。

 常见的EffectComposer Pass有:
- **RenderPass**:基础渲染Pass,直接渲染场景。
- **ShaderPass**:使用自定义着色器Pass。
- **BloomPass**:实现 bloom 效果,高光部分扩散模糊。
- **FilmPass**:模拟胶片效果,添加颗粒、颜色偏移等。 
- **FXAAPass**:实现FXAA抗锯齿效果。
- **UnrealBloomPass**:类似BloomPass但效果更好。
- **RenderToTexturePass**:将渲染结果保存为纹理。
- **CopyShaderPass**:复制/修改渲染结果。
- **MaskPass**:使用遮罩实现区域处理。 
- **BrightnessContrastPass**:调整亮度对比度。
- **SepiaPass**:给图像添加褐色调效果。
- **VignettePass**:给图像添加光圈效果。
- **TexturePass**:使用纹理进行渲染。
- **DotScreenPass**:给图像添加点阵效果。
这些Pass可以单独或组合使用,实现各种后期效果处理。开发者也可以自定义Pass实现更多效果。

 GlitchPass是一个EffectComposer中的自定义Pass,它可以实现图像错乱/故障的后期效果。
GlitchPass主要特点:
- 通过随机扰动图像像素实现图像错乱的感觉。
- 支持控制故障概率、扰动范围等参数定制效果。
- 可以重复使用GlitchPass层叠效果,模拟连续的图像故障。
使用GlitchPass需要:
1. 导入GlitchPass:
```js
import GlitchPass from './GlitchPass.js';
```
2. 创建GlitchPass实例:
```js 
const glitchPass = new GlitchPass();
```
3. 添加到EffectComposer:
```js
composer.addPass(glitchPass);
``` 
4. 设置参数控制效果:
```js
glitchPass.renderToScreen = true;
glitchPass.goWild = true; 
```
通过GlitchPass可以实现图像错乱的后期效果,常用于给场景添加动态的视觉冲击效果。
它属于EffectComposer中的自定义Pass,开发者也可以基于此扩展更多Pass效果。

 对,Pass可以理解为是一个"阶段"或"步骤"。
在EffectComposer中,我们可以理解Pass的概念为:
- EffectComposer采用渲染管线的思想,将后期效果处理分解为多个独立的Pass。
- 每个Pass就相当于渲染管线中的一个"步骤"或"阶段",它完成特定的后期效果操作。
- EffectComposer会按照Pass添加的顺序,依次执行每个Pass中的效果操作。
- 执行完一个Pass后,会将结果传递给下一个Pass,实现层叠效果。
所以每个Pass可以看作是:
- 渲染结果在经过一个"步骤"或"阶段"的处理。
- 完成特定的后期效果,比如模糊、色调等。
- 输出结果作为下一个Pass的输入,实现分步叠加效果。
所以Pass的概念就是将后期效果拆分为独立的"步骤"或"阶段",依次执行来实现复杂效果,与渲染管线思想相似。

 后期处理(Post-processing)在三维渲染中的含义是:
- 指在基本渲染完成后,对渲染结果进行额外处理的过程。
- 目的是为了实现更丰富的视觉效果,比如模糊、曝光、色调等。
后期处理常见技术包括:
- 色调映射/色调处理 - 对图像进行色调的增强或修改。
- 曝光/对比度 - 调整图像整体的亮度和对比度。
- 高动态范围渲染 - 实现更广泛的明亮和暗部处理。 
- 光晕/发光 - 实现光源周围的发光效果。
- 模糊 - 对图像部分区域进行模糊,如镜头模糊。
- 阴影/光照 - 对阴影区域进行增强处理。
- 着色/颜色校正 - 对图像整体或局部颜色进行修改。
后期处理的优点:
- 能实现更丰富的图像效果表现力。
- 对基本渲染结果进行二次处理。
- 常用于电影后期、游戏渲染等需要视觉效果的领域。
所以后期处理是三维渲染的重要组成部分。
---

 PerspectiveCamera和OrthographicCamera是Three.js中两个常用的相机类型,主要区别如下:
**PerspectiveCamera(透视相机)**
- 使用透视投影,近大远小,模拟人眼视觉。
- 有fov、aspect、near、far这些投影参数。
- 形成一个锥形视野范围。
**OrthographicCamera(正交相机)** 
- 使用正交投影,所有物体在视野内都看起来是等大的。 
- 没有fov、near/far概念,只有left/right/top/bottom范围。
- 形成一个立方体形状的视野范围。
联系:
- 都用于定义场景的观察视角。
- PerspectiveCamera效果更真实,Orthographic用于技术绘制。
区别在于:
- PerspectiveCamera使用透视投影。
- OrthographicCamera使用正交投影,没有透视 foreshortening 效果。
正确选择相机类型能带来更好的三维渲染效果。

 `.fog`属性是Three.js场景对象Scene中的一个重要属性,它用于定义场景中的雾效。
`.fog`的主要属性和方法如下:
- `.fog = new THREE.Fog(color, near, far)`
  创建雾效对象,参数为颜色、近距離、远距離。
- `.fog.color`
  雾效颜色。
- `.fog.near`
  雾效起始距离。
- `.fog.far`  
  雾效结束距离。
- scene.fog = fog
  将雾效对象添加到场景中。
当物体距离 camera 超过 `.fog.near` 时,会开始混合雾效颜色。
并在小于 `.fog.far` 时达到最浓密状态。
通过设置 `.fog` 属性可以很好的模拟大气环境中的远景朦胧效果。
它能很好的增强三维场景的真实感和包围性。是场景设置中的一个重要元素。


  下面是对代码块进行逐行注释和模块划分:
```js
// 导入Three.js
import * as THREE from 'three'; 
// 主函数
function main() {
  // 1. 设置canvas
  const canvas = document.querySelector('#c');
  // 2. 创建渲染器
  const renderer = new THREE.WebGLRenderer({
    antialias: true,
    canvas  
  });
  // 3. 设置相机参数
  const fov = 75;
  const aspect = 2;
  const near = 0.1;
  const far = 5;
  // 4. 创建透视相机
  const camera = new THREE.PerspectiveCamera(
    fov, 
    aspect,
    near,
    far
  );
  // 设置相机位置
  camera.position.z = 2;
  // 5. 创建场景
  const scene = new THREE.Scene();
  // 6. 添加光源
  {
    // 光源颜色和强度
    const color = 0xFFFFFF;  
    const intensity = 3;  
    // 创建光源
    const light = new THREE.DirectionalLight(
      color,
      intensity
    );
    // 设置光源位置
    light.position.set(-1, 2, 4);
    // 添加到场景
    scene.add(light);
  }
  // 7. 创建立方体几何体和材质
  // 几何体
  const boxWidth = 1;
  const boxHeight = 1; 
  const boxDepth = 1;
  const geometry = new THREE.BoxGeometry(
    boxWidth,
    boxHeight,
    boxDepth
  );
  // 材质
  const material = new THREE.MeshPhongMaterial({
    color: 0x44aa88
  });
  // 8. 创建网格对象
  const cube = new THREE.Mesh(geometry, material);
  // 添加到场景
  scene.add(cube);
  // 9. 渲染循环
  function render(time) {
    // 旋转立方体
    cube.rotation.x = time;
    cube.rotation.y = time;
    // 渲染场景
    renderer.render(scene, camera);  
    // 请求再次渲染
    requestAnimationFrame(render);
  }
  // 启动渲染循环
  requestAnimationFrame(render);
}
// 启动主函数
main();
```
通过注释和模块划分,可以更清晰地理解代码逻辑和功能结构。

 这段代码创建了一个Three.js中的WebGLRenderer对象。
WebGLRenderer是Three.js中用于渲染三维场景的主要渲染器对象。
代码中:
- THREE.WebGLRenderer是WebGLRenderer的构造函数
- antialias设置是否开启抗锯齿
- canvas指定渲染目标,这里渲染到id为c的canvas元素上
具体分析:
- WebGLRenderer使用WebGL API进行渲染
- 它负责将场景、相机等信息渲染到指定的canvas或webgl上下文中
- antialias开启可以使渲染效果更平滑 
- canvas指定渲染结果呈现的地方
所以这段代码完成了:
1. 创建Three.js的主渲染器WebGLRenderer
2. 开启抗锯齿
3. 指定渲染目标为id为c的canvas
WebGLRenderer对象是Three.js渲染的核心,它负责将三维场景最后渲染输出。

 您提出了一个好问题。代码中使用requestAnimationFrame调用渲染函数render两次,原因是:
- 第一次调用requestAnimationFrame(render)是为了启动动画循环。
- requestAnimationFrame是一个浏览器API,它会在每次屏幕刷新前调用回调函数,实现动画效果。
- 但仅仅调用一次不足以形成一个永久性的循环。
- 所以需要在render函数内部再次调用requestAnimationFrame(render),将渲染任务放入浏览器的任务队列中。
- 这样浏览器就会在每次屏幕刷新前都调用render函数,实现动画的连续渲染。
- 如果仅仅调用一次,动画就无法循环播放,仅能渲染一次。
所以:
- 第一次调用是为了启动动画循环
- 内部再调用是为了实现动画循环的持续性
两次调用合在一起才能形成一个完整的动画渲染循环。

 THREE.MeshPhongMaterial 是 Three.js 中常用的材质类型之一。
MeshPhongMaterial 使用 Phong 着色模型,可以实现更逼真的光照效果。
主要属性和方法:
- color: 设置材质颜色。
- specular: 设置镜面光颜色。
- shininess: 设置镜面光亮度,值越大越亮,取值范围0-100。
- opacity: 设置透明度,1为不透明,0为完全透明。
- transparent: 设置是否启用透明渲染。
- side: 设置正面和背面渲染,FrontSide、BackSide、DoubleSide。
- vertexColors: 是否使用顶点颜色。
使用方法:
```js
const material = new THREE.MeshPhongMaterial({
  color: 0xff0000,
  specular: 0x111111, 
  shininess: 30
});
```
它比MeshBasicMaterial效果更逼真,支持镜面光等光照效果。
适用于需要更真实光照的场景,如金属材质等。是Three.js常用高级材质类型。

  下面是格式化和注释后的代码:
```js
// 导入Three.js
import * as THREE from 'three';
function main() {
  // 1. 设置canvas
  const canvas = document.querySelector('#c');
  // 2. 创建渲染器
  const renderer = new THREE.WebGLRenderer({
    antialias: true,
    canvas  
  });
  // 3. 设置相机参数
  const fov = 75;
  const aspect = 2; // 画布宽高比
  const near = 0.1;
  const far = 5;
  // 4. 创建透视相机
  const camera = new THREE.PerspectiveCamera(
    fov, 
    aspect,
    near,
    far
  );
  // 设置相机位置
  camera.position.z = 2;
  // 5. 创建场景
  const scene = new THREE.Scene();
  // 6. 添加光源
  {
    // 光源颜色和强度
    const color = 0xFFFFFF;   
    const intensity = 3;
    // 创建光源
    const light = new THREE.DirectionalLight(
      color,
      intensity
    );
    // 设置光源位置
    light.position.set(-1, 2, 4); 
    // 添加到场景
    scene.add(light);
  }
  // 7. 创建立方体几何体
  const boxWidth = 1;
  const boxHeight = 1;
  const boxDepth = 1;
  const geometry = new THREE.BoxGeometry(
    boxWidth, 
    boxHeight,
    boxDepth
  );
  // 8. 创建立方体函数
  function makeInstance(geometry, color, x) {
    // 创建材质
    const material = new THREE.MeshPhongMaterial({color});
    // 创建网格对象
    const cube = new THREE.Mesh(geometry, material);
    // 添加到场景
    scene.add(cube);
    // 设置位置
    cube.position.x = x;
    return cube;
  }
  // 9. 创建三个立方体
  const cubes = [
    makeInstance(geometry, 0x44aa88, 0),  
    makeInstance(geometry, 0x8844aa, -2),
    makeInstance(geometry, 0xaa8844, 2)
  ];
  // 10. 渲染循环
  function render(time) {
    // 时间处理
    time *= 0.001;  
    // 旋转每个立方体
    cubes.forEach((cube, ndx) => {
      // 速度
      const speed = 1 + ndx * 0.1;
      // 旋转
      const rot = time * speed;  
      cube.rotation.x = rot;
      cube.rotation.y = rot;
    });
    // 渲染
    renderer.render(scene, camera);
    // 请求再次渲染
    requestAnimationFrame(render);
  }
  // 启动渲染循环
  requestAnimationFrame(render);
}
main();
```
主要做了格式化、模块划分和行内注释,保持代码完整性。

 您提出了一个好问题。
这段代码中:
- ndx来自cubes数组的forEach循环索引。
forEach会传入每个元素的索引作为第二个参数,这里取名为ndx。
- time来自渲染函数render的参数time。
render函数每次被调用时都会传入一个时间参数time。
具体分析:
- cubes数组包含3个立方体对象
- forEach循环每个立方体
- ndx记录当前是第几个立方体,从0开始
- time记录当前渲染时刻的时间戳
- speed根据ndx增量计算旋转速度
- rot计算旋转角度,结合time和speed
- 设置到cube.rotation实现旋转动画
所以:
- ndx来自forEach循环索引
- time来自render函数的参数
两者结合为每个立方体设置不同的旋转速度实现动画效果。

---

 您提出了一个好问题。代码中没有明确调用render(time)函数,而是使用requestAnimationFrame来启动动画循环。
requestAnimationFrame的工作原理是:
- 它是一个浏览器API,用于请求重绘窗口,实现动画效果。
- 每次浏览器重绘前,它会自动调用回调函数参数作为参数传递时间戳。
- 我们把render函数传给它作为回调,这样浏览器每帧就会自动调用render(time)。
具体流程:
1. 首次调用requestAnimationFrame(render),将render注册为回调
2. 浏览器重绘前,自动调用render(time),time为当前时间戳
3. 在render内部,我们再次调用requestAnimationFrame(render)
4. 浏览器循环1-3,实现动画循环渲染
所以:
- 我们不需要手动调用render
- requestAnimationFrame自动每帧调用render(time)
- 实现动画循环渲染,看不到直接调用但其实在自动调用
这就是requestAnimationFrame的工作机制。

  这段代码调用了makeInstance函数来创建立方体对象。
makeInstance函数定义如下:
```js
function makeInstance(geometry, color, x) {
  // ...
}
```
那么它的三个参数分别代表:
- geometry: 指定要使用的几何体对象
- color: 指定材质颜色,这里使用16进制0x44aa88表示绿色
- x: 指定立方体在x轴位置
具体分析:
- geometry传入全局定义的BoxGeometry对象
- color定义材质颜色为绿色
- x指定该实例在x轴位置为0
makeInstance函数内部会使用这三个参数:
- geometry来创建Mesh对象
- color来设置材质颜色
- x来设置实例对象的位置
所以这三个参数分别指定了:
- 几何体
- 颜色 
- 位置
用来定义每个立方体实例的基本属性。

  依赖DOM的script和不依赖DOM的script的区别在于:
**依赖DOM的script**
- 代码中需要操作DOM元素,如获取、添加、删除DOM节点等
- 例如:
  ```js
  const canvas = document.getElementById('canvas');
  ```
- 这需要等待DOM完全加载和解析后才能执行
**不依赖DOM的script** 
- 代码中不进行任何DOM操作
- 仅包含纯JavaScript逻辑,如三维渲染代码
- 例如:
  ```js
  const scene = new THREE.Scene();
  ```
- 不需要DOM也可以正常执行
区别在于:
- 依赖DOM的script需要DOM加载完毕后才能运行
- 不依赖DOM的script可以在DOM加载前就执行
所以正确做法是:
- 依赖DOM的script放在body结束前
- 不依赖DOM的script可以放在head部或body开头
以保证DOM加载完成,又不阻塞后续资源下载。

 这段代码使用sunMesh对象的scale属性来缩放模型。
scale属性在Three.js中用于设置物体在x,y,z三个轴向的缩放比例。
sunMesh.scale.set(5, 5, 5)具体意思是:
- sunMesh是三维网格对象
- scale是该对象的缩放属性
- set方法同时设置x,y,z三个轴向的缩放值
- 分别设置为5,5,5
设置完成后,原来单位大小的模型将会扩大5倍。
scale的默认值是1,1,1,表示原大小。
设置大于1的值可以实现放大效果。
设置小于1的值可以实现缩小效果。
三个参数可以单独设置,也可以同时设置。
通过修改scale属性很方便实现模型的大小调整,是模型变形的重要手段之一。
所以这段代码通过scale实现了太阳模型5倍的放大效果。

```js
const camera = new THREE.PerspectiveCamera( fov, aspect, near, far );
	camera.position.set( 0, 150, 0 );
	camera.up.set( 0, 0, 1 );
	camera.lookAt( 0, 0, 0 );
```
 这三行代码设置了相机的位置、上向量和目标点,具体作用如下:
1. camera.position.set(0, 150, 0)
- 设置相机位置坐标为(0, 150, 0),即在Y轴正方向150单位处
2. camera.up.set(0, 0, 1) 
- 设置相机的上向量为(0, 0, 1),即指向Z轴正方向
3. camera.lookAt(0, 0, 0)
- 设置相机目标点为原点(0, 0, 0)
这三项设置决定了相机的基本属性:
- 位置在Y轴正方向150处,俯视场景
- 上向量指向Z轴,确定相机本地坐标系方向 
- 目标点在原点,相机正对原点
通过这三行可以很方便地设置相机的基本观察属性:
- 位置、上向量确定相机的方向和姿态
- 目标点确定相机的焦点位置
从而实现对场景的观察设置。

---
 根据代码可以分析出:
- earthOrbit是一个三维对象,它被添加到solarSystem对象中。
- earthMesh是地球模型对象,它被添加到earthOrbit对象中。
两者的联系和区别:
联系:
- earthMesh是earthOrbit的子对象,会随earthOrbit一起移动旋转。
区别:
- earthOrbit控制地球的公转轨道位置和参数。
- earthMesh控制地球自身的形状、材质等模型属性。
具体来说:
- earthOrbit每帧更新其位置,实现地球围绕太阳的公转轨道。
- earthMesh随earthOrbit一起转动,自身也每帧更新自转角度。
所以:
- earthOrbit控制地球的公转轨道
- earthMesh是地球模型本身
两者通过父子关系结合实现地球的公转和自转动画效果。

 material.color.setHSL方法用于使用 HSL 色彩模型来设置材质颜色。
HSL 色彩模型用色相(H)、饱和度(S)和亮度(L)三个参数来表示颜色。
material.color.setHSL方法的三个参数分别为:
- H - 色相,取值0-1,0为红色,0.167为橙色等
- S - 饱和度,取值0-1,0为灰色(无色),1为饱和色 
- L - 亮度,取值0-1,0为黑色,1为白色
所以:
material.color.setHSL(0, 1, .5)
- 色相H为0,表示红色
- 饱和度S为1,表示饱和色 
- 亮度L为0.5,表示中等亮度
这样就设置了一个饱和度100%、亮度50%的红色。
通过HSL模型可以更直观地控制和调整颜色,比RGB模型更人性化。它是Three.js中常用的颜色设置方式之一。
注意，[`THREE.Color`](https://localhost:8080/docs/#api/zh/math/Color) 类型的属性有多种设置方式。
```js
- const material = new THREE.MeshPhongMaterial();
- material.color.set(0x00FFFF); // 同 CSS的 #RRGGBB 风格
- material.color.set(cssString); // 任何 CSS 颜色字符串, 比如 'purple', '#F32',
- // 'rgb(255, 127, 64)',
- // 'hsl(180, 50%, 25%)'
- material.color.set(someColor) // 其他一些 THREE.Color
- material.color.setHSL(h, s, l) // 其中 h, s, 和 l 从 0 到 1
- material.color.setRGB(r, g, b) // 其中 r, g, 和 b 从 0 到 1
```

 Three.js中的坐标系与通常的三维坐标系是一致的:
- X轴指向右边,从左到右为负到正
- Y轴指向上边,从下到上为负到正  
- Z轴指向前方,从后到前为负到正
Three.js坐标系的主要特点:
- 默认情况下Z轴指向屏幕,X、Y轴平行于屏幕
- 相机也遵循这个坐标系,它看向-Z轴方向
- 模型默认旋转轴顺序是XYZ,先X轴后Y轴最后Z轴
- 光源位置等属性也使用这个坐标系
在Three.js中常见的坐标轴使用:
- 模型位置属性(mesh.position)使用XYZ表示
- 相机位置属性使用XYZ
- 旋转属性(rotation)使用XYZ轴旋转
- 光源位置等也使用XYZ
所以总的来说:
- X向右、Y向上、Z向前
- 与常规三维坐标系一致
- 相机、模型等都遵循这个坐标定义
正确理解它有利于使用Three.js开发三维场景。

```js
	function resizeRendererToDisplaySize( renderer ) {

		const canvas = renderer.domElement;
		const width = canvas.clientWidth;
		const height = canvas.clientHeight;
		const needResize = canvas.width !== width || canvas.height !== height;
		if ( needResize ) {

			renderer.setSize( width, height, false );

		}

		return needResize;

	}
```
 这个函数的作用是将渲染器(renderer)的大小重新设置为canvas的当前显示大小。
具体作用:
1. 获取renderer对应的canvas元素
2. 获取canvas当前的clientWidth和clientHeight,也就是它当前显示的宽高
3. 判断canvas原始宽高是否等于当前宽高,如果不等则需要resize
4. 如果需要resize,调用renderer的setSize方法,将其宽高设置为canvas的当前宽高
5. setSize的最后一个参数false表示不清空canvas内容
6. 返回是否需要resize,用于外部判断是否需要重渲染
这样做的目的是:
- 响应浏览器窗口或屏幕尺寸的变化
- 保持渲染输出和canvas大小一致
- 避免渲染结果与显示不匹配导致拉伸等问题
所以这个函数的作用就是帮助三维场景自动适应显示器大小变化。

  下面是格式化并注释后的代码:
```js
// 渲染函数
function render(time) {
  // 1. 时间处理
  time *= 0.001;  
  // 2. 检测尺寸是否需要更新
  if (resizeRendererToDisplaySize(renderer)) {
    // 获取canvas
    const canvas = renderer.domElement;
  
    // 更新相机宽高比
    camera.aspect = canvas.clientWidth / canvas.clientHeight;
  
    // 更新相机投影矩阵
    camera.updateProjectionMatrix();
  }
  // 3. 旋转每个立方体
  cubes.forEach((cube, ndx) => {
    // 速度
    const speed = 0.2 + ndx * 0.1;  
    // 旋转角度
    const rot = time * speed;
    // 设置x轴旋转
    cube.rotation.x = rot;  
    // 设置y轴旋转  
    cube.rotation.y = rot;
  });
  // 4. 渲染场景
  renderer.render(scene, camera);
  // 5. 请求再次渲染
  requestAnimationFrame(render);
}
```
注释了每个步骤的功能,便于理解渲染流程。

 ```js
// 主函数
function main() {
  // 1. 获取canvas元素
  const canvas = document.querySelector('#c');
  // 2. 创建渲染器,传入canvas
  const renderer = new THREE.WebGLRenderer({
    antialias: true, 
    canvas
  });
  // 3. 设置相机视角参数
  const fov = 75;
  const aspect = 2; // 画布宽高比
  const near = 0.1; 
  const far = 5;
  // 4. 创建透视相机
  const camera = new THREE.PerspectiveCamera(
    fov, 
    aspect,
    near,
    far
  );
  // 5. 设置相机位置
  camera.position.z = 2;
  // 6. 创建场景
  const scene = new THREE.Scene();
  // 7. 创建立方几何体参数
  const boxWidth = 1;
  const boxHeight = 1; 
  const boxDepth = 1;
  // 8. 创建立方几何体
  const geometry = new THREE.BoxGeometry(
    boxWidth,
    boxHeight, 
    boxDepth
  );
  // 9. 定义存放立方体的数组
  const cubes = [];  
  // 10. 创建纹理加载器
  const loader = new THREE.TextureLoader();
  // 11. 加载图片纹理
  loader.load('url', (texture) => {
    // 12. 设置纹理颜色空间
    texture.colorSpace = THREE.SRGBColorSpace;
    // 13. 创建材质
    const material = new THREE.MeshBasicMaterial({
      map: texture
    });
    // 14. 创建网格对象
    const cube = new THREE.Mesh(geometry, material);
    // 15. 添加到场景和数组
    scene.add(cube);
    cubes.push(cube);
  });
}
```
逐行详细注释了主函数的各个步骤。

 Mesh对象是Three.js中最常见和基础的物体类型之一。
Mesh对象表示一个三维网格模型,它由几何体(Geometry)和材质(Material)组成。
主要特点和属性:
- geometry属性存储网格的几何数据
- material属性存储网格的材质效果
- 可以通过设置position、rotation等属性控制网格在场景中的位置和姿态
- 可添加到场景中渲染输出
常见创建方式:
```js
// 使用几何体和材质创建
const mesh = new THREE.Mesh(geometry, material);
// 也可以直接传入几何数据创建
const mesh = new THREE.Mesh(
  new THREE.BoxGeometry(1, 1, 1), 
  new THREE.MeshBasicMaterial()
);
```
Mesh对象是Three.js中最基本的可渲染对象,几乎所有3D模型都可以表示为Mesh。
它通过几何体和材质描述物体的外形和效果。是三维场景的基础组成部分。

```js
// Three.js - Cameras - Perspective 2 views
// from https://localhost:8080/manual/examples/cameras-perspective-2-scenes.html


import * as THREE from 'three';
import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
import { GUI } from 'three/addons/libs/lil-gui.module.min.js';

function main() {

	const canvas = document.querySelector( '#c' );
	const view1Elem = document.querySelector( '#view1' );
	const view2Elem = document.querySelector( '#view2' );
	const renderer = new THREE.WebGLRenderer( { antialias: true, canvas } );

	const fov = 45;
	const aspect = 2; // the canvas default
	const near = 5;
	const far = 100;
	const camera = new THREE.PerspectiveCamera( fov, aspect, near, far );
	camera.position.set( 0, 10, 20 );

	const cameraHelper = new THREE.CameraHelper( camera );

	class MinMaxGUIHelper {

		constructor( obj, minProp, maxProp, minDif ) {

			this.obj = obj;
			this.minProp = minProp;
			this.maxProp = maxProp;
			this.minDif = minDif;

		}
		get min() {

			return this.obj[ this.minProp ];

		}
		set min( v ) {

			this.obj[ this.minProp ] = v;
			this.obj[ this.maxProp ] = Math.max( this.obj[ this.maxProp ], v + this.minDif );

		}
		get max() {

			return this.obj[ this.maxProp ];

		}
		set max( v ) {

			this.obj[ this.maxProp ] = v;
			this.min = this.min; // this will call the min setter

		}

	}

	const gui = new GUI();
	gui.add( camera, 'fov', 1, 180 );
	const minMaxGUIHelper = new MinMaxGUIHelper( camera, 'near', 'far', 0.1 );
	gui.add( minMaxGUIHelper, 'min', 0.1, 50, 0.1 ).name( 'near' );
	gui.add( minMaxGUIHelper, 'max', 0.1, 50, 0.1 ).name( 'far' );

	const controls = new OrbitControls( camera, view1Elem );
	controls.target.set( 0, 5, 0 );
	controls.update();

	const camera2 = new THREE.PerspectiveCamera(
		60, // fov
		2, // aspect
		0.1, // near
		500, // far
	);
	camera2.position.set( 40, 10, 30 );
	camera2.lookAt( 0, 5, 0 );

	const controls2 = new OrbitControls( camera2, view2Elem );
	controls2.target.set( 0, 5, 0 );
	controls2.update();

	const scene = new THREE.Scene();
	scene.background = new THREE.Color( 'black' );
	scene.add( cameraHelper );

	{

		const planeSize = 40;

		const loader = new THREE.TextureLoader();
		const texture = loader.load( 'https://localhost:8080/manual/examples/resources/images/checker.png' );
		texture.wrapS = THREE.RepeatWrapping;
		texture.wrapT = THREE.RepeatWrapping;
		texture.magFilter = THREE.NearestFilter;
		texture.colorSpace = THREE.SRGBColorSpace;
		const repeats = planeSize / 2;
		texture.repeat.set( repeats, repeats );

		const planeGeo = new THREE.PlaneGeometry( planeSize, planeSize );
		const planeMat = new THREE.MeshPhongMaterial( {
			map: texture,
			side: THREE.DoubleSide,
		} );
		const mesh = new THREE.Mesh( planeGeo, planeMat );
		mesh.rotation.x = Math.PI * - .5;
		scene.add( mesh );

	}

	{

		const cubeSize = 4;
		const cubeGeo = new THREE.BoxGeometry( cubeSize, cubeSize, cubeSize );
		const cubeMat = new THREE.MeshPhongMaterial( { color: '#8AC' } );
		const mesh = new THREE.Mesh( cubeGeo, cubeMat );
		mesh.position.set( cubeSize + 1, cubeSize / 2, 0 );
		scene.add( mesh );

	}

	{

		const sphereRadius = 3;
		const sphereWidthDivisions = 32;
		const sphereHeightDivisions = 16;
		const sphereGeo = new THREE.SphereGeometry( sphereRadius, sphereWidthDivisions, sphereHeightDivisions );
		const sphereMat = new THREE.MeshPhongMaterial( { color: '#CA8' } );
		const mesh = new THREE.Mesh( sphereGeo, sphereMat );
		mesh.position.set( - sphereRadius - 1, sphereRadius + 2, 0 );
		scene.add( mesh );

	}

	{

		const color = 0xFFFFFF;
		const intensity = 3;
		const light = new THREE.DirectionalLight( color, intensity );
		light.position.set( 0, 10, 0 );
		light.target.position.set( - 5, 0, 0 );
		scene.add( light );
		scene.add( light.target );

	}

	function resizeRendererToDisplaySize( renderer ) {

		const canvas = renderer.domElement;
		const width = canvas.clientWidth;
		const height = canvas.clientHeight;
		const needResize = canvas.width !== width || canvas.height !== height;
		if ( needResize ) {

			renderer.setSize( width, height, false );

		}

		return needResize;

	}

	function setScissorForElement( elem ) {

		const canvasRect = canvas.getBoundingClientRect();
		const elemRect = elem.getBoundingClientRect();

		// compute a canvas relative rectangle
		const right = Math.min( elemRect.right, canvasRect.right ) - canvasRect.left;
		const left = Math.max( 0, elemRect.left - canvasRect.left );
		const bottom = Math.min( elemRect.bottom, canvasRect.bottom ) - canvasRect.top;
		const top = Math.max( 0, elemRect.top - canvasRect.top );

		const width = Math.min( canvasRect.width, right - left );
		const height = Math.min( canvasRect.height, bottom - top );

		// setup the scissor to only render to that part of the canvas
		const positiveYUpBottom = canvasRect.height - bottom;
		renderer.setScissor( left, positiveYUpBottom, width, height );
		renderer.setViewport( left, positiveYUpBottom, width, height );

		// return the aspect
		return width / height;

	}

	function render() {

		resizeRendererToDisplaySize( renderer );

		// turn on the scissor
		renderer.setScissorTest( true );

		// render the original view
		{

			const aspect = setScissorForElement( view1Elem );

			// adjust the camera for this aspect
			camera.aspect = aspect;
			camera.updateProjectionMatrix();
			cameraHelper.update();

			// don't draw the camera helper in the original view
			cameraHelper.visible = false;

			scene.background.set( 0x000000 );

			// render
			renderer.render( scene, camera );

		}

		// render from the 2nd camera
		{

			const aspect = setScissorForElement( view2Elem );

			// adjust the camera for this aspect
			camera2.aspect = aspect;
			camera2.updateProjectionMatrix();

			// draw the camera helper in the 2nd view
			cameraHelper.visible = true;

			scene.background.set( 0x000040 );

			renderer.render( scene, camera2 );

		}

		requestAnimationFrame( render );

	}

	requestAnimationFrame( render );

}

main();

```

 ```js
// 1. 创建一个方向光
const color = 0xFFFFFF;  
const intensity = 3;
const light = new THREE.DirectionalLight(color, intensity);
// 2. 设置光源位置  
light.position.set(0, 10, 0);
// 3. 设置光照目标位置
light.target.position.set(-5, 0, 0); 
// 4. 将光源添加到场景
scene.add(light);
// 5. 将光源目标也添加到场景  
scene.add(light.target);
```
这段代码添加了一个方向光源:
- 创建方向光,设置颜色和强度
- 设置光源和目标位置
- 将光源和目标添加到场景
方向光会根据目标位置产生光照效果。
通过它可以给场景添加光照渲染,实现更真实的三维效果。

```js
- {
- const color = 0xFFFFFF;
- const intensity = 1;
- const light = new THREE.DirectionalLight(color, intensity);
- light.position.set(-1, 2, 4);
- rtScene.add(light);
- }

- const boxWidth = 1;
- const boxHeight = 1;
- const boxDepth = 1;
- const geometry = new THREE.BoxGeometry(boxWidth, boxHeight, boxDepth);

- function makeInstance(geometry, color, x) {
- const material = new THREE.MeshPhongMaterial({color});

- const cube = new THREE.Mesh(geometry, material);
- rtScene.add(cube);

- cube.position.x = x;

- return cube;
- }

- const rtCubes = [
- makeInstance(geometry, 0x44aa88, 0),
- makeInstance(geometry, 0x8844aa, -2),
- makeInstance(geometry, 0xaa8844, 2),
- ];
```
 这段代码使用了一对大括号{}包裹,这种语法在JavaScript中被称为块级作用域(block statement)。
块级作用域使用{}将一组语句包裹在一起,它具有以下特点:
- 变量声明在{}内,只在块级作用域内有效,外部无法访问
- 可以把一组相关操作分组,起到分块的作用
- 不影响代码执行流程,只是一种语法结构
所以这段代码使用{}包裹光源添加逻辑:
- 将光源相关操作分组到一个块中
- 声明的变量color、intensity等只在块内有效
- 不影响其他代码,只起到分组的作用
它不影响代码执行,只是一种代码组织方式。
所以这段代码使用{}定义了一个块级作用域,将光源添加逻辑分组,主要起到代码结构和变量作用域隔离的作用。

 下面用一些比喻来描述Three.js中各对象之间的联系:
- 场景(Scene)可以看作是一个舞台。它可以包含和管理所有其他对象。
- 相机(Camera)就像观众的视角。它决定我们看到场景的哪个部分。
- 光源(Light)扮演照明的角色。它给场景中的对象提供光照效果。
- 几何体(Geometry)是建筑材料,用来构建模型的外形。
- 材质(Material)就像油漆,它给几何体添加颜色和表面效果。
- 网格(Mesh)可以看作是用材料装修过的房子。它由几何体和材质组成。
- 场景中的其他对象都可以看作是房子里的家具。它们都需要添加到场景中。
- 渲染器(Renderer)的角色是摄影师,它负责“拍照”场景并输出渲染结果。
- 动画系统可以看作是导演,它控制对象随时间变化的移动和变形。
通过这些比喻,可以更直观地理解Three.js中各对象的角色和它们之间的联系关系。帮助学习Three.js的工作原理。


```js
let scene, camera, renderer, spotLight, composer;

const init = () => {
  // 创建场景
  scene = new THREE.Scene();
  scene.background = new THREE.Color(0x000000);

  // 创建渲染器
  renderer = new THREE.WebGLRenderer({ antialias: true });
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.toneMapping = THREE.ReinhardToneMapping;
  renderer.toneMappingExposure = 3;
  renderer.shadowMap.enabled = true;
  document.body.appendChild(renderer.domElement);

  // 创建相机
  const aspect = window.innerWidth / window.innerHeight;
  camera = new THREE.PerspectiveCamera(35, aspect, 0.01, 1000);
  camera.position.set(0, 3, 5);

  // 相机控制器
  const controls = new THREE.OrbitControls(camera, renderer.domElement);
  controls.addEventListener('change', renderer);

  // 环境光
  const hemiLight = new THREE.HemisphereLight(0xffeeb1, 0x080820, 2);
  scene.add(hemiLight);

  // 聚光灯
  spotLight = new THREE.SpotLight(0xffa95c, 4);
  spotLight.castShadow = true;
  spotLight.shadow.bias = -0.001;
  spotLight.shadow.mapSize.width = 10000;
  spotLight.shadow.mapSize.height = 10000;
  scene.add(spotLight);

  // 后期处理
  composer = new POSTPROCESSING.EffectComposer(renderer);
  composer.addPass(new POSTPROCESSING.RenderPass(scene, camera));

  const effectPass = new POSTPROCESSING.EffectPass(
  camera,
  new POSTPROCESSING.BloomEffect({
    intensity: 3,
    luminanceThreshold: 0.8,
    width: 100,
    height: 100,
  })
  );
  composer.addPass(effectPass);

  // 模型加载
  const loader = new THREE.GLTFLoader();
  loader.load('scene.gltf', (result) => {
  // 获取加载的模型
  const model = result.scene.children[0];

  // 遍历模型的子节点
  model.traverse((n) => {
    if (n.isMesh) {
    // 设置模型的阴影属性和纹理属性
    n.castShadow = true;
    n.receiveShadow = true;
    if (n.material.map) n.material.map.anisotropy = 100;
    }
  });

  // 将模型添加到场景中
  scene.add(model);

  // 启动动画循环
  animate();
  });
};

// 递归循环渲染场景
const animate = () => {
  requestAnimationFrame(animate);

  // 设置聚光灯的位置
  spotLight.position.set(
  camera.position.x + 5,
  camera.position.y + 5,
  camera.position.z - 5
  );

  // 渲染场景
  composer.render();
};

// 初始化函数调用
init();


```

