LangChain æä¾›äº†å¤šç§**å†…ç½®çš„ Agent ç±»å‹ï¼ˆbuilt-in agentsï¼‰**ï¼Œå®ƒä»¬å°è£…äº†å¸¸è§çš„æ¨ç†æ¨¡å¼ï¼ˆå¦‚ ReActã€Plan-and-Executeã€Self-Ask ç­‰ï¼‰ï¼Œå¹¶è‡ªåŠ¨é…å¯¹äº†å¯¹åº”çš„ **æç¤ºæ¨¡æ¿ï¼ˆPromptï¼‰** å’Œ **è¾“å‡ºè§£æå™¨ï¼ˆOutputParserï¼‰**ã€‚ä½ æ— éœ€ä»é›¶å®ç°æ¨ç†é€»è¾‘ï¼Œåªéœ€æä¾› LLM å’Œå·¥å…·ï¼ˆToolsï¼‰å³å¯ã€‚

---

### ğŸ“¦ LangChain è‡ªå¸¦çš„ä¸»è¦ Agent ç±»å‹ï¼ˆæˆªè‡³ LangChain 0.2+ï¼‰

> æ³¨ï¼šéƒ¨åˆ†æ—§ç‰ˆ `AgentType` æšä¸¾å·²å¼ƒç”¨ï¼Œæ¨èä½¿ç”¨ `create_*_agent` å·¥å‚å‡½æ•° + `hub` æç¤ºã€‚

#### âœ… 1. **ReAct ç³»åˆ—ï¼ˆæœ€å¸¸ç”¨ï¼‰**
åŸºäº [ReAct: Synergizing Reasoning and Acting](https://arxiv.org/abs/2210.03629) è®ºæ–‡ï¼Œç»“åˆæ¨ç†ï¼ˆThoughtï¼‰ä¸è¡ŒåŠ¨ï¼ˆActionï¼‰ã€‚

| åç§° | åˆ›å»ºæ–¹å¼ | ç‰¹ç‚¹ |
|------|--------|------|
| **Zero-shot ReAct** | `create_react_agent(llm, tools, prompt)` | æœ€ç»å…¸ï¼Œæ”¯æŒå¤šå·¥å…·è°ƒç”¨ï¼Œéœ€æ¨¡å‹ç†è§£ ReAct æ ¼å¼ |
| **Structured ReAct** | `create_structured_chat_agent(...)` | æ”¯æŒèŠå¤©å†å²ï¼Œç»“æ„åŒ–è¾“å…¥ï¼ˆå¸¸ç”¨äºå¯¹è¯åœºæ™¯ï¼‰ |

> ğŸ”§ é…å¥—è§£æå™¨ï¼š`ReActSingleInputOutputParser` æˆ– `ReActJsonOutputParser`ï¼ˆè‹¥ç”¨ JSON æ¨¡å¼ï¼‰

ğŸ“Œ ä½¿ç”¨ç¤ºä¾‹ï¼š
```python
from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain_community.llms import Ollama

llm = Ollama(model="qwen:7b")
tools = [/* your tools */]

# æ‹‰å–å®˜æ–¹ ReAct æç¤ºï¼ˆå«æ ¼å¼æŒ‡ä»¤ï¼‰
prompt = hub.pull("hwchase17/react")  # æˆ– "langchain/structured-chat-react"

agent = create_react_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```

---

#### âœ… 2. **OpenAI Functions Agentï¼ˆä»…é™æ”¯æŒ function calling çš„æ¨¡å‹ï¼‰**
- é€‚ç”¨äº **OpenAI GPT-4-turbo / GPT-3.5-turbo**ã€**Anthropic Claude**ã€**Google Gemini** ç­‰æ”¯æŒåŸç”Ÿå‡½æ•°è°ƒç”¨çš„æ¨¡å‹ã€‚
- ä¸ä¾èµ– ReAct æ–‡æœ¬æ ¼å¼ï¼Œè€Œæ˜¯é€šè¿‡ **JSON Schema** å£°æ˜å·¥å…·ï¼Œç”±æ¨¡å‹ç›´æ¥è¿”å›ç»“æ„åŒ–å‡½æ•°è°ƒç”¨ã€‚

```python
from langchain.agents import create_openai_functions_agent

prompt = hub.pull("hwchase17/openai-functions-agent")
agent = create_openai_functions_agent(llm, tools, prompt)
```

> âš ï¸ **ä¸é€‚ç”¨äºæ™®é€šæœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ Llamaã€Qwen baseï¼‰**ï¼Œé™¤éä½ ç”¨ vLLM/Ollama å¯ç”¨äº† function calling ä»¿çœŸã€‚

---

#### âœ… 3. **Plan-and-Execute Agent**
- å…ˆè®©ä¸€ä¸ª â€œPlannerâ€ åˆ¶å®šå¤šæ­¥è®¡åˆ’ï¼Œå†ç”± â€œExecutorâ€ é€æ­¥æ‰§è¡Œã€‚
- é€‚åˆå¤æ‚ä»»åŠ¡ï¼Œä½†é€Ÿåº¦æ…¢ã€æˆæœ¬é«˜ã€‚

```python
from langchain.agents import create_plan_and_execute_agent
```

---

#### âœ… 4. **Self-Ask with Search**
- ä»…æ”¯æŒå•ä¸ª `Intermediate Answer` å·¥å…·ï¼ˆé€šå¸¸æ˜¯æœç´¢ï¼‰ã€‚
- æ¨¡å‹é€šè¿‡è‡ªé—®è‡ªç­”åˆ†è§£é—®é¢˜ï¼ˆå¦‚ â€œWhat is X? â†’ First, find Yâ€¦â€ï¼‰ã€‚
- ç°åœ¨è¾ƒå°‘ä½¿ç”¨ï¼Œå·²è¢« ReAct å–ä»£ã€‚

---

#### âœ… 5. **Tool Calling Agentsï¼ˆæ–°ç‰ˆæ¨èï¼‰**
LangChain 0.2+ æ¨å‡ºäº†æ›´ç»Ÿä¸€çš„ **tool calling interface**ï¼Œæ”¯æŒï¼š
- è‡ªåŠ¨æ ¹æ®å·¥å…·ç”Ÿæˆå·¥å…·æè¿°
- å…¼å®¹ OpenAIã€Anthropicã€Mistralã€Groq ç­‰åŸç”Ÿ tool calling
- å¯¹äºä¸æ”¯æŒçš„æ¨¡å‹ï¼ˆå¦‚ Llamaï¼‰ï¼Œå¯ fallback åˆ° ReAct

```python
from langchain_core.messages import HumanMessage
from langchain.tools.render import render_text_description
from langchain.agents import AgentExecutor, create_tool_calling_agent

# è‡ªåŠ¨é€‚é…æ¨¡å‹èƒ½åŠ›
agent = create_tool_calling_agent(llm, tools, prompt)
```

---

### ğŸ†š å†…ç½® Agent å¯¹æ¯”è¡¨

| Agent ç±»å‹ | æ˜¯å¦éœ€è¦ ReAct æ ¼å¼ | é€‚ç”¨æ¨¡å‹ | å¤šè½®å·¥å…·è°ƒç”¨ | å¤‡æ³¨ |
|-----------|------------------|--------|------------|------|
| `react` | âœ… æ˜¯ | ä»»ä½•æ–‡æœ¬æ¨¡å‹ï¼ˆQwen, Llama, GPTç­‰ï¼‰ | âœ… | æœ€é€šç”¨ |
| `openai-functions` | âŒ å¦ï¼ˆç”¨ JSONï¼‰ | OpenAI / Claude / Gemini | âœ… | é«˜æ•ˆå‡†ç¡® |
| `structured-chat-react` | âœ… æ˜¯ï¼ˆå¸¦èŠå¤©å†å²ï¼‰ | ä»»ä½• | âœ… | é€‚åˆå¯¹è¯ |
| `plan-and-execute` | âœ… æ˜¯ | ä»»ä½• | âœ…âœ… | å¤æ‚ä»»åŠ¡ |
| `tool_calling_agent` | âš ï¸ è‡ªåŠ¨é€‚é… | æ”¯æŒ function calling çš„ä¼˜å…ˆç”¨ JSONï¼Œå¦åˆ™å›é€€ ReAct | âœ… | **æ¨èæ–°é¡¹ç›®ä½¿ç”¨** |

---

### â“å¸¸è§é—®é¢˜

#### Q1: æˆ‘ç”¨ Qwen/Llamaï¼Œèƒ½ç”¨ `openai-functions-agent` å—ï¼Ÿ
**ä¸èƒ½ç›´æ¥ç”¨**ã€‚é™¤éï¼š
- ä½ ç”¨çš„æ˜¯ **Qwen-Max / Qwen-Plus**ï¼ˆé˜¿é‡Œäº‘ API æ”¯æŒ function callingï¼‰
- æˆ–ä½ ç”¨ **Ollama + function-calling é€‚é…å±‚**ï¼ˆå®éªŒæ€§ï¼‰
å¦åˆ™è¯·ç”¨ `react` æˆ– `tool_calling_agent`ï¼ˆå®ƒä¼šè‡ªåŠ¨é™çº§åˆ° ReActï¼‰

#### Q2: èƒ½ä¸ç”¨ä»»ä½•å†…ç½® Agent å—ï¼Ÿ
å¯ä»¥ï¼ä½ å¯ä»¥ï¼š
- ç›´æ¥è°ƒç”¨ `llm.invoke(prompt)` + è‡ªå®šä¹‰è§£æ
- å®ç°è‡ªå·±çš„ `AgentExecutor` å¾ªç¯
ä½†ä¼šå¤±å» LangChain çš„ retryã€memoryã€streaming ç­‰èƒ½åŠ›ã€‚

#### Q3: å¦‚ä½•æŸ¥çœ‹æŸä¸ª Agent çš„æç¤ºæ¨¡æ¿ï¼Ÿ
```python
prompt = hub.pull("hwchase17/react")
print(prompt.pretty_repr())  # æˆ– print(prompt.messages)
```
ä½ ä¼šçœ‹åˆ°ç±»ä¼¼ï¼š
```
Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question
```

---

### âœ… å»ºè®®

- **å¦‚æœä½ ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆQwenã€Llama ç­‰ï¼‰** â†’ ç”¨ `create_react_agent` æˆ– `create_tool_calling_agent`
- **å¦‚æœä½ ç”¨ OpenAI/Claude/Gemini** â†’ ä¼˜å…ˆç”¨ `create_openai_functions_agent` æˆ– `create_tool_calling_agent`
- **é‡åˆ°è§£æé”™è¯¯** â†’ ç»§æ‰¿ `AgentOutputParser` å†™ `CustomOutputParser`ï¼ˆå¦‚ä½ ä¹‹å‰åšçš„ï¼‰

---

éœ€è¦æˆ‘å¸®ä½ æ ¹æ®ä½ çš„å…·ä½“æ¨¡å‹ï¼ˆæ¯”å¦‚ Qwen2-7B-Instructï¼‰å’Œå·¥å…·ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¯è¿è¡Œ Agent ç¤ºä¾‹å—ï¼Ÿ