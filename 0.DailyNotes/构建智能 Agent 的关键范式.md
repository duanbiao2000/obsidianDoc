除了 ReAct 框架，还有多种构建智能 Agent 的关键范式，它们在不同的层面和策略上增强了 LLM 的推理、规划和执行能力。这些范式通常可以单独使用，也可以相互结合，以解决更复杂的任务。

以下是一些重要的 Agent 构建范式：

### 1. 链式思考 (Chain of Thought, CoT)

- **核心思想：** LLM 在给出最终答案之前，先生成一系列中间推理步骤。这就像要求 LLM “展示你的思考过程”。
- **特性：**
    - **提高复杂推理能力：** 通过强制 LLM 逐步思考，可以显著提高其在算术、符号推理和常识推理等复杂任务上的表现。
    - **可解释性：** 提供了 LLM 决策过程的内部视图。
    - **无需外部工具：** 纯粹依赖 LLM 自身的推理能力，不涉及外部工具调用。
- **与 ReAct 关系：** ReAct 是 CoT 的一个扩展。CoT 是 ReAct 中“Thought”部分的基础，ReAct 将 CoT 的推理步骤与外部“Action”相结合。

### 2. 自我反思 / 自我修正 (Self-Reflection / Self-Correction)

- **核心思想：** Agent 在执行任务后，会评估自己的输出或行动，识别潜在的错误或不足，然后基于这种反思来修正或改进。
- **特性：**
    - **错误检测与修正：** 通过批判性地审查自己的工作，Agent 可以迭代地完善答案或策略。
    - **评估机制：** 需要一个明确的评估标准或另一个 LLM 来对当前结果进行判断。
    - **迭代优化：** 允许 Agent 从错误中学习并提高性能。
- **与 ReAct 关系：** ReAct 的“Observation”步骤为自我反思提供了数据，Agent 可以根据观察到的结果来反思其Thought-Action链是否有效。

### 3. 思想树 (Tree of Thought, ToT)

- **核心思想：** 扩展了 CoT，允许 LLM 在思考过程中探索多个不同的推理路径（树状结构），而不是单一的线性链。Agent 可以进行前瞻性思考、回溯和全局评估，以找到最佳路径。
- **特性：**
    - **多路径探索：** 像人类解决问题时尝试不同方法一样，评估每个“思想分支”的潜在结果。
    - **回溯能力：** 当某个路径被证明无效时，可以回溯到之前的决策点并探索新的路径。
    - **更强的规划：** 适用于需要进行复杂搜索或多步规划的任务，如游戏、难题解决。
- **与 ReAct 关系：** ToT 可以在 ReAct 的“Thought”阶段内部应用，使 LLM 的思考过程更加丰富和有策略性。

### 4. 模块化推理、知识和语言 (MRKL - Modular Reasoning, Knowledge and Language)

- **核心思想：** 这是早期的一种混合专家系统，将 LLM 作为路由层，决定将请求转发给哪个“专家模块”（包括知识库、计算器、API 等工具），或直接由 LLM 回答。
- **特性：**
    - **模块化：** 将不同的功能封装在独立的模块中。
    - **路由能力：** LLM 充当一个智能调度员。
    - **效率：** 只有在需要时才调用特定模块，避免不必要的 LLM 推理。
- **与 ReAct 关系：** MRKL 是工具使用的早期概念。ReAct 更进一步，它不仅选择工具，还在使用工具后进行更深入的推理和迭代。

### 5. 生成式 Agent (Generative Agents)

- **核心思想：** (例如 Stanford/Google 的论文) 模拟人类行为和认知过程，通过记忆流、反思和规划来构建可信的虚拟人物。这些 Agent 能够在模拟环境中独立生活、交互和适应。
- **特性：**
    - **长期记忆和反思：** 能够回忆和反思过去的经验，从而影响未来的行为。
    - **动态规划：** 基于记忆和当前情境制定短期和长期计划。
    - **社会互动：** 在模拟环境中与其他 Agent 交互，形成社交网络。
    - **更复杂的行为模式：** 不仅解决特定任务，还能展现出更高级的、类似人类的复杂行为。
- **与 ReAct 关系：** 生成式 Agent 可能会在其内部的规划和执行循环中采用 ReAct 模式来与环境或内部工具进行交互。

### 6. 自主 Agent (Autonomous Agents - 如 AutoGPT / BabyAGI)

- **核心思想：** 旨在实现一个高层次的目标，并能够自主地进行任务分解、子任务执行、结果评估和迭代，直到目标达成。它们通常不需要人类的频繁干预。
- **特性：**
    - **目标驱动：** 围绕一个设定的高级目标进行所有行动。
    - **自主循环：** 持续地“思考 -> 行动 -> 观察 -> 评估 -> 调整”循环。
    - **任务分解与管理：** 能够识别和管理子任务。
    - **持久性：** 通常会利用外部存储来保存状态和进度。
- **与 ReAct 关系：** ReAct 是许多自主 Agent 内部微观执行循环的关键。自主 Agent 负责宏观的规划和任务管理，而 ReAct 则负责在每个子任务中进行细粒度的推理和工具调用。

### 7. 思想图谱 (Graph of Thoughts, GoT)

- **核心思想：** 将 CoT 和 ToT 进一步泛化，允许 LLM 的思想状态以任意图结构而不是线性或树状结构进行演化。这使得 Agent 能够进行更复杂的非线性思考，例如合并来自不同分支的思考、识别并处理循环依赖。
- **特性：**
    - **灵活的思考结构：** 超越线性和树状，支持更复杂的思考模式。
    - **多源信息融合：** 可以整合来自不同推理路径的信息。
    - **解决特定复杂问题：** 适用于需要高度非线性思考的场景。
- **与 ReAct 关系：** GoT 可以作为 ReAct 中“Thought”阶段的一种更高级、更复杂的实现方式。

### 总结

这些范式各自侧重于 LLM 智能 Agent 的不同方面：

- **CoT** 关注内部推理的**透明性**。
- **ReAct** 结合了**推理和外部行动**。
- **Self-Reflection** 强调**自我修正**。
- **ToT** 引入了**多路径探索**和**回溯**。
- **MRKL** 是**模块化工具使用**的早期探索。
- **Generative Agents** 和 **Autonomous Agents** 则将 LLM 提升到更宏观的**自主规划和行为**层面。
- **GoT** 提供了更**灵活的思考结构**。

在实践中，构建智能 Agent 往往会**混合和匹配**这些范式，例如一个自主 Agent 可能在其决策循环中嵌入 ReAct 模式，并利用自反思来改进其行为。