

##### **零停机迁移框架：五步法 (The 5-Step Framework)**

| 阶段                 | 核心操作                               | 目的                                       | 关键技术/代码模式                                        |
| :------------------- | :------------------------------------- | :----------------------------------------- | :------------------------------------------------------- |
| **1. 准备 (Preparation)** | 创建新表 (`user_profile` 等)，部署新服务但**不引入流量**。 | 建立新大陆，为迁徙做准备。                 | `GORM` 定义新模型，部署空的 API 服务。                     |
| **2. 双写 (Dual Write)**   | 修改应用代码，任何对旧表的**写操作**，都**同时写入**新表/新服务。 | 保证增量数据实时同步。                     | **异步双写 + 补偿队列** 模式。                           |
| **3. 数据同步 (Sync)**   | 用脚本将旧表的**历史数据**分批同步到新表。 | 迁移存量数据。                             | `pt-archiver` 或自定义分批 `SELECT ... LIMIT` 脚本。     |
| **4. 灰度读 (Gray Read)**  | 逐步将**读请求**从旧表切换到新服务。   | 验证新服务的性能和稳定性。                 | **基于配置或用户 ID 的流量切分** 模式。                    |
| **5. 切流 & 清理**     | 将所有**写请求**切换到新服务，关闭双写，下线旧表。 | 完成迁移，移除历史包袱。                   | **功能开关**，一键切换。数据校验脚本。                     |

---

#### **3. 关键代码模式 (Key Code Patterns)**

##### **模式一：异步双写 + 补偿队列 (确保最终一致性)**

```python
# 伪代码：更新用户资料
def update_user_profile(user_id, data):
    try:
        # 1. 主流程：写入旧表，保证主业务不受影响
        db_legacy.update("users", user_id, data)
    except Exception as e:
        logger.error("Failed to write to legacy DB!", error=e)
        raise  # 主业务失败，直接返回错误

    # 2. 异步：写入新服务，允许失败
    try:
        user_profile_service.update_async(user_id, data)
    except Exception as e:
        # 3. 补偿：写入失败时，将任务推入重试队列 (如 RabbitMQ, Kafka)
        logger.warning("Failed to write to new service, pushing to retry queue.", error=e)
        retry_queue.push({"user_id": user_id, "data": data})

    return "success"
```

##### **模式二：基于配置的灰度读 (实现可控的流量切换)**

```go
// 伪代码：获取用户资料
func GetUserProfile(userID int) (*Profile, error) {
    // 从配置中心（如 Viper, Apollo）读取灰度比例
    readNewServicePercentage := config.GetInt("user_profile.read_new_service_percentage")

    // 根据用户 ID 哈希值或随机数决定路由
    if userID % 100 < readNewServicePercentage {
        // 走新服务
        return profileService.GetProfile(userID)
    } else {
        // 走旧数据库
        return legacyRepo.GetProfileFromUsersTable(userID)
    }
}
```

##### **模式三：数据一致性校验脚本 (确保迁移质量)**

```python
# 伪代码：抽样对比新旧数据
def verify_data_consistency(sample_size=1000):
    user_ids = legacy_db.get_random_user_ids(sample_size)
    mismatches = []
    
    for user_id in user_ids:
        old_data = legacy_db.get_user(user_id)
        new_data = new_service.get_user(user_id)
        
        # 对比关键字段
        if old_data.name != new_data.name or old_data.email != new_data.email:
            mismatches.append(user_id)
            
    if mismatches:
        logger.error("Data mismatch found for users!", user_ids=mismatches)
    else:
        logger.info(f"Consistency check passed for {sample_size} users.")
```

---

#### **4. 生产环境重构 Checklist (行动前核对)**

-   **[ ] 目标明确**: 这次重构要解决的核心问题是什么？（性能？可维护性？）
-   **[ ] 方案已评审**: 方案是否经过团队（包括 DBA、运维）的充分评审？
-   **[ ] 步骤已分解**: 是否已将重构拆分为可独立执行和验证的小步骤？
-   **[ ] 监控已就绪**: 是否有监控来对比重构前后的性能指标（延迟、CPU、错误率）？
-   **[ ] 测试已覆盖**: 是否有自动化测试来保证重构不破坏现有业务逻辑？
-   **[ ] 回滚预案已验证**: 如果出现问题，回滚方案是否清晰？是否演练过？
-   **[ ] 沟通已同步**: 所有相关的上下游团队是否都知晓这次变更的时间窗口和潜在影响？

> **最终心法**: **真正的数据库重构，考验的不是你的 SQL 技巧，而是你设计一个“过渡态系统”并管理其复杂性的能力。** 你的目标不是一步到位，而是搭建一座安全的桥梁，让业务平稳地从旧大陆迁徙到新大陆。