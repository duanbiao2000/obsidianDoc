---
view-count: 7
update: 2026-01-09 11:17
related:
  - "[[思维模型：极简认知工具箱]]"
  - "[[思维模型：优化思考的实用工具箱]]"
  - "[[模式识别]]"
---

## 0. 本质 (The Essence)

- **核心逻辑**：机器学习 = 寻找最优拟合函数 $f(x) \approx y$。
- **演进路径**：从**基础几何**（线性/超平面）到**逻辑分支**（决策树），再到**集体智慧**（集成学习）与**层次表征**（深度学习）。
- **定位**：解决现实问题的算法工具箱，没有“最强”，只有“最适配”。

---

## 1. 核心算法矩阵

| 类别       | 核心模型            | 核心逻辑            | 典型场景          | 吐槽            |
| :------- | :-------------- | :-------------- | :------------ | :------------ |
| **经典模型** | **线性/逻辑回归**     | 直线/S曲线拟合        | 房价预测、点击率      | 简单但容易欠拟合      |
|          | **SVM**         | 最大化分类间隔         | 小样本、高维分类      | 工业界被树模型抢了风头   |
|          | **决策树**         | 属性选择与分支         | 基础决策流         | 容易过拟合（长得太深）   |
|          | **KNN**         | 邻居投票            | 推荐、异常检测       | 慢，大数据量下是灾难    |
| **集成学习** | **随机森林**        | 树的并联 (Bagging)  | 表格数据分类        | 稳如老狗，鲁棒性极高    |
|          | **XGB/LGBM**    | 树的串联 (Boosting) | 结构化数据竞赛       | 工业界表格数据的大杀手   |
| **神经网络** | **CNN**         | 局部感受野/卷积        | 图像识别、OCR      | 识别形状的“放大镜”    |
|          | **RNN/LSTM**    | 循环记忆            | 语音、老式翻译       | 处理长序列会“健忘”    |
|          | **Transformer** | 自注意力机制          | NLP、大模型 (LLM) | 现在的“版本答案”，费算力 |

---

## 2. 逻辑骨架 (Minimal Hierarchy)

### **建模三部曲**

`定义损失函数 (目标) -> 选择优化算法 (路径) -> 训练迭代 (收敛)`

### **集成逻辑**

- **Bagging (并联)**：`数据扰动 -> 独立训练 -> 结果平均` (减小方差)。
- **Boosting (串联)**：`模型迭代 -> 重点修正错误样本 -> 加权聚合` (减小偏差)。

---

## 3. 避坑指南 (Brutal Truths)

- **没有银弹 (No Free Lunch)**：不要上来就套 Transformer。表格数据上，LightGBM 往往能吊打神经网络。
- **垃圾进，垃圾出 (GIGO)**：模型再强也救不了劣质数据。特征工程的收益通常大于模型调优。
- **可解释性陷阱**：在金融/医疗领域，可解释的逻辑回归/决策树比黑盒深度学习更可靠。
- **过拟合是永远的敌人**：模型在训练集表现完美通常是灾难，一定要看测试集表现。

---

## 4. 模型选择决策树

1. **数据是图像/视频/音频？**
   - 是 → **CNN / Transformer**。
2. **数据是表格类结构化数据？**
   - 数据量小 (<1万) → **随机森林 / SVM**。
   - 数据量大 (>10万) → **XGBoost / LightGBM**。
3. **需要极高的可解释性（如合规审计）？**
   - 是 → **线性/逻辑回归 / 决策树**。
4. **数据是变长序列（文本/时间序列）？**
   - 是 → **Transformer / LSTM**。
5. **数据量极小且无训练时间？**
   - 是 → **KNN / 朴素贝叶斯**。

---

## 5. 建模审查清单 (Checklist)

- [ ] **Baseline**：我是否跑过线性回归或随机森林作为基准对比？
- [ ] **数据分布**：我处理过类别不平衡和缺失值了吗？
- [ ] **交叉验证**：我是否使用了 K-Fold 验证而不是单次测试？
- [ ] **复杂度控制**：我是否加了正则化（L1/L2）或剪枝策略？
- [ ] **性能指标**：AUC、F1-score 还是 MSE？我选对评估指标了吗？

---

**原则**：KISS (Keep It Simple, Stupid)。先用最简单的模型跑通流程，再考虑复杂的集成。
