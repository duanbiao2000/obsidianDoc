Prompt Tuning æ˜¯åœ¨å¤§æ¨¡å‹ï¼ˆå¦‚ GPTã€T5ã€BERT ç­‰ï¼‰ä¸Šè¿›è¡Œ**å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰**çš„å…³é”®æŠ€æœ¯ä¹‹ä¸€ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å†»ç»“å¤§æ¨¡å‹å‚æ•°ï¼Œä»…ä¼˜åŒ–ä¸€ä¸ªå¯å­¦ä¹ çš„â€œPrompt embeddingâ€å‘é‡ï¼Œä»¥æœ€å°ä»£ä»·é€‚é…ç‰¹å®šä»»åŠ¡æˆ–é£æ ¼ã€‚**

---

## âœ… Prompt Tuning çš„æ ¸å¿ƒåŸç†

### ğŸš§ é—®é¢˜èƒŒæ™¯

å¤§æ¨¡å‹å‚æ•°é‡åŠ¨è¾„æ•°åäº¿ï¼Œä¼ ç»Ÿå¾®è°ƒæˆæœ¬å·¨å¤§ï¼Œå°¤å…¶åœ¨å¤šä»»åŠ¡/å¤šé¢†åŸŸéƒ¨ç½²æ—¶ï¼š

- æ¯ä¸ªä»»åŠ¡éƒ½è¦å¾®è°ƒä¸€æ¬¡æ¨¡å‹ â†’ å­˜å‚¨å¼€é”€å·¨å¤§
    
- æ¨¡å‹æƒé‡é‡è®­ç»ƒæ…¢ï¼Œéƒ¨ç½²å¤æ‚
    

---

### ğŸ’¡ Prompt Tuning çš„åšæ³•

ä»¥ T5 æˆ– GPT ä¸ºä¾‹ï¼Œå®ƒä»¬æ˜¯ Encoder-Decoder æˆ– Decoder-only æ¶æ„ã€‚

æˆ‘ä»¬åšçš„ä¸æ˜¯ä¿®æ”¹åŸå§‹ promptï¼Œè€Œæ˜¯å°†ä¸€ä¸ª**å¯è®­ç»ƒçš„å‘é‡å‰ç¼€**æ’å…¥ token embedding å±‚å‰ï¼š

```text
[Prompt Embedding (trainable)] + [Input Embedding (frozen)] â†’ Model â†’ Output
```

ä»…è®­ç»ƒ Prompt Embeddingï¼ˆé€šå¸¸æ˜¯å‡ ååˆ°å‡ ç™¾ç»´ï¼Œå‡ åä¸ª tokenï¼‰ï¼Œè€Œå¤§æ¨¡å‹çš„å…¨éƒ¨å‚æ•°ä¿æŒå†»ç»“ã€‚

---

## ğŸ” å’Œ LoRA / P-Tuning v2 çš„åŒºåˆ«

| æ–¹æ³•            | ä¼˜åŒ–ç›®æ ‡                    | å‚æ•°é‡   | æ”¯æŒå¤šä»»åŠ¡  | é€‚é…çµæ´»æ€§  | æ¨ç†é€Ÿåº¦  |
| ------------- | ----------------------- | ----- | ------ | ------ | ----- |
| Prompt Tuning | Prompt embedding        | ğŸŸ¢ æå° | ğŸŸ¢ æ˜“æ‰©å±• | ğŸ”´ è¾ƒå·®  | ğŸŸ¢ å¿«é€Ÿ |
| P-Tuning v2   | Prompt embedding + deep | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¢ å¼º   | ğŸŸ¢ çµæ´»  | ğŸŸ¡ ä¸€èˆ¬ |
| LoRA          | ç‰¹å®šå±‚æƒé‡ä½ç§©é‡æ„               | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¢ å¼º   | ğŸŸ¢ æ›´å¼º  | ğŸŸ¡ ä¸€èˆ¬ |
| å…¨é‡å¾®è°ƒ          | æ‰€æœ‰å‚æ•°                    | ğŸ”´ å·¨å¤§ | ğŸ”´ å·®   | ğŸŸ¢ æœ€çµæ´» | ğŸ”´ æ…¢  |

---

## ğŸ§ª ç¤ºä¾‹ä»£ç ï¼ˆä»¥ T5 ä¸ºä¾‹ï¼‰

```python
from transformers import T5Tokenizer, T5ForConditionalGeneration
from transformers import PromptTuningConfig, PromptTuningModel

# è½½å…¥åŸºåº§æ¨¡å‹
model = T5ForConditionalGeneration.from_pretrained("t5-small")
tokenizer = T5Tokenizer.from_pretrained("t5-small")

# æ„å»º Prompt Tuning é…ç½®
prompt_config = PromptTuningConfig(
    task_type="seq2seq_lm",
    num_virtual_tokens=20,
    tokenizer_name_or_path="t5-small"
)

# åŒ…è£…æ¨¡å‹ï¼ˆå†»ç»“åŸå§‹å‚æ•°ï¼‰
prompt_model = PromptTuningModel.from_pretrained(model, prompt_config)

# Forward è¾“å…¥
input_ids = tokenizer("Translate English to French: Hello world", return_tensors="pt").input_ids
outputs = prompt_model.generate(input_ids)

print(tokenizer.decode(outputs[0]))
```

---

## ğŸ“Œ å…³é”®å‚æ•°

|å‚æ•°|å«ä¹‰|
|---|---|
|`num_virtual_tokens`|Prompt embedding ä¸­çš„ token æ•°é‡|
|`task_type`|æ¨¡å‹ä»»åŠ¡ç±»å‹ï¼ˆseq2seq, causal, etc.ï¼‰|
|`tokenizer_name_or_path`|tokenizer è·¯å¾„ï¼Œç”¨äºå¯¹é½ embedding|

---

## ğŸ”‹ ä¼˜åŠ¿

1. **å‚æ•°é«˜æ•ˆ**ï¼šå‡ åä¸ª trainable prompt tokensï¼Œå‡ åƒå‚æ•°å³å¯å®Œæˆä»»åŠ¡å¾®è°ƒ
    
2. **é€‚é…æ€§å¼º**ï¼šé€‚åˆä½èµ„æºåœºæ™¯æˆ–å¤šä»»åŠ¡éƒ¨ç½²
    
3. **æ˜“æ‰©å±•**ï¼šå¤š Prompt å¯æ’æ‹”ç»„åˆï¼ˆPrompt Compositionï¼‰
    

---

## ğŸ”¥ åº”ç”¨åœºæ™¯

- **æŒ‡ä»¤å¾®è°ƒè¡¥å……**ï¼šè®©æ¨¡å‹å¯¹ç‰¹å®š prompt æ›´æ•æ„Ÿ
    
- **é£æ ¼é€‚é…**ï¼šå¦‚åŒ»å­¦ / æ³•å¾‹é—®ç­”ã€ä¼ä¸šç‰¹å®šè¯­å¢ƒ
    
- **é¢†åŸŸè¿ç§»**ï¼šå°‘æ ·æœ¬è¯­æ–™ä»»åŠ¡
    
- **æ•™å­¦ä¼˜åŒ–**ï¼šè®­ç»ƒå¤šä¸ª prompt tokenï¼Œå¼ºåŒ–æ¨¡å‹æ€è€ƒè·¯å¾„ï¼ˆChain-of-thoughtï¼‰
    

---

## ğŸ” Prompt Tuning çš„å˜ç§

|æŠ€æœ¯å|ç‰¹ç‚¹|
|---|---|
|**Prefix Tuning**|å­¦ä¹ çš„ Prompt æ’å…¥åˆ° Transformer çš„ key/value projection ä¸­|
|**P-Tuning v2**|å¤šå±‚åµŒå…¥ï¼Œç»“åˆ LSTMï¼Œå¯æ”¯æŒå¤šä»»åŠ¡ã€é²æ£’æ€§å¼º|
|**Soft Prompt**|Prompt æ˜¯ continuous vectorï¼Œè€Œéè¯è¡¨ token|
|**Prompt Adapter**|ç±»ä¼¼äº LoRA çš„ Prompt åˆ†æ”¯ï¼Œæ”¯æŒçƒ­æ’æ‹”|

---

## ğŸš€ å·¥å…·ç”Ÿæ€æ”¯æŒ

- ğŸ¤— Transformers `PromptTuningModel`ï¼ˆä¸»æµï¼‰
    
- `peft` åŒ…æ”¯æŒ Prompt / Prefix Tuning
    
- LangChain / LangGraph å¯é€šè¿‡ prompt injection å®ç° prompt tuning æ§åˆ¶æµæŒ‚è½½
    

---

## ğŸ§© æ€»ç»“

|ä½ è¦çš„æ˜¯ä»€ä¹ˆï¼Ÿ|æ¨èæ–¹æ¡ˆ|
|---|---|
|æœ€å°è®­ç»ƒèµ„æº|Prompt Tuning âœ…|
|å¤šä»»åŠ¡æ”¯æŒ + çµæ´»|P-Tuning v2 / Adapter âœ…|
|ç²¾åº¦ + é€Ÿåº¦ +èåˆæ§åˆ¶æµ|LoRA + LangGraph âœ…|
|æ¨¡å‹è®­ç»ƒ + æ’ä»¶åŒ–|Prompt adapter + çƒ­æ’æ‹”|

---

éœ€è¦æˆ‘ä¸ºæŸä¸ªå…·ä½“åœºæ™¯ï¼ˆå¦‚ Gemini API æ¥å…¥ + Prompt Tuning ç»„åˆï¼‰æä¾›åŸå‹ä»£ç å—ï¼Ÿè¿˜æ˜¯ä½ æƒ³åœ¨ LangGraph ä¸­å®ç° prompt åŠ¨æ€åˆ‡æ¢ flowï¼Ÿæˆ‘å¯ä»¥ç›´æ¥å¸®ä½ èµ·è‰ã€‚