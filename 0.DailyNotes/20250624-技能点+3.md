## 技能点1: 事件驱动的微服务架构与分布式消息

### 前置条件
- 扎实的面向对象编程（OOP）基础
- 熟悉RESTful API设计原则与实践
- 对分布式系统（如CAP定理、网络延迟、一致性）有基本理解
- 至少掌握一种后端Web框架（如Python的FastAPI/Flask，Java的Spring Boot）

### 理论基础和技术栈
- **理论基础**:
    - 事件驱动架构（EDA）：通过发布/订阅模式实现服务解耦和异步通信。
    - CAP定理与最终一致性：理解在分布式系统中可用性、分区容错性和一致性之间的权衡。
    - Saga模式：处理分布式事务，确保跨服务的操作原子性。
    - 幂等性：设计可重复执行且不产生副作用的操作。
    - 消息队列的可靠性机制：消息持久化、确认机制、死信队列。
- **[[技术栈]]和第三方依赖库**:
    - **后端语言/框架**: Python (FastAPI), Java (Spring Boot), Go (Gin)
    - **消息中间件**: RabbitMQ, Apache Kafka, Redis Streams
    - **容器化**: Docker
    - **部署编排**: Kubernetes (K8s)
    - **监控**: Prometheus, Grafana
    - **Python库**: `pika` (RabbitMQ客户端), `confluent-kafka-python` (Kafka客户端)

### 应用场景
构建高可扩展、高可用、松耦合的复杂业务系统，例如：
- **电商订单处理**: 订单创建、支付通知、库存扣减、物流发货等通过消息异步驱动。
- **实时数据管道**: 收集、处理和分发来自不同源的数据流。
- **物联网（IoT）**: 大规模设备数据采集和事件响应。
- **异步任务处理**: 如图片处理、邮件发送、报表生成等耗时操作。

### 代码实例
以下是一个使用Python FastAPI和RabbitMQ实现事件驱动订单处理的简化示例。
**order_service.py (订单服务)**
```python
import pika
import json
import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uuid

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

# RabbitMQ配置
RABBITMQ_HOST = 'localhost' # 在生产环境应使用服务发现或配置管理
ORDER_QUEUE = 'order_created_events'

class Order(BaseModel):
    items: list[str]
    total_amount: float
    user_id: int

def publish_order_event(order_data: dict):
    """发布订单创建事件到RabbitMQ"""
    try:
        connection = pika.BlockingConnection(pika.ConnectionParameters(host=RABBITMQ_HOST))
        channel = connection.channel()
        channel.queue_declare(queue=ORDER_QUEUE, durable=True) # durable=True 确保队列持久化
        
        message = json.dumps(order_data)
        channel.basic_publish(
            exchange='',
            routing_key=ORDER_QUEUE,
            body=message,
            properties=pika.BasicProperties(
                delivery_mode=pika.spec.PERSISTENT_DELIVERY_MODE # 消息持久化
            )
        )
        logger.info(f"Published order event: {message}")
        connection.close()
    except pika.exceptions.AMQPConnectionError as e:
        logger.error(f"Failed to connect to RabbitMQ: {e}")
        raise HTTPException(status_code=500, detail="Failed to connect to message broker")
    except Exception as e:
        logger.error(f"Error publishing message: {e}")
        raise HTTPException(status_code=500, detail="Failed to publish order event")

@app.post("/orders/")
async def create_order(order: Order):
    """创建订单并发布事件"""
    order_id = str(uuid.uuid4())
    order_data = order.dict()
    order_data["order_id"] = order_id
    order_data["status"] = "pending"
    
    logger.info(f"Creating order: {order_data}")
    # 模拟订单存储到数据库
    # db.save_order(order_data) 
    
    publish_order_event(order_data)
    
    return {"message": "Order created successfully, processing in background.", "order_id": order_id}

# 测试用例 (通常会放在独立的测试文件中，例如 test_order_service.py)
# 启动 RabbitMQ: docker run -d --hostname my-rabbit --name some-rabbit -p 5672:5672 -p 15672:15672 rabbitmq:3-management
# 启动 Order Service: uvicorn order_service:app --reload --port 8000
# 使用以下命令测试:
# curl -X POST -H "Content-Type: application/json" -d '{"items": ["itemA", "itemB"], "total_amount": 100.0, "user_id": 123}' http://localhost:8000/orders/
```

**inventory_service.py (库存服务 - 消费者)**
```python
import pika
import json
import logging
import time

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# RabbitMQ配置
RABBITMQ_HOST = 'localhost'
ORDER_QUEUE = 'order_created_events'

def process_order_event(ch, method, properties, body):
    """处理订单创建事件，模拟库存扣减"""
    order_data = json.loads(body)
    order_id = order_data.get("order_id")
    items = order_data.get("items")
    user_id = order_data.get("user_id")

    logger.info(f"Inventory Service received order {order_id} for user {user_id} with items: {items}")
    
    try:
        # 模拟库存扣减逻辑
        logger.info(f"Simulating inventory deduction for order {order_id}...")
        time.sleep(2) # 模拟耗时操作
        
        # 在生产环境中，这里会更新数据库中的库存记录
        # db.deduct_inventory(items)
        logger.info(f"Inventory for order {order_id} deducted successfully.")
        
        # 确认消息已被处理
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        logger.error(f"Failed to process order {order_id}: {e}. Nack and re-queue.", exc_info=True)
        # 拒绝消息并将其重新放入队列 (或发送到死信队列)
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True) 

def start_consuming():
    """启动RabbitMQ消费者"""
    while True:
        try:
            connection = pika.BlockingConnection(pika.ConnectionParameters(host=RABBITMQ_HOST))
            channel = connection.channel()
            channel.queue_declare(queue=ORDER_QUEUE, durable=True)
            logger.info('Inventory Service started. Waiting for messages. To exit press CTRL+C')

            # 每次只预取一条消息，处理完再取下一条，避免消费者过载
            channel.basic_qos(prefetch_count=1) 
            channel.basic_consume(queue=ORDER_QUEUE, on_message_callback=process_order_event)
            channel.start_consuming()
        except pika.exceptions.AMQPConnectionError as e:
            logger.error(f"Failed to connect to RabbitMQ, retrying in 5 seconds: {e}")
            time.sleep(5)
        except KeyboardInterrupt:
            logger.info("Exiting Inventory Service.")
            if 'connection' in locals() and connection.is_open:
                connection.close()
            break
        except Exception as e:
            logger.error(f"An unexpected error occurred in consumer loop: {e}", exc_info=True)
            time.sleep(5) # 避免错误发生时CPU空转

if __name__ == '__main__':
    start_consuming()

# 测试用例 (通常会放在独立的测试文件中)
# 1. 确保 RabbitMQ 服务器运行。
# 2. 运行 inventory_service.py: python inventory_service.py
# 3. 在另一个终端运行 order_service.py: uvicorn order_service:app --reload --port 8000
# 4. 发送 POST 请求到 order_service:
#    curl -X POST -H "Content-Type: application/json" -d '{"items": ["laptop", "mouse"], "total_amount": 1200.0, "user_id": 456}' http://localhost:8000/orders/
# 5. 观察 inventory_service 的日志输出，确认消息被正确消费。
# 6. 可以尝试多次发送请求，观察并发处理效果。
# 7. 模拟 RabbitMQ 断开连接，观察消费者重连机制。
```

## 技能点2: MLOps实践：生产级AI模型部署与管理

### 前置条件
- 熟悉机器学习（ML）模型开发生命周期（数据预处理、模型训练、评估）
- 掌握至少一种ML框架（如TensorFlow、PyTorch、Scikit-learn）
- 了解DevOps基本理念和CI/CD（持续集成/持续交付）概念
- 熟悉Docker容器化技术

### 理论基础和技术栈
- **理论基础**:
    - MLOps（Machine Learning Operations）：将DevOps原则应用于机器学习，旨在自动化和简化ML模型从开发到生产部署、监控和维护的全过程。
    - 模型版本控制与回溯：管理模型的不同迭代，确保可复现性。
    - 数据漂移与模型漂移检测：在生产环境中识别输入数据或模型性能的变化。
    - A/B测试与Canary发布：逐步发布新模型并评估其在真实世界中的表现。
    - 特征存储（Feature Store）：管理和共享特征，确保训练/ serving一致性。
- **[[技术栈]]和第三方依赖库**:
    - **ML框架**: TensorFlow, PyTorch, Scikit-learn
    - **模型服务**: FastAPI/Flask (自定义API), TensorFlow Serving, TorchServe, BentoML, Triton Inference Server
    - **容器化**: Docker
    - **编排**: Kubernetes (K8s), Docker Compose (开发环境)
    - **CI/CD**: GitHub Actions, GitLab CI/CD, Jenkins, DVC (Data Version Control)
    - **ML平台/工具**: MLflow (模型注册、实验跟踪), Kubeflow, Airflow (工作流编排)
    - **监控**: Prometheus, Grafana, custom model performance metrics

### 应用场景
将训练好的机器学习模型投入生产环境，并对其进行持续管理，例如：
- **实时推荐系统**: 为用户提供个性化商品或内容推荐。
- **欺诈检测**: 在交易发生时实时判断是否存在欺诈行为。
- **自然语言处理（NLP）API**: 如情感分析、文本分类、机器翻译服务。
- **计算机视觉应用**: 如图像识别、目标检测服务。
- **预测性维护**: 预测设备故障并安排维护。

### 代码实例
以下是一个使用FastAPI部署Scikit-learn模型的简化示例，并包含Docker配置。
**model_serving_app.py (模型服务应用)**
```python
from fastapi import FastAPI
from pydantic import BaseModel
import joblib
import os
import logging
from typing import List

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

# 假设模型文件在应用启动时位于 /app/models/ 下
MODEL_PATH = "models/iris_classifier.joblib" # 生产环境中应从配置服务或模型注册中心获取

class PredictRequest(BaseModel):
    features: List[float]

class PredictResponse(BaseModel):
    prediction: int
    class_name: str

model = None
class_names = ['setosa', 'versicolor', 'virginica'] # Iris数据集类别名

@app.on_event("startup")
async def load_model():
    """在应用启动时加载模型"""
    global model
    if not os.path.exists(MODEL_PATH):
        logger.error(f"Model file not found at {MODEL_PATH}")
        raise FileNotFoundError(f"Model file not found: {MODEL_PATH}")
    
    try:
        model = joblib.load(MODEL_PATH)
        logger.info(f"Model loaded successfully from {MODEL_PATH}")
    except Exception as e:
        logger.error(f"Error loading model from {MODEL_PATH}: {e}")
        raise RuntimeError(f"Failed to load model: {e}")

@app.get("/health")
async def health_check():
    """健康检查端点"""
    if model is not None:
        return {"status": "ok", "model_loaded": True}
    return {"status": "loading", "model_loaded": False}

@app.post("/predict", response_model=PredictResponse)
async def predict(request: PredictRequest):
    """接收特征并返回模型预测结果"""
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded yet.")
    
    try:
        # 模型期望输入是二维数组，即使只有一个样本
        features_array = [request.features] 
        prediction = model.predict(features_array)[0]
        predicted_class_name = class_names[prediction]
        logger.info(f"Received features: {request.features}, Predicted: {predicted_class_name}")
        return PredictResponse(prediction=int(prediction), class_name=predicted_class_name)
    except Exception as e:
        logger.error(f"Error during prediction: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Prediction error: {e}")

# 生产级考虑：
# 1. 模型训练与保存: 
#    from sklearn.datasets import load_iris
#    from sklearn.ensemble import RandomForestClassifier
#    from sklearn.model_selection import train_test_split
#    import joblib
#    
#    iris = load_iris()
#    X, y = iris.data, iris.target
#    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#    model = RandomForestClassifier(random_state=42)
#    model.fit(X_train, y_train)
#    
#    os.makedirs('models', exist_ok=True)
#    joblib.dump(model, MODEL_PATH)
#    print(f"Model saved to {MODEL_PATH}")
#
# 2. Dockerfile:
#    FROM python:3.9-slim-buster
#    WORKDIR /app
#    COPY requirements.txt .
#    RUN pip install --no-cache-dir -r requirements.txt
#    COPY . .
#    # 将模型文件从构建上下文复制到容器内指定路径
#    COPY models/iris_classifier.joblib /app/models/
#    CMD ["uvicorn", "model_serving_app:app", "--host", "0.0.0.0", "--port", "80"]
#
# 3. requirements.txt:
#    fastapi
#    uvicorn[standard]
#    scikit-learn
#    joblib
#
# 4. 部署与测试:
#    a. 确保已训练并保存模型到 ./models/iris_classifier.joblib
#    b. 构建Docker镜像: docker build -t iris-classifier .
#    c. 运行容器: docker run -d -p 8001:80 iris-classifier
#    d. 测试API:
#       curl -X POST -H "Content-Type: application/json" -d '{"features": [5.1, 3.5, 1.4, 0.2]}' http://localhost:8001/predict
#       curl http://localhost:8001/health
```

## 技能点3: 高性能异步编程与并发控制

### 前置条件
- 扎实的编程语言基础（如Python）
- 理解进程、线程、协程的基本概念及区别
- 对I/O密集型和CPU密集型任务有清晰认知
- 熟悉网络编程基础（TCP/IP、HTTP请求）

### 理论基础和技术栈
- **理论基础**:
    - 异步I/O模型：事件循环（Event Loop）、回调（Callbacks）、Future/Promise、协程（Coroutines）。
    - 并发与并行：并发指任务交错执行，并行指任务同时执行。
    - 全局解释器锁（GIL）：理解其对Python多线程并行计算的限制及应对策略。
    - 临界区与同步原语：锁（Lock）、信号量（Semaphore）、条件变量（Condition Variable）、队列（Queue）等用于管理共享资源和避免竞争条件。
    - 调度策略：理解操作系统和语言运行时如何调度并发任务。
- **[[技术栈]]和第三方依赖库**:
    - **Python**: `asyncio` (核心异步I/O库), `aiohttp` (异步HTTP客户端/服务器), `uvloop` (替代`asyncio`默认事件循环，提升性能), `concurrent.futures` (线程池/进程池)
    - **Go**: `goroutines`, `channels`
    - **Node.js**: `EventEmitter`, `Promise`, `async/await`
    - **Java**: `java.nio` (NIO), `CompletableFuture`, `ExecutorService`
    - **C++**: `Boost.Asio`, C++11/14/17 `std::async`, `std::thread`

### 应用场景
构建高吞吐量、低延迟的应用程序，特别适用于I/O密集型任务：
- **高并发Web服务器**: 处理大量并发用户请求。
- **实时数据流处理**: 从多个源异步读取和写入数据。
- **网络爬虫**: 并发抓取大量网页数据。
- **RPC服务与微服务间通信**: 提高服务间调用的效率。
- **游戏服务器**: 实时处理玩家操作和状态同步。
- **高频交易系统**: 快速处理市场数据和执行交易。

### 代码实例
以下是一个使用Python `asyncio`和`aiohttp`并发请求多个API的例子。
**async_http_client.py (异步HTTP客户端)**
```python
import asyncio
import aiohttp
import time
import logging
from typing import List, Dict, Any

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def fetch_url(session: aiohttp.ClientSession, url: str) -> Dict[str, Any]:
    """
    异步地从给定URL获取数据。
    """
    start_time = time.time()
    try:
        async with session.get(url, timeout=10) as response:
            response.raise_for_status() # 对HTTP错误（4xx或5xx）抛出异常
            data = await response.json()
            end_time = time.time()
            logger.info(f"Successfully fetched {url} in {end_time - start_time:.2f}s")
            return {"url": url, "status": response.status, "data": data}
    except aiohttp.ClientError as e:
        end_time = time.time()
        logger.error(f"Error fetching {url}: {e} in {end_time - start_time:.2f}s")
        return {"url": url, "status": "error", "error": str(e)}
    except asyncio.TimeoutError:
        end_time = time.time()
        logger.error(f"Timeout fetching {url} in {end_time - start_time:.2f}s")
        return {"url": url, "status": "timeout", "error": "Request timed out"}
    except Exception as e:
        end_time = time.time()
        logger.error(f"An unexpected error occurred for {url}: {e} in {end_time - start_time:.2f}s", exc_info=True)
        return {"url": url, "status": "error", "error": f"Unexpected error: {e}"}

async def fetch_all_urls_concurrently(urls: List[str]) -> List[Dict[str, Any]]:
    """
    使用aiohttp的ClientSession并发地获取所有URL的数据。
    """
    results = []
    # aiohttp.ClientSession 应该只创建一次并在所有请求中复用
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        # asyncio.gather 收集所有任务的结果，保持顺序
        # return_exceptions=True 确保即使某个任务失败，其他任务也能继续并返回各自结果
        results = await asyncio.gather(*tasks, return_exceptions=True) 
    return results

async def main():
    """主函数，演示并发请求"""
    # 示例URL，可以替换为实际API
    # 建议使用 https://jsonplaceholder.typicode.com/posts/1 等测试
    test_urls = [
        "https://jsonplaceholder.typicode.com/posts/1",
        "https://jsonplaceholder.typicode.com/users/2",
        "https://jsonplaceholder.typicode.com/comments/3",
        "https://jsonplaceholder.typicode.com/todos/4",
        "https://jsonplaceholder.typicode.com/albums/5",
        "http://httpbin.org/delay/3" # 模拟一个耗时3秒的请求
    ]
    
    logger.info(f"Starting concurrent fetching of {len(test_urls)} URLs...")
    start_total_time = time.time()
    
    results = await fetch_all_urls_concurrently(test_urls)
    
    end_total_time = time.time()
    logger.info(f"All URLs fetched in {end_total_time - start_total_time:.2f}s")
    
    for res in results:
        if isinstance(res, Exception): # 处理 return_exceptions=True 捕获的异常
            logger.error(f"Task failed with exception: {res}")
        else:
            logger.info(f"Result for {res['url']}: Status={res.get('status', 'N/A')}, Data snippet={str(res.get('data', res.get('error', '')))[0:50]}...")

if __name__ == "__main__":
    # 启动事件循环并运行主协程
    # 在生产环境中，可以集成到Web框架（如FastAPI/Sanic）中，它们会管理事件循环
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Program interrupted by user.")

# 测试用例 (在命令行中直接运行)
# 1. 确保安装了 `aiohttp`: pip install aiohttp
# 2. 运行脚本: python async_http_client.py
# 3. 观察日志输出，特别是总耗时。如果是非异步（同步）请求，总耗时会接近所有单个请求耗时之和。
#    由于并发，总耗时将接近最长单个请求的耗时（加上少量调度开销）。
# 4. 尝试添加一个无效URL (e.g., "http://invalid-domain-xyz.com") 或一个会返回500的URL来测试错误处理。
# 5. 观察`httpbin.org/delay/3`这个模拟耗时请求如何与其他请求并行执行，而不是阻塞。
```