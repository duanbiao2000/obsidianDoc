
```python
# LangGraph Flow Prototype: ç»“æ„åŒ–ç¬”è®° AI Agentï¼ˆå«çŠ¶æ€è®°å¿†ã€å›¾è°±å¯¼å‡ºã€AgentLoopï¼‰

from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from collections import defaultdict
import networkx as nx
import matplotlib.pyplot as plt
import json
import os

# ------ ENV é…ç½® ------
os.environ["GOOGLE_API_KEY"] = "your_gemini_api_key_here"
llm = ChatGoogleGenerativeAI(model="gemini-pro")
embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = FAISS.from_documents([Document(page_content="init")], embedding_model)
retriever = vectorstore.as_retriever()

# ------ çŠ¶æ€å›¾è®°å¿†å®¹å™¨ ------
memory_state = defaultdict(list)

# ------ Prompts ------
parse_prompt = ChatPromptTemplate.from_template(
    """
ç¬”è®°å†…å®¹å¦‚ä¸‹ï¼š"{note}"
è¯·æŠ½å–å…¶ä¸­çš„æ ¸å¿ƒæ¦‚å¿µã€å…³ç³»å¯¹ã€ç›¸å…³ä¸»é¢˜ï¼Œè¾“å‡ºï¼š
- æ¦‚å¿µæ¸…å•
- ä¸‰å…ƒç»„åˆ—è¡¨ï¼ˆå¦‚ï¼šA, å…³ç³», Bï¼‰
- æ¨èçŸ¥è¯†å›¾è°±èŠ‚ç‚¹
"""
)

reflect_prompt = ChatPromptTemplate.from_template(
    """
å›¾è°±ä¸Šä¸‹æ–‡å¦‚ä¸‹ï¼š"{context}"
æ–°ç¬”è®°ï¼š"{note}"
è¯·åˆ¤æ–­ï¼š
- æ˜¯å¦å­˜åœ¨é‡å¤æˆ–å†²çªï¼Ÿ
- æ˜¯å¦å‡ºç°æ–°è¿æ¥æˆ–ç†è§£é“¾ï¼Ÿ
- æ¨èçš„å›¾è°±æ›´æ–°æ–¹å¼
"""
)

summarize_prompt = ChatPromptTemplate.from_template(
    "æ€»ç»“å½“å‰çŸ¥è¯†å›¾è°±çš„ä¸»è¦ä¸»é¢˜å’Œç»“æ„ã€‚"
)

next_task_prompt = ChatPromptTemplate.from_template(
    "åŸºäºå½“å‰å›¾è°±å†…å®¹ï¼Œæ€»ç»“ä¸‹ä¸€ä¸ªå€¼å¾—æ·±å…¥çš„é—®é¢˜æˆ–å»¶å±•ç¬”è®°ä¸»é¢˜ï¼š\n{reflection}"
)

# ------ Runnable Chains ------
parse_chain = parse_prompt | llm | StrOutputParser()
reflect_chain = reflect_prompt | llm | StrOutputParser()
summarize_chain = summarize_prompt | llm | StrOutputParser()
next_task_chain = next_task_prompt | llm | StrOutputParser()

# ------ çŸ¥è¯†å›¾è°±å¯è§†åŒ– ------
def update_graph(triples, output_file="kg_graph.png"):
    G = nx.DiGraph()
    for t in triples:
        if len(t) == 3:
            G.add_edge(t[0], t[2], label=t[1])
    plt.figure(figsize=(10, 6))
    pos = nx.spring_layout(G)
    nx.draw(G, pos, with_labels=True, node_color="skyblue", edge_color="gray", node_size=2000, font_size=12)
    edge_labels = nx.get_edge_attributes(G, 'label')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
    plt.title("çŸ¥è¯†å›¾è°±ç»“æ„å›¾")
    plt.savefig(output_file)
    plt.close()

# ------ Node Functions ------
def ingest_note(state):
    note = state["note"]
    vectorstore.add_documents([Document(page_content=note)])
    memory_state["notes"].append(note)
    return {"note": note}

def parse_knowledge(state):
    parsed = parse_chain.invoke({"note": state["note"]})
    memory_state["parsed"].append(parsed)
    try:
        triples = []
        for line in parsed.split("\n"):
            if line.strip().startswith("(") and "," in line:
                t = line.strip("() ").split(",")
                triples.append(tuple(x.strip() for x in t))
        memory_state["triples"].extend(triples)
        update_graph(memory_state["triples"], output_file="knowledge_graph.png")
    except Exception as e:
        print("[Parse Error]", e)
    return {"parsed": parsed}

def reflect_and_update(state):
    docs = retriever.get_relevant_documents(state["note"])
    context = "\n".join([d.page_content for d in docs])
    reflection = reflect_chain.invoke({"note": state["note"], "context": context})
    memory_state["reflections"].append(reflection)
    return {"reflection": reflection}

def summarize_graph(state):
    summary = summarize_chain.invoke({})
    memory_state["summary"] = summary
    return {"summary": summary}

def suggest_next_task(state):
    reflection = state.get("reflection", "")
    task = next_task_chain.invoke({"reflection": reflection})
    memory_state["next_tasks"].append(task)
    return {"note": task}  # å¾ªç¯æ³¨å…¥åˆ°ä¸‹æ¬¡è¿è¡Œ

# ------ LangGraph æµç¨‹å›¾æ„å»º ------
graph_builder = StateGraph()

graph_builder.add_node("ingest_note", RunnableLambda(ingest_note))
graph_builder.add_node("parse_knowledge", RunnableLambda(parse_knowledge))
graph_builder.add_node("reflect_update", RunnableLambda(reflect_and_update))
graph_builder.add_node("summarize", RunnableLambda(summarize_graph))
graph_builder.add_node("next_task", RunnableLambda(suggest_next_task))

# æ§åˆ¶è¾¹ï¼ˆAgentLoopï¼‰

def loop_or_end(state):
    if len(memory_state["next_tasks"]) > 2:
        return "end"
    return "ingest_note"

graph_builder.set_entry_point("ingest_note")

graph_builder.add_edge("ingest_note", "parse_knowledge")
graph_builder.add_edge("parse_knowledge", "reflect_update")
graph_builder.add_edge("reflect_update", "summarize")
graph_builder.add_edge("summarize", "next_task")
graph_builder.add_conditional_edges("next_task", loop_or_end, {"ingest_note": "ingest_note", "end": END})

agent_graph = graph_builder.compile()

# ------ è¿è¡Œç¤ºä¾‹ ------
if __name__ == "__main__":
    first_note = "Transformer æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶å¯ç¤ºæˆ‘æ„å»ºæŸ¥è¯¢-åŒ¹é…å›¾è°±ç»“æ„ã€‚"
    final = agent_graph.invoke({"note": first_note})
    print("\nğŸ“Œ [çŸ¥è¯†æŠ½å–]", final.get("parsed"))
    print("\nğŸ” [åæ€æ›´æ–°]", final.get("reflection"))
    print("\nğŸ§  [å›¾è°±æ€»ç»“]", final.get("summary"))
    print("\nğŸ§­ [æ–°é—®é¢˜ç”Ÿæˆ]", final.get("note"))

    with open("memory_state.json", "w", encoding="utf-8") as f:
        json.dump(dict(memory_state), f, indent=2, ensure_ascii=False)
        print("\nğŸ“ çŠ¶æ€å·²ä¿å­˜è‡³ memory_state.jsonï¼Œå›¾è°±è¾“å‡ºè‡³ knowledge_graph.png")

```

âœ… å·²ç”Ÿæˆå®Œæ•´å®ç°ç‰ˆæœ¬ï¼š

è¿™å¥—ä»£ç æ˜¯ä¸€ä¸ªå…·å¤‡å¦‚ä¸‹æ ¸å¿ƒåŠŸèƒ½çš„æ™ºèƒ½ç¬”è®°ç³»ç»ŸåŸå‹ï¼š

- **ğŸ“Œ çŠ¶æ€è®°å¿†**ï¼š`memory_state` è´¯ç©¿æ•´ä¸ª Agent æµï¼›
    
- **ğŸ§  å›¾è°±å¯¼å‡º**ï¼šè‡ªåŠ¨æŠ½å–ä¸‰å…ƒç»„å¹¶ç”Ÿæˆ `.png` å›¾ï¼›
    
- **ğŸ” Agent å¾ªç¯**ï¼šæ€»ç»“-åæ€-æé—®è‡ªåŠ¨é—­ç¯æ‰§è¡Œï¼›
    
- **ğŸ’¾ æœ¬åœ°ä¿å­˜**ï¼šè¾“å‡º `memory_state.json` ä¸å›¾è°±æ–‡ä»¶ï¼›
    
- **ğŸ”— æ¨¡å—ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨ `LangGraph + Runnable + EL + Memory` æ„å»ºæ ‡å‡†åŒ– Flowã€‚
    

ä½ å¯ä»¥è¿è¡Œå®ƒæ¥æ•´ç†ä¸€æ‰¹ç¬”è®°æ–‡ä»¶ï¼Œå®ç°ä¸ªäººçŸ¥è¯†çš„ç»“æ„åŒ–ä¸æ¼”åŒ–ã€‚

ğŸ“å»ºè®®ä¸‹ä¸€æ­¥ï¼š

- åŠ å…¥æœ¬åœ°ç¬”è®°æºï¼ˆå¦‚ Obsidian Syncï¼‰ï¼›
    
- å¢å¼ºæé—®ç”Ÿæˆç­–ç•¥ï¼ˆå¼•å…¥å…ƒè®¤çŸ¥æç¤ºè¯ï¼‰ï¼›
    
- å¼•å…¥ Markdown æ€»ç»“è¾“å‡ºå’Œé•¿æœŸå›¾è°±å½’æ¡£ã€‚
    

éœ€è¦æˆ‘å¸®ä½ é…ä¸€ä¸ªæ›´å¼ºçš„æç¤ºè¯åº“æˆ–è€…å¯è§†åŒ–å·¥å…·é“¾ä¹Ÿå¯ä»¥æã€‚ç»§ç»­æ·±å…¥ï¼Ÿ