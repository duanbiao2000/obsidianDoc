[[元提示词]]（Meta Prompt）是一种高级的[[提示词工程]]方法论，其核心在于超越单一任务的[[指令]]编写，通过[[结构化]]、[[自动化]]和[[抽象化]]的手段，更高效地引导[[大语言模型]]（LLMs）执行复杂任务。它不是直接告诉LLM“做什么”，而是告诉LLM“如何思考”、“如何理解任务”以及“如何生成满足特定标准的结果”。

**[[元提示词]]的核心理念与价值：**

1.  **抽象与模式化：** [[元提示词]]将人类在设计[[提示词]]时的[[思维过程]]进行[[抽象化]]和模式化。它将通用的任务模式（如角色扮演、逐步推理、格式化输出）固化为可复用的[[提示词]]结构，减少重复劳动，提高[[提示词]]的质量和一致性。
2.  **引导模型行为：** 不仅仅是提供输入，[[元提示词]]更侧重于影响LLM的内部[[推理过程]]。例如，通过注入[[思维链]]（Chain-of-Thought, CoT）或要求LLM进行[[多步骤推理]]，促使模型执行更深层次的[[逻辑思考]]，从而提升复杂问题解决能力。
3.  **[[任务拆解]]与[[代理模式]]：** [[元提示词]]可以用于指导LLM进行[[任务拆解]]，将一个大问题分解为多个子问题，并为每个子问题生成相应的子[[提示词]]。这种设计是构建[[Agentic LLM]]（智能[[代理]]）的基础，使得LLM能够像一个有规划、有执行力的[[智能体]]一样工作，甚至能调用外部工具或进行[[多轮对话]]。
4.  **动态与自适应：** 结合[[RAG]]（Retrieval-Augmented Generation）等技术，[[元提示词]]可以实现动态生成和自适应。这意味着[[元提示词]]能够根据实时的上下文信息、外部知识或用户反馈进行调整，使其更具灵活性和[[上下文感知]]能力。
5.  **提升[[提示词工程]]效率与可维护性：** 通过[[自动化]]生成和[[模块化]]管理，[[元提示词]]大大提升了[[提示词工程]]的效率。当模型更新或任务需求变化时，只需调整[[元提示词]]中的核心策略或模块，而无需重新编写所有[[提示词]]，从而提高了可维护性。

总而言之，[[元提示词]]是将人类的[[智能]]与[[大语言模型]]的能力深度融合的产物，它将[[提示词工程]]从一次性的艺术创作，推向了可系统化、[[可扩展]]的[[工程实践]]。


---
![[元提示词范例]]