{
	"nodes":[
		{"id":"c3450558e7055b6d","x":-300,"y":-320,"width":540,"height":580,"type":"text","text":"BM25，全称是 **Best Matching 25**，是信息检索领域最经典的排序函数之一，用于根据查询词对文档进行相关性评分。\n\n它是 Okapi BM 系列的进化版，被广泛用于搜索引擎、问答系统、推荐系统里的候选排序，比如：\n\n- Elasticsearch / Lucene 的默认打分模型\n- GPT 类检索增强（RAG）的向量 + BM25 混合检索方案\n- StackOverflow、知乎搜索背后的文本相关性打分\n\n---\n\n## 🧠 BM25核心公式\n\n对于查询 \\( Q = \\{q_1, q_2, ..., q_n\\} \\) 和文档 \\( D \\)，BM25 的打分公式如下：\n\n\\[\n\\text{score}(D, Q) = \\sum_{i=1}^{n} \\text{IDF}(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})}\n\\]\n\n---\n\n## ✍️ 参数解释\n\n| 符号              | 含义 |\n|-------------------|------|\n| \\( f(q_i, D) \\)   | 词 \\( q_i \\) 在文档 \\( D \\) 中出现的次数（term freq） |\n| \\( |D| \\)         | 文档长度（总词数） |\n| \\( \\text{avgdl} \\) | 语料中所有文档的平均长度 |\n| \\( k_1 \\)         | 控制 TF 饱和度，常取 1.2～2.0 |\n| \\( b \\)           | 控制文档长度归一，0 表示不考虑长度，1 表示完全考虑 |\n| \\( \\text{IDF}(q_i) \\) | 逆文档频率（常平滑处理） |\n\n其中：\n\n\\[\n\\text{IDF}(q_i) = \\log \\left( \\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5} + 1 \\right)\n\\]\n\n- \\( N \\)：总文档数\n- \\( n(q_i) \\)：包含词 \\( q_i \\) 的文档数\n\n---\n\n## 🔍 和 TF-IDF 的关键区别\n\n| 特性           | TF-IDF             | BM25                                |\n|----------------|--------------------|-------------------------------------|\n| TF 处理        | 线性累计           | **非线性饱和**，防止词频过高失真   |\n| 文档长度归一化 | 无                 | ✅ 使用 \\( b \\cdot |D|/\\text{avgdl} \\) |\n| 实用效果       | 理论好，实际有限   | 搜索引擎实际效果更好               |\n| 可调参数       | 无                 | \\( k_1, b \\) 可调，适配不同数据集   |\n\n---\n\n## 🧠 为啥 BM25 是“工业界搜索默认选项”？\n\n- 兼顾 **精度与可解释性**\n- 效果好：常作为 **RAG 检索 baseline**\n- 无需训练，纯基于统计，**可冷启动**\n- 简单快速，Lucene / Elasticsearch 内建\n- 和 TF-IDF 比，**更鲁棒于长文档/高频词**\n\n---\n\n## 🛠 典型应用场景\n\n| 场景                           | BM25 表现 |\n|--------------------------------|-----------|\n| 文本检索（搜索引擎）           | ✅ 主力 |\n| FAQ / 知识库匹配                | ✅ |\n| 语义检索（结合向量）            | ⚠️ 通常混合使用 |\n| 推荐召回                        | 可用于 item-title、description 匹配 |\n| RAG 检索（embedding + BM25）   | ✅ 热门组合 |\n\n---\n\n## 🚀 Bonus：向量 + BM25 混合方案\n\n现代信息检索一般采用：\n\n- 语义向量召回（Dense embedding）\n- + BM25（Sparse）\n- → **融合排序（Hybrid Retrieval）**\n\n比如：\n```python\nscore = α · cosine(embedding) + (1 - α) · BM25_score\n```\n\n适用于冷启动语义、FAQ 多样性、召回补全。\n\n---\n\n## 🔧 代码实现（Python 简版）\n\n```python\nfrom rank_bm25 import BM25Okapi\n\ncorpus = [\n    \"the quick brown fox jumps over the lazy dog\",\n    \"never jump over the lazy dog quickly\",\n    \"the fox is quick and brown\",\n]\n\ntokenized_corpus = [doc.split() for doc in corpus]\nbm25 = BM25Okapi(tokenized_corpus)\n\nquery = \"quick fox\".split()\nscores = bm25.get_scores(query)\n```\n\n---\n\n## 🧠 总结一句话\n\n> BM25 是经典但强大的词频-倒排文档打分函数，对搜索质量提升巨大，尤其适合冷启动检索、FAQ 匹配、信息检索 baseline，在现代 RAG 系统中仍是不可忽视的对照项。\n\n---\n\n要不要我画个 BM25 和 TF-IDF 的公式对比图？或者帮你搭建一个 BM25 + 向量的混合检索原型？"},
		{"id":"01b97e81720ed6fb","x":-300,"y":280,"width":400,"height":289,"type":"file","file":"5.Misc/Attachments/Pasted image 20250416233234.png"}
	],
	"edges":[]
}