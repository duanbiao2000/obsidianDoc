---
view-count: 3
update: 2026-01-03 23:46
---

# AI时代TDD (2025)

## 范式转变

```
传统: 人写测试 → 人写代码 → 人重构
AI增强: 人写测试 → AI写代码 → AI重构(人审)
2025: 人写规格 → AI写测试+代码 → 人验证意图
```

测试验证AI + 约束AI + 传达意图

---

## 角色矩阵

| 环节   | 传统TDD  | 2025实践        |
| ---- | ------ | ------------- |
| 意图定义 | 隐含在测试中 | Spec文件明确      |
| 测试编写 | 人类手写   | 人写关键+AI补边界    |
| 代码实现 | 人类手写   | AI生成→测试验证→人审  |
| 重构   | 人类主导   | AI执行→测试守护→人批准 |
| 审查   | 代码审查   | 审查测试意图理解      |

---

## 工作流

```
SPEC (人类核心)
  自然语言描述期望 + 边界条件 + 验收标准
  ↓
TEST (人机协作)
  AI生成用例 ← 人审查意图 + 人补充边界
  ↓
GENERATE (AI主导)
  AI生成实现 → 测试验证 → 失败则迭代
  ↓
VERIFY (人类把关)
  可读性 + 意图覆盖 + 边缘情况
```

---

## 测试三层职责

```
Layer 3: 约束AI行为边界
         防止危险代码 + 明确"不应该"

Layer 2: 验证功能正确性
         输入输出 + 边界条件

Layer 1: 传达人类意图
         测试即规格 + AI理解需求
```

测试质量决定AI生成质量\
写好测试 > 写好prompt

---

## Eval-Driven Development

| 对比   | 传统TDD           | AI系统EDD       |
| ---- | --------------- | ------------- |
| 验证对象 | 确定性代码           | 概率性输出         |
| 断言   | `assert x == y` | `score > 0.8` |
| 数据   | 固定用例            | 多样化样本集        |
| 标准   | 100%通过          | 统计显著性         |
| 回归   | 精确匹配            | 分布漂移检测        |

```python
# 传统
def test_add():
    assert add(1,2) == 3

# AI系统
def eval_summary():
    results = [judge(summary(doc)) for doc in test_set]
    assert mean(results) > 0.85
    assert min(results) > 0.5
```

---

## Agent测试策略

```
传统函数: input → output
Agent: input → [思考→工具→思考]→ output
              ↑ 过程不确定
```

**策略**

- 行为边界 → 不应该做什么
- 工具调用 → 调用正确工具
- 最终结果 → 目标达成
- 测试目标达成 > 测试路径

```python
def test_agent():
    result = agent.run("订明天去上海机票")
    
    # 最终状态
    assert result.booking_confirmed
    assert result.destination == "上海"
    
    # 安全边界
    assert "delete" not in result.tool_calls
    assert result.total_cost < user.budget_limit
```

---

## 测试金字塔

```
传统         2025
/E2E\       /Eval\      AI输出评估
/集成\       /Agent\     行为边界
/单元\       /单元+生成\   AI生成+验证
```

每层都需人类定义"什么是对的"

---

## 工具链

**代码生成**
Cursor/Copilot/Windsurf → 测试验证 → AI修复

**AI评估**

- Promptfoo: Prompt回归
- DeepEval: LLM输出
- RAGAS: RAG系统
- LangSmith: Agent追踪

---

## 反常识

- AI写代码**更需要**测试
- 测试是给AI看的规格
- 意图覆盖率 > 100%覆盖率
- 没测试 = AI无边界
- 手写关键 + AI补边界

---

## 人类价值

```
AI擅长           人类必须
────────────────────────
生成大量用例  ←→  定义值得测试
通过测试     ←→  判断反映需求
执行重构     ←→  决定方向目标
发现模式     ←→  判断适合业务
```

意图定义权 + 验收决策权\
AI加速执行，人类把控方向

---

## 实践清单

**立即**

- [ ] "这能让AI理解意图吗"
- [ ] AI生成边界 + 人工审查
- [ ] 测试加自然语言注释

**逐步**

- [ ] Spec → 测试 → 代码流程
- [ ] 建立Eval基准集
- [ ] Agent行为边界框架

**持续**

- [ ] 测试即Prompt演进
- [ ] 形式化验证 + AI
- [ ] 自动化意图验证

---

## 关键问题

- 测试能让AI理解意图吗?
- AI测试覆盖关心边界吗?
- 测试通过 = 需求满足?
- 如何测试"质量"非"正确"?
- 如何检测Agent越界?
- 测试代码还是测试AI理解?

---

## 终极洞察

测试本质: 验证意图被正确实现\
测试对象: 代码 → AI系统\
测试作用: 验证 → 约束+沟通\
TDD更重要: 测试是人类意图的机器可读表达\
会写测试 = 会定义AI行为边界

**未来区分度**\
能定义"什么是对的" > 能实现功能
