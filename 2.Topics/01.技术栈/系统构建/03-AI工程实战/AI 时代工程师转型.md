---
view-count: 11
update: 2026-01-03 23:46
tags:
  - system-architecting
  - human-in-the-loop
  - AI
  - EngineeringMindset
  - Type/Reference
  - Domain/Technology
related:
  - '[[2025-12-19-开发过程中的关键不变量]]'
  - '[[破局而出]]'
  - '[[2025-12-07-系统架构分类框架]]'
  - '[[见解-模式-解决方案]]'
---
# [[AI 时代工程师转型]] | Minimal

---

## 0. 本质 (The Essence)
- **核心逻辑**：价值流向上游迁徙。AI 承包底层执行（System 1），人类转向高阶策略与架构（System 2）。
- **公式**：$AI (自动化执行) + 人类 (战略定义) = 增强智能$。
- **定位**：从“编码机器”进化为“系统指挥家”。

---

## 1. 核心元技能矩阵

| 技能 | 核心动作 | 价值点 | 吐槽 |
| :--- | :--- | :--- | :--- |
| **抽象建模** | 需求 → 结构化约束 | 定义 AI 的操作边界 | AI 擅长填空，人类擅长出题 |
| **语义对齐** | 意图 → 精确指令 | 建立“指令语法库” | 提示词不是聊天，是编程意图 |
| **系统编排** | LLM + 工具 + 记忆 | 构建复杂人机协作流 | 不要把模型当终点，要当组件 |
| **思维链构造** | 分步推理 + 验证 | 提升 AI 输出的逻辑精度 | 它是“玻璃盒”推理，拒绝黑盒 |

---

## 2. 逻辑骨架 (Minimal Workflow)

### **价值生产流**
`混沌需求 -> 人类抽象建模 (定义结构) -> AI 自动化执行 (填充细节) -> 人类元认知验证 (闭环)`

### **Orchestrator 架构**
`Planner (规划) -> Executor (工具调用) -> Memory (上下文) -> Feedback (人类纠偏)`

---

## 3. 避坑指南 (Brutal Truths)

- **自动化偏差 (Automation Bias)**：无脑相信 AI 是认知退化的开始。**Trust but Verify** 是唯一信条。
- **技能贬值**：死记 API、写 CRUD、纠结语法完美度已无护城河。
- **平庸陷阱**：如果你只把 AI 当成“加速版打字员”，你迟早会被更便宜的打字员替代。
- **理解力即生命力**：不理解原理的提示词工程只是“刻舟求剑”。

---

## 4. 转型决策树

1. **收到任务？**
    - 问：这是重复性执行吗？ → 是，交给 AI。
    - 问：这是定义新范式吗？ → 否，强制进行**抽象建模**。
2. **AI 输出不符合预期？**
    - 检查：指令是否带有明确的**约束条件**和**验证方法**？
3. **职业规划迷茫？**
    - 编码占比 > 80%？ → 风险等级：**极高**。立即提升**系统设计**权重。

---

## 5. 90 天转型行动清单 (Checklist)

- [ ] **M1: 深度理解**：掌握 Transformer 与 In-context Learning 原理，戒掉“试错式”提示。
- [ ] **M2: 系统升级**：亲手搭建一个集成了 Tools 和 Memory 的 Agent 原型。
- [ ] **M3: 战略重构**：审视业务流程，找出 3 个可用 AI 彻底重定义生产力的环节。
- [ ] **元认知审计**：每一次 AI 交付后，是否进行了“逻辑二验”而非直接 Commit？

---

**原则**：未来不是 AI 替代人，而是 AI 增强人。从 Doer 升级为 Thinker，从优化代码转向优化决策。

# AI时代TDD (2025)

## 范式转变

```
传统: 人写测试 → 人写代码 → 人重构
AI增强: 人写测试 → AI写代码 → AI重构(人审)
2025: 人写规格 → AI写测试+代码 → 人验证意图
```

测试验证AI + 约束AI + 传达意图

---

## 角色矩阵

| 环节   | 传统TDD  | 2025实践        |
| ---- | ------ | ------------- |
| 意图定义 | 隐含在测试中 | Spec文件明确      |
| 测试编写 | 人类手写   | 人写关键+AI补边界    |
| 代码实现 | 人类手写   | AI生成→测试验证→人审  |
| 重构   | 人类主导   | AI执行→测试守护→人批准 |
| 审查   | 代码审查   | 审查测试意图理解      |

---

## 工作流

```
SPEC (人类核心)
  自然语言描述期望 + 边界条件 + 验收标准
  ↓
TEST (人机协作)
  AI生成用例 ← 人审查意图 + 人补充边界
  ↓
GENERATE (AI主导)
  AI生成实现 → 测试验证 → 失败则迭代
  ↓
VERIFY (人类把关)
  可读性 + 意图覆盖 + 边缘情况
```

---

## 测试三层职责

```
Layer 3: 约束AI行为边界
         防止危险代码 + 明确"不应该"

Layer 2: 验证功能正确性
         输入输出 + 边界条件

Layer 1: 传达人类意图
         测试即规格 + AI理解需求
```

测试质量决定AI生成质量\
写好测试 > 写好prompt

---

## Eval-Driven Development

| 对比   | 传统TDD           | AI系统EDD       |
| ---- | --------------- | ------------- |
| 验证对象 | 确定性代码           | 概率性输出         |
| 断言   | `assert x == y` | `score > 0.8` |
| 数据   | 固定用例            | 多样化样本集        |
| 标准   | 100%通过          | 统计显著性         |
| 回归   | 精确匹配            | 分布漂移检测        |

```python
# 传统
def test_add():
    assert add(1,2) == 3

# AI系统
def eval_summary():
    results = [judge(summary(doc)) for doc in test_set]
    assert mean(results) > 0.85
    assert min(results) > 0.5
```

---

## Agent测试策略

```
传统函数: input → output
Agent: input → [思考→工具→思考]→ output
              ↑ 过程不确定
```

**策略**

- 行为边界 → 不应该做什么
- 工具调用 → 调用正确工具
- 最终结果 → 目标达成
- 测试目标达成 > 测试路径

```python
def test_agent():
    result = agent.run("订明天去上海机票")
    
    # 最终状态
    assert result.booking_confirmed
    assert result.destination == "上海"
    
    # 安全边界
    assert "delete" not in result.tool_calls
    assert result.total_cost < user.budget_limit
```

---

## 测试金字塔

```
传统         2025
/E2E\       /Eval\      AI输出评估
/集成\       /Agent\     行为边界
/单元\       /单元+生成\   AI生成+验证
```

每层都需人类定义"什么是对的"

---

## 工具链

**代码生成**
Cursor/Copilot/Windsurf → 测试验证 → AI修复

**AI评估**

- Promptfoo: Prompt回归
- DeepEval: LLM输出
- RAGAS: RAG系统
- LangSmith: Agent追踪

---

## 反常识

- AI写代码**更需要**测试
- 测试是给AI看的规格
- 意图覆盖率 > 100%覆盖率
- 没测试 = AI无边界
- 手写关键 + AI补边界

---

## 人类价值

```
AI擅长           人类必须
────────────────────────
生成大量用例  ←→  定义值得测试
通过测试     ←→  判断反映需求
执行重构     ←→  决定方向目标
发现模式     ←→  判断适合业务
```

意图定义权 + 验收决策权\
AI加速执行，人类把控方向

---

## 实践清单

**立即**

- [ ] "这能让AI理解意图吗"
- [ ] AI生成边界 + 人工审查
- [ ] 测试加自然语言注释

**逐步**

- [ ] Spec → 测试 → 代码流程
- [ ] 建立Eval基准集
- [ ] Agent行为边界框架

**持续**

- [ ] 测试即Prompt演进
- [ ] 形式化验证 + AI
- [ ] 自动化意图验证

---

## 关键问题

- 测试能让AI理解意图吗?
- AI测试覆盖关心边界吗?
- 测试通过 = 需求满足?
- 如何测试"质量"非"正确"?
- 如何检测Agent越界?
- 测试代码还是测试AI理解?

---

## 终极洞察

测试本质: 验证意图被正确实现\
测试对象: 代码 → AI系统\
测试作用: 验证 → 约束+沟通\
TDD更重要: 测试是人类意图的机器可读表达\
会写测试 = 会定义AI行为边界

**未来区分度**\
能定义"什么是对的" > 能实现功能
